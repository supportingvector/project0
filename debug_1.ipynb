{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepariation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from model import Model\n",
    "from utils import DataLoader\n",
    "from tensorflow.python.ops import variable_scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_loader=utils.DataLoader()\n",
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_decoder(decoder_inputs,\n",
    "                initial_state,\n",
    "                cell,\n",
    "                loop_function=None,\n",
    "                scope=None):\n",
    "    with variable_scope.variable_scope(scope or \"rnn_decoder\"):\n",
    "        state = initial_state\n",
    "        outputs = []\n",
    "        prev = None\n",
    "        for i, inp in enumerate(decoder_inputs):\n",
    "            if loop_function is not None and prev is not None:\n",
    "                with variable_scope.variable_scope(\"loop_function\", reuse=True):\n",
    "                    inp = loop_function(prev, i)\n",
    "            if i > 0:\n",
    "                variable_scope.get_variable_scope().reuse_variables()\n",
    "            output, state = cell(inp, state)\n",
    "            outputs.append(output)\n",
    "            if loop_function is not None:\n",
    "                prev = output\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "class Model():\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        parameters_init\n",
    "        '''\n",
    "        sequence_length=data_loader.seq_length\n",
    "        rnn_size=130\n",
    "        num_layers=3\n",
    "        self.lr=0.00001\n",
    "        batch_size=50\n",
    "        embedding_size=32\n",
    "        grad_clip=5\n",
    "        '''\n",
    "        data_input\n",
    "        '''\n",
    "        self.input_data = tf.placeholder(tf.float32, [None,sequence_length, 2])\n",
    "        #input:(batch_size,序列长度，2)\n",
    "        self.target_data = tf.placeholder(tf.float32, [None, sequence_length, 2])\n",
    "        #target_data:(batch_size,序列长度，2)\n",
    "        seq_length=int(5)\n",
    "        self.inputs = tf.split(axis=1, num_or_size_splits=int(seq_length), value=self.input_data)\n",
    "        #(序列长度，batch_size,1,2)\n",
    "        self.inputs = [tf.squeeze(input_, [1]) for input_ in self.inputs]\n",
    "        #(序列长度，batch_size,2)\n",
    "        #即转成了每一列为一个batch的一组序列\n",
    "        # Get a list of 2D tensors. Each of size numPoints x 2\n",
    "        '''\n",
    "        embedding\n",
    "        '''\n",
    "        self.embedded_inputs = []\n",
    "        #with tf.variable_scope(\"coordinate_embedding\"):\n",
    "        with tf.variable_scope(\"coordinate_embedding\",reuse=True):\n",
    "            #  The spatial embedding using a ReLU layer\n",
    "            #  Embed the 2D coordinates into embedding_size dimensions\n",
    "            #  TODO: (improve) For now assume embedding_size = rnn_size\n",
    "            embedding_w = tf.get_variable(\"embedding_w\", [2, embedding_size])\n",
    "            embedding_b = tf.get_variable(\"embedding_b\", [embedding_size])       \n",
    "        for x in self.inputs:\n",
    "            #这里的x跟坐标的x没关系，只是指代一个\n",
    "            # Each x is a 2D tensor of size numPoints x 2\n",
    "            # Embedding layer\n",
    "            embedded_x = tf.nn.relu(tf.add(tf.matmul(x, embedding_w), embedding_b))\n",
    "            self.embedded_inputs.append(embedded_x)\n",
    "        #得到的embedded_inputs维度是（sequence_length，batch_size,embedding_size）\n",
    "            \n",
    "        \n",
    "        '''\n",
    "        rnn_cell defination\n",
    "        '''\n",
    "        cell=rnn_cell.BasicLSTMCell(rnn_size,state_is_tuple=True)\n",
    "        #cell=rnn_cell.MultiRNNCell([cell]*num_layers,state_is_tuple=True)\n",
    "        self.cell=cell\n",
    "        self.initial_state=cell.zero_state(batch_size=batch_size,dtype=tf.float32)       \n",
    "        # Output size is the set of parameters (mu, sigma, corr)\n",
    "        output_size = 5  # 2 mu, 2 sigma and 1 corr\n",
    "        #with tf.variable_scope(\"rnnlm\"):\n",
    "        with tf.variable_scope(\"rnnlm\",reuse=True):\n",
    "            output_w = tf.get_variable(\"output_w\", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)\n",
    "            output_b = tf.get_variable(\"output_b\", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)\n",
    "                 \n",
    "        #with tf.variable_scope('rnnlm'):\n",
    "        with tf.variable_scope('rnnlm',reuse=True):\n",
    "            self.outputs, last_state =rnn_decoder(self.embedded_inputs, self.initial_state, cell, loop_function=None)\n",
    "            #outputs shape[sequence_length, batch_size, hidden_layers]\n",
    "        self.output = tf.reshape(tf.concat(self.outputs,1), [-1,rnn_size])\n",
    "        #output shape: [sequence*batch_size,hidden_layers]\n",
    "        self.output = tf.nn.xw_plus_b(self.output, output_w, output_b)\n",
    "        \n",
    "        self.final_state = last_state\n",
    "        #final_state shape: [2(两个隐层数组)，batch_size,hidden_layers)]\n",
    "        flat_target_data = tf.reshape(self.target_data, [-1, 2])\n",
    "        [x_data, y_data] = tf.split(flat_target_data, 2,1)\n",
    "        #x_data代表target_data的第一列，即所有x坐标\n",
    "        #y_data代表target_data的第二列，即所有y坐标\n",
    "        '''\n",
    "        some built_in_class functions \n",
    "        '''\n",
    "        def tf_2d_normal(x, y, mux, muy, sx, sy, rho):\n",
    "            #输入x,y输出其对应的概率密度值是多少\n",
    "            '''x : input x points\n",
    "            y : input y points\n",
    "            mux : mean of the distribution in x\n",
    "            muy : mean of the distribution in y\n",
    "            sx : std dev of the distribution in x\n",
    "            sy : std dev of the distribution in y\n",
    "            rho : Correlation factor of the distribution'''\n",
    "            normx = tf.subtract(x, mux)\n",
    "            normy = tf.subtract(y, muy)\n",
    "            sxsy = tf.multiply(sx, sy)\n",
    "            z = tf.square(tf.div(normx, sx)) + tf.square(tf.div(normy, sy)) - 2*tf.div(tf.multiply(rho, tf.multiply(normx, normy)), sxsy)\n",
    "            negRho = 1 - tf.square(rho)\n",
    "            result = tf.exp(tf.div(-z, 2*negRho))\n",
    "            denom = 2 * np.pi * tf.multiply(sxsy, tf.sqrt(negRho))\n",
    "            result = tf.div(result, denom)\n",
    "            self.result = result\n",
    "            return result\n",
    "        \n",
    "        def get_lossfunc(z_mux, z_muy, z_sx, z_sy, z_corr, x_data, y_data):\n",
    "            step = tf.constant(1e-3, dtype=tf.float32, shape=(1, 1))\n",
    "            # Calculate the PDF of the data w.r.t to the distribution\n",
    "            result0_1 = tf_2d_normal(x_data, y_data, z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "            result0_2 = tf_2d_normal(tf.add(x_data, step), y_data, z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "            result0_3 = tf_2d_normal(x_data, tf.add(y_data, step), z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "            result0_4 = tf_2d_normal(tf.add(x_data, step), tf.add(y_data, step), z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "            result0 = tf.div(tf.add(tf.add(tf.add(result0_1, result0_2), result0_3), result0_4), tf.constant(4.0, dtype=tf.float32, shape=(1, 1)))\n",
    "            #数值稳定性，加小系数求平均\n",
    "            result0 = tf.multiply(tf.multiply(result0, step), step)\n",
    "            # For numerical stability purposes\n",
    "            epsilon = 1e-20\n",
    "            result1 = -tf.log(tf.maximum(result0, epsilon))  # Numerical stability\n",
    "            return tf.reduce_sum(result1)\n",
    "    \n",
    "        def get_coef(output):\n",
    "            z = output\n",
    "            z_mux, z_muy, z_sx, z_sy, z_corr = tf.split(z,5,1)\n",
    "            z_sx = tf.exp(z_sx)\n",
    "            z_sy = tf.exp(z_sy)\n",
    "            z_corr = tf.tanh(z_corr)\n",
    "            return [z_mux, z_muy, z_sx, z_sy, z_corr]   \n",
    "        [o_mux, o_muy, o_sx, o_sy, o_corr] = get_coef(self.output)\n",
    "        # Store the predicted outputs\n",
    "        self.mux = o_mux\n",
    "        self.muy = o_muy\n",
    "        self.sx = o_sx\n",
    "        self.sy = o_sy\n",
    "        self.corr = o_corr\n",
    "        # Compute the loss function\n",
    "        lossfunc = get_lossfunc(o_mux, o_muy, o_sx, o_sy, o_corr, x_data, y_data)\n",
    "        self.cost = tf.div(lossfunc, (batch_size * seq_length))\n",
    "        tvars = tf.trainable_variables()\n",
    "        self.gradients = tf.gradients(self.cost, tvars)\n",
    "        grads, _ = tf.clip_by_global_norm(self.gradients,grad_clip)\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.lr)\n",
    "        with tf.variable_scope(\"rnnlm\",reuse=True):\n",
    "        #with tf.variable_scope(\"rnnlm\"):\n",
    "            self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "    def sample(self, sess, traj, num=10):\n",
    "        '''\n",
    "        Given an initial trajectory (as a list of tuples of points), predict the future trajectory\n",
    "        until a few timesteps\n",
    "        Params:\n",
    "        sess: Current session of Tensorflow\n",
    "        traj: List of past trajectory points\n",
    "        num: Number of time-steps into the future to be predicted\n",
    "        '''\n",
    "        def sample_gaussian_2d(mux, muy, sx, sy, rho):\n",
    "            '''\n",
    "            Function to sample a point from a given 2D normal distribution\n",
    "            params:\n",
    "            mux : mean of the distribution in x\n",
    "            muy : mean of the distribution in y\n",
    "            sx : std dev of the distribution in x\n",
    "            sy : std dev of the distribution in y\n",
    "            rho : Correlation factor of the distribution\n",
    "            '''\n",
    "            # Extract mean\n",
    "            mean = [mux, muy]\n",
    "            # Extract covariance matrix\n",
    "            cov = [[sx*sx, rho*sx*sy], [rho*sx*sy, sy*sy]]\n",
    "            # Sample a point from the multivariate normal distribution\n",
    "            x = np.random.multivariate_normal(mean, cov, 1)\n",
    "            return x[0][0], x[0][1]\n",
    "\n",
    "        # Initial state with zeros\n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "\n",
    "        # Iterate over all the positions seen in the trajectory\n",
    "        for pos in traj[:-1]:\n",
    "            # Create the input data tensor\n",
    "            data = np.zeros((1, 1, 2), dtype=np.float32)\n",
    "            data[0, 0, 0] = pos[0]  # x\n",
    "            data[0, 0, 1] = pos[1]  # y\n",
    "\n",
    "            # Create the feed dict\n",
    "            feed = {self.input_data: data, self.initial_state: state}\n",
    "            # Get the final state after processing the current position\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        ret = traj\n",
    "\n",
    "        # Last position in the observed trajectory\n",
    "        last_pos = traj[-1]\n",
    "\n",
    "        # Construct the input data tensor for the last point\n",
    "        prev_data = np.zeros((1, 1, 2), dtype=np.float32)\n",
    "        prev_data[0, 0, 0] = last_pos[0]  # x\n",
    "        prev_data[0, 0, 1] = last_pos[1]  # y\n",
    "\n",
    "        for t in range(num):\n",
    "            # Create the feed dict\n",
    "            feed = {self.input_data: prev_data, self.initial_state: state}\n",
    "\n",
    "            # Get the final state and also the coef of the distribution of the next point\n",
    "            [o_mux, o_muy, o_sx, o_sy, o_corr, state] = sess.run([self.mux, self.muy, self.sx, self.sy, self.corr, self.final_state], feed)\n",
    "\n",
    "            # Sample the next point from the distribution\n",
    "            next_x, next_y = sample_gaussian_2d(o_mux[0][0], o_muy[0][0], o_sx[0][0], o_sy[0][0], o_corr[0][0])\n",
    "            # Append the new point to the trajectory\n",
    "            ret = np.vstack((ret, [next_x, next_y]))\n",
    "\n",
    "            # Set the current sampled position as the last observed position\n",
    "            prev_data[0, 0, 0] = next_x\n",
    "            prev_data[0, 0, 1] = next_y\n",
    "\n",
    "        return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-160306bfa184>:3: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "model=1\n",
    "model=Model()\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model.ckpt-2500\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, 'save/model.ckpt-2500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2800 (epoch 0), train_loss = 10.110, time/batch = 0.871\n",
      "1/2800 (epoch 0), train_loss = 9.879, time/batch = 0.031\n",
      "2/2800 (epoch 0), train_loss = 9.411, time/batch = 0.031\n",
      "3/2800 (epoch 0), train_loss = 10.995, time/batch = 0.038\n",
      "4/2800 (epoch 0), train_loss = 9.207, time/batch = 0.031\n",
      "5/2800 (epoch 0), train_loss = 11.112, time/batch = 0.047\n",
      "6/2800 (epoch 0), train_loss = 9.220, time/batch = 0.046\n",
      "7/2800 (epoch 0), train_loss = 10.943, time/batch = 0.047\n",
      "8/2800 (epoch 0), train_loss = 8.884, time/batch = 0.047\n",
      "9/2800 (epoch 0), train_loss = 11.829, time/batch = 0.037\n",
      "10/2800 (epoch 0), train_loss = 9.316, time/batch = 0.034\n",
      "11/2800 (epoch 0), train_loss = 10.967, time/batch = 0.035\n",
      "12/2800 (epoch 0), train_loss = 9.054, time/batch = 0.042\n",
      "13/2800 (epoch 0), train_loss = 10.649, time/batch = 0.053\n",
      "14/2800 (epoch 0), train_loss = 8.904, time/batch = 0.052\n",
      "15/2800 (epoch 0), train_loss = 11.226, time/batch = 0.038\n",
      "16/2800 (epoch 0), train_loss = 8.963, time/batch = 0.036\n",
      "17/2800 (epoch 0), train_loss = 11.200, time/batch = 0.037\n",
      "18/2800 (epoch 0), train_loss = 8.887, time/batch = 0.041\n",
      "19/2800 (epoch 0), train_loss = 10.823, time/batch = 0.042\n",
      "20/2800 (epoch 0), train_loss = 8.992, time/batch = 0.042\n",
      "21/2800 (epoch 0), train_loss = 10.638, time/batch = 0.034\n",
      "22/2800 (epoch 0), train_loss = 9.477, time/batch = 0.033\n",
      "23/2800 (epoch 0), train_loss = 11.120, time/batch = 0.040\n",
      "24/2800 (epoch 0), train_loss = 9.739, time/batch = 0.051\n",
      "25/2800 (epoch 0), train_loss = 10.468, time/batch = 0.039\n",
      "26/2800 (epoch 0), train_loss = 9.726, time/batch = 0.041\n",
      "27/2800 (epoch 0), train_loss = 10.619, time/batch = 0.031\n",
      "28/2800 (epoch 0), train_loss = 9.421, time/batch = 0.030\n",
      "29/2800 (epoch 0), train_loss = 10.562, time/batch = 0.033\n",
      "30/2800 (epoch 0), train_loss = 9.553, time/batch = 0.039\n",
      "31/2800 (epoch 0), train_loss = 10.783, time/batch = 0.041\n",
      "32/2800 (epoch 0), train_loss = 9.255, time/batch = 0.033\n",
      "33/2800 (epoch 0), train_loss = 10.470, time/batch = 0.032\n",
      "34/2800 (epoch 0), train_loss = 9.391, time/batch = 0.031\n",
      "35/2800 (epoch 0), train_loss = 10.185, time/batch = 0.033\n",
      "36/2800 (epoch 0), train_loss = 11.296, time/batch = 0.082\n",
      "37/2800 (epoch 0), train_loss = 11.848, time/batch = 0.079\n",
      "38/2800 (epoch 0), train_loss = 11.143, time/batch = 0.060\n",
      "39/2800 (epoch 0), train_loss = 11.107, time/batch = 0.033\n",
      "40/2800 (epoch 0), train_loss = 10.672, time/batch = 0.027\n",
      "41/2800 (epoch 0), train_loss = 10.614, time/batch = 0.028\n",
      "42/2800 (epoch 0), train_loss = 10.952, time/batch = 0.032\n",
      "43/2800 (epoch 0), train_loss = 10.635, time/batch = 0.028\n",
      "44/2800 (epoch 0), train_loss = 11.003, time/batch = 0.023\n",
      "45/2800 (epoch 0), train_loss = 10.560, time/batch = 0.023\n",
      "46/2800 (epoch 0), train_loss = 11.228, time/batch = 0.023\n",
      "47/2800 (epoch 0), train_loss = 10.590, time/batch = 0.024\n",
      "48/2800 (epoch 0), train_loss = 11.496, time/batch = 0.025\n",
      "49/2800 (epoch 0), train_loss = 10.436, time/batch = 0.025\n",
      "50/2800 (epoch 0), train_loss = 11.128, time/batch = 0.032\n",
      "51/2800 (epoch 0), train_loss = 10.367, time/batch = 0.035\n",
      "52/2800 (epoch 0), train_loss = 10.830, time/batch = 0.036\n",
      "53/2800 (epoch 0), train_loss = 10.319, time/batch = 0.023\n",
      "54/2800 (epoch 0), train_loss = 10.484, time/batch = 0.025\n",
      "55/2800 (epoch 0), train_loss = 10.586, time/batch = 0.025\n",
      "56/2800 (epoch 1), train_loss = 9.916, time/batch = 0.020\n",
      "57/2800 (epoch 1), train_loss = 10.270, time/batch = 0.016\n",
      "58/2800 (epoch 1), train_loss = 10.087, time/batch = 0.031\n",
      "59/2800 (epoch 1), train_loss = 9.539, time/batch = 0.031\n",
      "60/2800 (epoch 1), train_loss = 10.392, time/batch = 0.038\n",
      "61/2800 (epoch 1), train_loss = 9.242, time/batch = 0.031\n",
      "62/2800 (epoch 1), train_loss = 10.364, time/batch = 0.016\n",
      "63/2800 (epoch 1), train_loss = 9.630, time/batch = 0.034\n",
      "64/2800 (epoch 1), train_loss = 10.012, time/batch = 0.019\n",
      "65/2800 (epoch 1), train_loss = 8.871, time/batch = 0.016\n",
      "66/2800 (epoch 1), train_loss = 12.166, time/batch = 0.016\n",
      "67/2800 (epoch 1), train_loss = 9.292, time/batch = 0.031\n",
      "68/2800 (epoch 1), train_loss = 10.915, time/batch = 0.022\n",
      "69/2800 (epoch 1), train_loss = 9.127, time/batch = 0.031\n",
      "70/2800 (epoch 1), train_loss = 10.531, time/batch = 0.016\n",
      "71/2800 (epoch 1), train_loss = 9.393, time/batch = 0.016\n",
      "72/2800 (epoch 1), train_loss = 10.027, time/batch = 0.034\n",
      "73/2800 (epoch 1), train_loss = 9.212, time/batch = 0.019\n",
      "74/2800 (epoch 1), train_loss = 10.348, time/batch = 0.016\n",
      "75/2800 (epoch 1), train_loss = 9.237, time/batch = 0.047\n",
      "76/2800 (epoch 1), train_loss = 10.274, time/batch = 0.038\n",
      "77/2800 (epoch 1), train_loss = 9.893, time/batch = 0.047\n",
      "78/2800 (epoch 1), train_loss = 11.030, time/batch = 0.037\n",
      "79/2800 (epoch 1), train_loss = 9.451, time/batch = 0.035\n",
      "80/2800 (epoch 1), train_loss = 10.506, time/batch = 0.026\n",
      "81/2800 (epoch 1), train_loss = 9.616, time/batch = 0.051\n",
      "82/2800 (epoch 1), train_loss = 10.151, time/batch = 0.050\n",
      "83/2800 (epoch 1), train_loss = 9.412, time/batch = 0.034\n",
      "84/2800 (epoch 1), train_loss = 10.329, time/batch = 0.029\n",
      "85/2800 (epoch 1), train_loss = 9.803, time/batch = 0.030\n",
      "86/2800 (epoch 1), train_loss = 10.186, time/batch = 0.039\n",
      "87/2800 (epoch 1), train_loss = 9.719, time/batch = 0.035\n",
      "88/2800 (epoch 1), train_loss = 9.940, time/batch = 0.036\n",
      "89/2800 (epoch 1), train_loss = 9.716, time/batch = 0.044\n",
      "90/2800 (epoch 1), train_loss = 10.862, time/batch = 0.032\n",
      "91/2800 (epoch 1), train_loss = 11.336, time/batch = 0.033\n",
      "92/2800 (epoch 1), train_loss = 11.370, time/batch = 0.029\n",
      "93/2800 (epoch 1), train_loss = 10.840, time/batch = 0.028\n",
      "94/2800 (epoch 1), train_loss = 10.899, time/batch = 0.027\n",
      "95/2800 (epoch 1), train_loss = 10.633, time/batch = 0.030\n",
      "96/2800 (epoch 1), train_loss = 10.884, time/batch = 0.023\n",
      "97/2800 (epoch 1), train_loss = 10.669, time/batch = 0.047\n",
      "98/2800 (epoch 1), train_loss = 11.059, time/batch = 0.023\n",
      "99/2800 (epoch 1), train_loss = 10.622, time/batch = 0.021\n",
      "100/2800 (epoch 1), train_loss = 10.696, time/batch = 0.021\n",
      "101/2800 (epoch 1), train_loss = 10.801, time/batch = 0.020\n",
      "102/2800 (epoch 1), train_loss = 11.227, time/batch = 0.017\n",
      "103/2800 (epoch 1), train_loss = 10.570, time/batch = 0.003\n",
      "104/2800 (epoch 1), train_loss = 10.979, time/batch = 0.016\n",
      "105/2800 (epoch 1), train_loss = 10.344, time/batch = 0.016\n",
      "106/2800 (epoch 1), train_loss = 10.873, time/batch = 0.016\n",
      "107/2800 (epoch 1), train_loss = 10.126, time/batch = 0.016\n",
      "108/2800 (epoch 1), train_loss = 10.880, time/batch = 0.034\n",
      "109/2800 (epoch 1), train_loss = 10.859, time/batch = 0.004\n",
      "110/2800 (epoch 1), train_loss = 9.829, time/batch = 0.016\n",
      "111/2800 (epoch 1), train_loss = 10.130, time/batch = 0.016\n",
      "112/2800 (epoch 2), train_loss = 9.912, time/batch = 0.000\n",
      "113/2800 (epoch 2), train_loss = 9.836, time/batch = 0.016\n",
      "114/2800 (epoch 2), train_loss = 10.013, time/batch = 0.016\n",
      "115/2800 (epoch 2), train_loss = 9.499, time/batch = 0.016\n",
      "116/2800 (epoch 2), train_loss = 10.585, time/batch = 0.018\n",
      "117/2800 (epoch 2), train_loss = 9.384, time/batch = 0.004\n",
      "118/2800 (epoch 2), train_loss = 10.379, time/batch = 0.016\n",
      "119/2800 (epoch 2), train_loss = 9.495, time/batch = 0.016\n",
      "120/2800 (epoch 2), train_loss = 10.516, time/batch = 0.016\n",
      "121/2800 (epoch 2), train_loss = 8.965, time/batch = 0.016\n",
      "122/2800 (epoch 2), train_loss = 10.597, time/batch = 0.016\n",
      "123/2800 (epoch 2), train_loss = 9.826, time/batch = 0.018\n",
      "124/2800 (epoch 2), train_loss = 9.925, time/batch = 0.004\n",
      "125/2800 (epoch 2), train_loss = 8.976, time/batch = 0.016\n",
      "126/2800 (epoch 2), train_loss = 10.921, time/batch = 0.016\n",
      "127/2800 (epoch 2), train_loss = 9.047, time/batch = 0.000\n",
      "128/2800 (epoch 2), train_loss = 11.494, time/batch = 0.016\n",
      "129/2800 (epoch 2), train_loss = 8.902, time/batch = 0.016\n",
      "130/2800 (epoch 2), train_loss = 11.479, time/batch = 0.016\n",
      "131/2800 (epoch 2), train_loss = 8.554, time/batch = 0.022\n",
      "132/2800 (epoch 2), train_loss = 11.786, time/batch = 0.031\n",
      "133/2800 (epoch 2), train_loss = 8.729, time/batch = 0.016\n",
      "134/2800 (epoch 2), train_loss = 11.819, time/batch = 0.016\n",
      "135/2800 (epoch 2), train_loss = 8.631, time/batch = 0.042\n",
      "136/2800 (epoch 2), train_loss = 12.691, time/batch = 0.017\n",
      "137/2800 (epoch 2), train_loss = 9.537, time/batch = 0.017\n",
      "138/2800 (epoch 2), train_loss = 9.603, time/batch = 0.016\n",
      "139/2800 (epoch 2), train_loss = 9.723, time/batch = 0.017\n",
      "140/2800 (epoch 2), train_loss = 9.618, time/batch = 0.016\n",
      "141/2800 (epoch 2), train_loss = 9.936, time/batch = 0.020\n",
      "142/2800 (epoch 2), train_loss = 9.949, time/batch = 0.017\n",
      "143/2800 (epoch 2), train_loss = 10.042, time/batch = 0.021\n",
      "144/2800 (epoch 2), train_loss = 9.629, time/batch = 0.021\n",
      "145/2800 (epoch 2), train_loss = 10.271, time/batch = 0.014\n",
      "146/2800 (epoch 2), train_loss = 9.656, time/batch = 0.013\n",
      "147/2800 (epoch 2), train_loss = 9.971, time/batch = 0.012\n",
      "148/2800 (epoch 2), train_loss = 9.677, time/batch = 0.012\n",
      "149/2800 (epoch 2), train_loss = 9.944, time/batch = 0.012\n",
      "150/2800 (epoch 2), train_loss = 10.252, time/batch = 0.000\n",
      "151/2800 (epoch 2), train_loss = 11.887, time/batch = 0.016\n",
      "152/2800 (epoch 2), train_loss = 10.894, time/batch = 0.016\n",
      "153/2800 (epoch 2), train_loss = 11.296, time/batch = 0.016\n",
      "154/2800 (epoch 2), train_loss = 10.901, time/batch = 0.000\n",
      "155/2800 (epoch 2), train_loss = 10.807, time/batch = 0.016\n",
      "156/2800 (epoch 2), train_loss = 10.943, time/batch = 0.016\n",
      "157/2800 (epoch 2), train_loss = 10.763, time/batch = 0.016\n",
      "158/2800 (epoch 2), train_loss = 10.726, time/batch = 0.006\n",
      "159/2800 (epoch 2), train_loss = 10.775, time/batch = 0.000\n",
      "160/2800 (epoch 2), train_loss = 10.325, time/batch = 0.000\n",
      "161/2800 (epoch 2), train_loss = 11.569, time/batch = 0.016\n",
      "162/2800 (epoch 2), train_loss = 10.495, time/batch = 0.016\n",
      "163/2800 (epoch 2), train_loss = 11.424, time/batch = 0.016\n",
      "164/2800 (epoch 2), train_loss = 10.546, time/batch = 0.016\n",
      "165/2800 (epoch 2), train_loss = 11.642, time/batch = 0.000\n",
      "166/2800 (epoch 2), train_loss = 10.200, time/batch = 0.006\n",
      "167/2800 (epoch 2), train_loss = 10.776, time/batch = 0.016\n",
      "168/2800 (epoch 3), train_loss = 10.159, time/batch = 0.000\n",
      "169/2800 (epoch 3), train_loss = 9.401, time/batch = 0.016\n",
      "170/2800 (epoch 3), train_loss = 9.833, time/batch = 0.016\n",
      "171/2800 (epoch 3), train_loss = 10.261, time/batch = 0.016\n",
      "172/2800 (epoch 3), train_loss = 9.374, time/batch = 0.016\n",
      "173/2800 (epoch 3), train_loss = 9.987, time/batch = 0.000\n",
      "174/2800 (epoch 3), train_loss = 9.386, time/batch = 0.022\n",
      "175/2800 (epoch 3), train_loss = 10.156, time/batch = 0.016\n",
      "176/2800 (epoch 3), train_loss = 9.716, time/batch = 0.000\n",
      "177/2800 (epoch 3), train_loss = 10.730, time/batch = 0.016\n",
      "178/2800 (epoch 3), train_loss = 9.287, time/batch = 0.016\n",
      "179/2800 (epoch 3), train_loss = 11.107, time/batch = 0.016\n",
      "180/2800 (epoch 3), train_loss = 9.355, time/batch = 0.016\n",
      "181/2800 (epoch 3), train_loss = 9.097, time/batch = 0.022\n",
      "182/2800 (epoch 3), train_loss = 9.356, time/batch = 0.000\n",
      "183/2800 (epoch 3), train_loss = 9.925, time/batch = 0.016\n",
      "184/2800 (epoch 3), train_loss = 9.339, time/batch = 0.016\n",
      "185/2800 (epoch 3), train_loss = 9.754, time/batch = 0.016\n",
      "186/2800 (epoch 3), train_loss = 9.317, time/batch = 0.016\n",
      "187/2800 (epoch 3), train_loss = 9.377, time/batch = 0.000\n",
      "188/2800 (epoch 3), train_loss = 9.860, time/batch = 0.016\n",
      "189/2800 (epoch 3), train_loss = 9.866, time/batch = 0.022\n",
      "190/2800 (epoch 3), train_loss = 9.807, time/batch = 0.000\n",
      "191/2800 (epoch 3), train_loss = 9.924, time/batch = 0.016\n",
      "192/2800 (epoch 3), train_loss = 10.633, time/batch = 0.016\n",
      "193/2800 (epoch 3), train_loss = 9.591, time/batch = 0.016\n",
      "194/2800 (epoch 3), train_loss = 10.677, time/batch = 0.016\n",
      "195/2800 (epoch 3), train_loss = 9.343, time/batch = 0.016\n",
      "196/2800 (epoch 3), train_loss = 10.190, time/batch = 0.019\n",
      "197/2800 (epoch 3), train_loss = 9.447, time/batch = 0.003\n",
      "198/2800 (epoch 3), train_loss = 10.126, time/batch = 0.016\n",
      "199/2800 (epoch 3), train_loss = 9.786, time/batch = 0.016\n",
      "200/2800 (epoch 3), train_loss = 9.911, time/batch = 0.000\n",
      "201/2800 (epoch 3), train_loss = 9.652, time/batch = 0.016\n",
      "202/2800 (epoch 3), train_loss = 9.958, time/batch = 0.016\n",
      "203/2800 (epoch 3), train_loss = 9.729, time/batch = 0.016\n",
      "204/2800 (epoch 3), train_loss = 11.477, time/batch = 0.016\n",
      "205/2800 (epoch 3), train_loss = 11.298, time/batch = 0.006\n",
      "206/2800 (epoch 3), train_loss = 10.978, time/batch = 0.016\n",
      "207/2800 (epoch 3), train_loss = 10.852, time/batch = 0.000\n",
      "208/2800 (epoch 3), train_loss = 10.798, time/batch = 0.016\n",
      "209/2800 (epoch 3), train_loss = 10.735, time/batch = 0.031\n",
      "210/2800 (epoch 3), train_loss = 10.752, time/batch = 0.016\n",
      "211/2800 (epoch 3), train_loss = 10.791, time/batch = 0.021\n",
      "212/2800 (epoch 3), train_loss = 10.871, time/batch = 0.000\n",
      "213/2800 (epoch 3), train_loss = 10.608, time/batch = 0.016\n",
      "214/2800 (epoch 3), train_loss = 10.500, time/batch = 0.016\n",
      "215/2800 (epoch 3), train_loss = 10.895, time/batch = 0.016\n",
      "216/2800 (epoch 3), train_loss = 11.199, time/batch = 0.016\n",
      "217/2800 (epoch 3), train_loss = 10.428, time/batch = 0.018\n",
      "218/2800 (epoch 3), train_loss = 11.650, time/batch = 0.005\n",
      "219/2800 (epoch 3), train_loss = 10.802, time/batch = 0.016\n",
      "220/2800 (epoch 3), train_loss = 10.340, time/batch = 0.016\n",
      "221/2800 (epoch 3), train_loss = 10.733, time/batch = 0.016\n",
      "222/2800 (epoch 3), train_loss = 10.315, time/batch = 0.016\n",
      "223/2800 (epoch 3), train_loss = 10.831, time/batch = 0.033\n",
      "224/2800 (epoch 4), train_loss = 9.916, time/batch = 0.005\n",
      "225/2800 (epoch 4), train_loss = 9.652, time/batch = 0.016\n",
      "226/2800 (epoch 4), train_loss = 9.616, time/batch = 0.031\n",
      "227/2800 (epoch 4), train_loss = 10.529, time/batch = 0.016\n",
      "228/2800 (epoch 4), train_loss = 9.308, time/batch = 0.016\n",
      "229/2800 (epoch 4), train_loss = 10.489, time/batch = 0.019\n",
      "230/2800 (epoch 4), train_loss = 9.337, time/batch = 0.004\n",
      "231/2800 (epoch 4), train_loss = 11.479, time/batch = 0.016\n",
      "232/2800 (epoch 4), train_loss = 9.050, time/batch = 0.016\n",
      "233/2800 (epoch 4), train_loss = 11.227, time/batch = 0.016\n",
      "234/2800 (epoch 4), train_loss = 9.363, time/batch = 0.016\n",
      "235/2800 (epoch 4), train_loss = 10.227, time/batch = 0.016\n",
      "236/2800 (epoch 4), train_loss = 8.943, time/batch = 0.016\n",
      "237/2800 (epoch 4), train_loss = 11.554, time/batch = 0.006\n",
      "238/2800 (epoch 4), train_loss = 9.445, time/batch = 0.016\n",
      "239/2800 (epoch 4), train_loss = 11.048, time/batch = 0.016\n",
      "240/2800 (epoch 4), train_loss = 8.877, time/batch = 0.016\n",
      "241/2800 (epoch 4), train_loss = 10.908, time/batch = 0.016\n",
      "242/2800 (epoch 4), train_loss = 9.031, time/batch = 0.016\n",
      "243/2800 (epoch 4), train_loss = 11.494, time/batch = 0.022\n",
      "244/2800 (epoch 4), train_loss = 9.391, time/batch = 0.016\n",
      "245/2800 (epoch 4), train_loss = 10.557, time/batch = 0.016\n",
      "246/2800 (epoch 4), train_loss = 9.282, time/batch = 0.016\n",
      "247/2800 (epoch 4), train_loss = 11.088, time/batch = 0.016\n",
      "248/2800 (epoch 4), train_loss = 9.226, time/batch = 0.032\n",
      "249/2800 (epoch 4), train_loss = 10.553, time/batch = 0.005\n",
      "250/2800 (epoch 4), train_loss = 9.366, time/batch = 0.016\n",
      "251/2800 (epoch 4), train_loss = 10.538, time/batch = 0.016\n",
      "252/2800 (epoch 4), train_loss = 9.541, time/batch = 0.016\n",
      "253/2800 (epoch 4), train_loss = 10.016, time/batch = 0.016\n",
      "254/2800 (epoch 4), train_loss = 9.844, time/batch = 0.016\n",
      "255/2800 (epoch 4), train_loss = 10.073, time/batch = 0.022\n",
      "256/2800 (epoch 4), train_loss = 9.397, time/batch = 0.000\n",
      "257/2800 (epoch 4), train_loss = 10.558, time/batch = 0.016\n",
      "258/2800 (epoch 4), train_loss = 9.537, time/batch = 0.016\n",
      "259/2800 (epoch 4), train_loss = 9.684, time/batch = 0.016\n",
      "260/2800 (epoch 4), train_loss = 9.738, time/batch = 0.016\n",
      "261/2800 (epoch 4), train_loss = 12.145, time/batch = 0.000\n",
      "262/2800 (epoch 4), train_loss = 11.199, time/batch = 0.016\n",
      "263/2800 (epoch 4), train_loss = 11.471, time/batch = 0.018\n",
      "264/2800 (epoch 4), train_loss = 10.829, time/batch = 0.005\n",
      "265/2800 (epoch 4), train_loss = 10.822, time/batch = 0.016\n",
      "266/2800 (epoch 4), train_loss = 10.499, time/batch = 0.016\n",
      "267/2800 (epoch 4), train_loss = 10.930, time/batch = 0.016\n",
      "268/2800 (epoch 4), train_loss = 10.627, time/batch = 0.016\n",
      "269/2800 (epoch 4), train_loss = 11.159, time/batch = 0.000\n",
      "270/2800 (epoch 4), train_loss = 10.362, time/batch = 0.016\n",
      "271/2800 (epoch 4), train_loss = 11.338, time/batch = 0.022\n",
      "272/2800 (epoch 4), train_loss = 10.470, time/batch = 0.000\n",
      "273/2800 (epoch 4), train_loss = 10.568, time/batch = 0.016\n",
      "274/2800 (epoch 4), train_loss = 10.861, time/batch = 0.016\n",
      "275/2800 (epoch 4), train_loss = 11.267, time/batch = 0.000\n",
      "276/2800 (epoch 4), train_loss = 10.259, time/batch = 0.016\n",
      "277/2800 (epoch 4), train_loss = 10.425, time/batch = 0.016\n",
      "278/2800 (epoch 4), train_loss = 9.946, time/batch = 0.016\n",
      "279/2800 (epoch 4), train_loss = 10.992, time/batch = 0.000\n",
      "280/2800 (epoch 5), train_loss = 9.691, time/batch = 0.022\n",
      "281/2800 (epoch 5), train_loss = 9.614, time/batch = 0.016\n",
      "282/2800 (epoch 5), train_loss = 9.667, time/batch = 0.016\n",
      "283/2800 (epoch 5), train_loss = 9.920, time/batch = 0.016\n",
      "284/2800 (epoch 5), train_loss = 10.337, time/batch = 0.016\n",
      "285/2800 (epoch 5), train_loss = 9.494, time/batch = 0.016\n",
      "286/2800 (epoch 5), train_loss = 9.569, time/batch = 0.000\n",
      "287/2800 (epoch 5), train_loss = 8.938, time/batch = 0.022\n",
      "288/2800 (epoch 5), train_loss = 11.609, time/batch = 0.000\n",
      "289/2800 (epoch 5), train_loss = 8.667, time/batch = 0.016\n",
      "290/2800 (epoch 5), train_loss = 11.415, time/batch = 0.016\n",
      "291/2800 (epoch 5), train_loss = 9.856, time/batch = 0.016\n",
      "292/2800 (epoch 5), train_loss = 9.543, time/batch = 0.000\n",
      "293/2800 (epoch 5), train_loss = 9.047, time/batch = 0.016\n",
      "294/2800 (epoch 5), train_loss = 10.070, time/batch = 0.016\n",
      "295/2800 (epoch 5), train_loss = 9.331, time/batch = 0.000\n",
      "296/2800 (epoch 5), train_loss = 9.789, time/batch = 0.022\n",
      "297/2800 (epoch 5), train_loss = 9.524, time/batch = 0.000\n",
      "298/2800 (epoch 5), train_loss = 10.135, time/batch = 0.016\n",
      "299/2800 (epoch 5), train_loss = 9.237, time/batch = 0.016\n",
      "300/2800 (epoch 5), train_loss = 9.276, time/batch = 0.016\n",
      "301/2800 (epoch 5), train_loss = 9.203, time/batch = 0.016\n",
      "302/2800 (epoch 5), train_loss = 9.166, time/batch = 0.000\n",
      "303/2800 (epoch 5), train_loss = 11.181, time/batch = 0.000\n",
      "304/2800 (epoch 5), train_loss = 9.862, time/batch = 0.022\n",
      "305/2800 (epoch 5), train_loss = 9.811, time/batch = 0.000\n",
      "306/2800 (epoch 5), train_loss = 10.137, time/batch = 0.016\n",
      "307/2800 (epoch 5), train_loss = 9.573, time/batch = 0.016\n",
      "308/2800 (epoch 5), train_loss = 9.825, time/batch = 0.000\n",
      "309/2800 (epoch 5), train_loss = 9.588, time/batch = 0.016\n",
      "310/2800 (epoch 5), train_loss = 10.063, time/batch = 0.016\n",
      "311/2800 (epoch 5), train_loss = 9.917, time/batch = 0.016\n",
      "312/2800 (epoch 5), train_loss = 10.024, time/batch = 0.000\n",
      "313/2800 (epoch 5), train_loss = 9.977, time/batch = 0.022\n",
      "314/2800 (epoch 5), train_loss = 9.414, time/batch = 0.001\n",
      "315/2800 (epoch 5), train_loss = 10.140, time/batch = 0.016\n",
      "316/2800 (epoch 5), train_loss = 11.461, time/batch = 0.016\n",
      "317/2800 (epoch 5), train_loss = 11.012, time/batch = 0.016\n",
      "318/2800 (epoch 5), train_loss = 10.583, time/batch = 0.016\n",
      "319/2800 (epoch 5), train_loss = 11.700, time/batch = 0.000\n",
      "320/2800 (epoch 5), train_loss = 10.530, time/batch = 0.016\n",
      "321/2800 (epoch 5), train_loss = 11.268, time/batch = 0.017\n",
      "322/2800 (epoch 5), train_loss = 10.594, time/batch = 0.005\n",
      "323/2800 (epoch 5), train_loss = 11.053, time/batch = 0.016\n",
      "324/2800 (epoch 5), train_loss = 10.982, time/batch = 0.000\n",
      "325/2800 (epoch 5), train_loss = 10.757, time/batch = 0.016\n",
      "326/2800 (epoch 5), train_loss = 10.769, time/batch = 0.016\n",
      "327/2800 (epoch 5), train_loss = 10.749, time/batch = 0.016\n",
      "328/2800 (epoch 5), train_loss = 10.533, time/batch = 0.000\n",
      "329/2800 (epoch 5), train_loss = 10.789, time/batch = 0.016\n",
      "330/2800 (epoch 5), train_loss = 10.439, time/batch = 0.020\n",
      "331/2800 (epoch 5), train_loss = 11.280, time/batch = 0.002\n",
      "332/2800 (epoch 5), train_loss = 10.258, time/batch = 0.016\n",
      "333/2800 (epoch 5), train_loss = 11.330, time/batch = 0.016\n",
      "334/2800 (epoch 5), train_loss = 10.444, time/batch = 0.016\n",
      "335/2800 (epoch 5), train_loss = 10.371, time/batch = 0.016\n",
      "336/2800 (epoch 6), train_loss = 9.947, time/batch = 0.000\n",
      "337/2800 (epoch 6), train_loss = 9.985, time/batch = 0.016\n",
      "338/2800 (epoch 6), train_loss = 9.622, time/batch = 0.022\n",
      "339/2800 (epoch 6), train_loss = 10.468, time/batch = 0.016\n",
      "340/2800 (epoch 6), train_loss = 9.113, time/batch = 0.000\n",
      "341/2800 (epoch 6), train_loss = 11.565, time/batch = 0.016\n",
      "342/2800 (epoch 6), train_loss = 9.041, time/batch = 0.016\n",
      "343/2800 (epoch 6), train_loss = 12.628, time/batch = 0.016\n",
      "344/2800 (epoch 6), train_loss = 9.176, time/batch = 0.016\n",
      "345/2800 (epoch 6), train_loss = 11.025, time/batch = 0.000\n",
      "346/2800 (epoch 6), train_loss = 9.169, time/batch = 0.022\n",
      "347/2800 (epoch 6), train_loss = 10.785, time/batch = 0.016\n",
      "348/2800 (epoch 6), train_loss = 9.174, time/batch = 0.000\n",
      "349/2800 (epoch 6), train_loss = 10.785, time/batch = 0.016\n",
      "350/2800 (epoch 6), train_loss = 9.088, time/batch = 0.016\n",
      "351/2800 (epoch 6), train_loss = 11.106, time/batch = 0.016\n",
      "352/2800 (epoch 6), train_loss = 8.906, time/batch = 0.016\n",
      "353/2800 (epoch 6), train_loss = 10.206, time/batch = 0.021\n",
      "354/2800 (epoch 6), train_loss = 8.902, time/batch = 0.001\n",
      "355/2800 (epoch 6), train_loss = 11.036, time/batch = 0.016\n",
      "356/2800 (epoch 6), train_loss = 8.756, time/batch = 0.016\n",
      "357/2800 (epoch 6), train_loss = 10.275, time/batch = 0.016\n",
      "358/2800 (epoch 6), train_loss = 10.182, time/batch = 0.016\n",
      "359/2800 (epoch 6), train_loss = 9.622, time/batch = 0.000\n",
      "360/2800 (epoch 6), train_loss = 10.288, time/batch = 0.016\n",
      "361/2800 (epoch 6), train_loss = 9.613, time/batch = 0.022\n",
      "362/2800 (epoch 6), train_loss = 10.047, time/batch = 0.000\n",
      "363/2800 (epoch 6), train_loss = 9.406, time/batch = 0.000\n",
      "364/2800 (epoch 6), train_loss = 10.368, time/batch = 0.016\n",
      "365/2800 (epoch 6), train_loss = 9.620, time/batch = 0.016\n",
      "366/2800 (epoch 6), train_loss = 10.101, time/batch = 0.016\n",
      "367/2800 (epoch 6), train_loss = 9.524, time/batch = 0.016\n",
      "368/2800 (epoch 6), train_loss = 9.634, time/batch = 0.021\n",
      "369/2800 (epoch 6), train_loss = 9.191, time/batch = 0.001\n",
      "370/2800 (epoch 6), train_loss = 10.380, time/batch = 0.016\n",
      "371/2800 (epoch 6), train_loss = 11.860, time/batch = 0.016\n",
      "372/2800 (epoch 6), train_loss = 11.362, time/batch = 0.016\n",
      "373/2800 (epoch 6), train_loss = 11.231, time/batch = 0.016\n",
      "374/2800 (epoch 6), train_loss = 11.000, time/batch = 0.016\n",
      "375/2800 (epoch 6), train_loss = 10.661, time/batch = 0.016\n",
      "376/2800 (epoch 6), train_loss = 10.509, time/batch = 0.006\n",
      "377/2800 (epoch 6), train_loss = 10.907, time/batch = 0.016\n",
      "378/2800 (epoch 6), train_loss = 10.795, time/batch = 0.000\n",
      "379/2800 (epoch 6), train_loss = 10.896, time/batch = 0.016\n",
      "380/2800 (epoch 6), train_loss = 10.519, time/batch = 0.016\n",
      "381/2800 (epoch 6), train_loss = 11.406, time/batch = 0.016\n",
      "382/2800 (epoch 6), train_loss = 10.509, time/batch = 0.016\n",
      "383/2800 (epoch 6), train_loss = 10.243, time/batch = 0.000\n",
      "384/2800 (epoch 6), train_loss = 11.225, time/batch = 0.022\n",
      "385/2800 (epoch 6), train_loss = 10.690, time/batch = 0.000\n",
      "386/2800 (epoch 6), train_loss = 10.445, time/batch = 0.016\n",
      "387/2800 (epoch 6), train_loss = 10.340, time/batch = 0.016\n",
      "388/2800 (epoch 6), train_loss = 9.906, time/batch = 0.016\n",
      "389/2800 (epoch 6), train_loss = 10.709, time/batch = 0.000\n",
      "390/2800 (epoch 6), train_loss = 10.321, time/batch = 0.016\n",
      "391/2800 (epoch 6), train_loss = 10.079, time/batch = 0.016\n",
      "392/2800 (epoch 7), train_loss = 10.328, time/batch = 0.000\n",
      "393/2800 (epoch 7), train_loss = 9.371, time/batch = 0.022\n",
      "394/2800 (epoch 7), train_loss = 10.514, time/batch = 0.000\n",
      "395/2800 (epoch 7), train_loss = 9.209, time/batch = 0.016\n",
      "396/2800 (epoch 7), train_loss = 11.103, time/batch = 0.016\n",
      "397/2800 (epoch 7), train_loss = 9.061, time/batch = 0.016\n",
      "398/2800 (epoch 7), train_loss = 10.297, time/batch = 0.016\n",
      "399/2800 (epoch 7), train_loss = 9.040, time/batch = 0.016\n",
      "400/2800 (epoch 7), train_loss = 10.272, time/batch = 0.020\n",
      "401/2800 (epoch 7), train_loss = 9.288, time/batch = 0.002\n",
      "402/2800 (epoch 7), train_loss = 10.591, time/batch = 0.016\n",
      "403/2800 (epoch 7), train_loss = 9.511, time/batch = 0.016\n",
      "404/2800 (epoch 7), train_loss = 9.002, time/batch = 0.000\n",
      "405/2800 (epoch 7), train_loss = 9.348, time/batch = 0.016\n",
      "406/2800 (epoch 7), train_loss = 10.042, time/batch = 0.016\n",
      "407/2800 (epoch 7), train_loss = 8.661, time/batch = 0.000\n",
      "408/2800 (epoch 7), train_loss = 11.039, time/batch = 0.016\n",
      "409/2800 (epoch 7), train_loss = 8.959, time/batch = 0.020\n",
      "410/2800 (epoch 7), train_loss = 10.844, time/batch = 0.001\n",
      "411/2800 (epoch 7), train_loss = 9.042, time/batch = 0.016\n",
      "412/2800 (epoch 7), train_loss = 9.821, time/batch = 0.016\n",
      "413/2800 (epoch 7), train_loss = 9.353, time/batch = 0.000\n",
      "414/2800 (epoch 7), train_loss = 10.389, time/batch = 0.000\n",
      "415/2800 (epoch 7), train_loss = 9.261, time/batch = 0.016\n",
      "416/2800 (epoch 7), train_loss = 9.521, time/batch = 0.016\n",
      "417/2800 (epoch 7), train_loss = 9.439, time/batch = 0.017\n",
      "418/2800 (epoch 7), train_loss = 9.849, time/batch = 0.005\n",
      "419/2800 (epoch 7), train_loss = 10.428, time/batch = 0.016\n",
      "420/2800 (epoch 7), train_loss = 9.633, time/batch = 0.000\n",
      "421/2800 (epoch 7), train_loss = 10.278, time/batch = 0.016\n",
      "422/2800 (epoch 7), train_loss = 9.418, time/batch = 0.016\n",
      "423/2800 (epoch 7), train_loss = 10.958, time/batch = 0.016\n",
      "424/2800 (epoch 7), train_loss = 9.536, time/batch = 0.000\n",
      "425/2800 (epoch 7), train_loss = 10.434, time/batch = 0.016\n",
      "426/2800 (epoch 7), train_loss = 9.322, time/batch = 0.022\n",
      "427/2800 (epoch 7), train_loss = 9.444, time/batch = 0.000\n",
      "428/2800 (epoch 7), train_loss = 9.761, time/batch = 0.016\n",
      "429/2800 (epoch 7), train_loss = 10.246, time/batch = 0.016\n",
      "430/2800 (epoch 7), train_loss = 13.768, time/batch = 0.016\n",
      "431/2800 (epoch 7), train_loss = 11.161, time/batch = 0.016\n",
      "432/2800 (epoch 7), train_loss = 11.271, time/batch = 0.000\n",
      "433/2800 (epoch 7), train_loss = 10.968, time/batch = 0.016\n",
      "434/2800 (epoch 7), train_loss = 10.775, time/batch = 0.018\n",
      "435/2800 (epoch 7), train_loss = 10.608, time/batch = 0.003\n",
      "436/2800 (epoch 7), train_loss = 10.671, time/batch = 0.016\n",
      "437/2800 (epoch 7), train_loss = 10.796, time/batch = 0.000\n",
      "438/2800 (epoch 7), train_loss = 10.674, time/batch = 0.016\n",
      "439/2800 (epoch 7), train_loss = 10.670, time/batch = 0.016\n",
      "440/2800 (epoch 7), train_loss = 11.245, time/batch = 0.016\n",
      "441/2800 (epoch 7), train_loss = 10.922, time/batch = 0.000\n",
      "442/2800 (epoch 7), train_loss = 10.473, time/batch = 0.016\n",
      "443/2800 (epoch 7), train_loss = 11.248, time/batch = 0.018\n",
      "444/2800 (epoch 7), train_loss = 10.668, time/batch = 0.004\n",
      "445/2800 (epoch 7), train_loss = 10.313, time/batch = 0.016\n",
      "446/2800 (epoch 7), train_loss = 10.520, time/batch = 0.000\n",
      "447/2800 (epoch 7), train_loss = 10.103, time/batch = 0.016\n",
      "448/2800 (epoch 8), train_loss = 10.562, time/batch = 0.016\n",
      "449/2800 (epoch 8), train_loss = 9.665, time/batch = 0.016\n",
      "450/2800 (epoch 8), train_loss = 11.117, time/batch = 0.016\n",
      "451/2800 (epoch 8), train_loss = 9.375, time/batch = 0.019\n",
      "452/2800 (epoch 8), train_loss = 9.696, time/batch = 0.003\n",
      "453/2800 (epoch 8), train_loss = 9.452, time/batch = 0.016\n",
      "454/2800 (epoch 8), train_loss = 10.316, time/batch = 0.016\n",
      "455/2800 (epoch 8), train_loss = 9.183, time/batch = 0.000\n",
      "456/2800 (epoch 8), train_loss = 10.122, time/batch = 0.016\n",
      "457/2800 (epoch 8), train_loss = 9.338, time/batch = 0.016\n",
      "458/2800 (epoch 8), train_loss = 10.132, time/batch = 0.016\n",
      "459/2800 (epoch 8), train_loss = 9.327, time/batch = 0.018\n",
      "460/2800 (epoch 8), train_loss = 10.608, time/batch = 0.004\n",
      "461/2800 (epoch 8), train_loss = 9.176, time/batch = 0.016\n",
      "462/2800 (epoch 8), train_loss = 9.171, time/batch = 0.000\n",
      "463/2800 (epoch 8), train_loss = 9.776, time/batch = 0.016\n",
      "464/2800 (epoch 8), train_loss = 9.857, time/batch = 0.016\n",
      "465/2800 (epoch 8), train_loss = 10.144, time/batch = 0.016\n",
      "466/2800 (epoch 8), train_loss = 9.975, time/batch = 0.016\n",
      "467/2800 (epoch 8), train_loss = 9.931, time/batch = 0.021\n",
      "468/2800 (epoch 8), train_loss = 9.673, time/batch = 0.001\n",
      "469/2800 (epoch 8), train_loss = 9.112, time/batch = 0.016\n",
      "470/2800 (epoch 8), train_loss = 9.996, time/batch = 0.016\n",
      "471/2800 (epoch 8), train_loss = 10.292, time/batch = 0.016\n",
      "472/2800 (epoch 8), train_loss = 9.968, time/batch = 0.000\n",
      "473/2800 (epoch 8), train_loss = 9.385, time/batch = 0.016\n",
      "474/2800 (epoch 8), train_loss = 9.369, time/batch = 0.016\n",
      "475/2800 (epoch 8), train_loss = 11.399, time/batch = 0.000\n",
      "476/2800 (epoch 8), train_loss = 9.302, time/batch = 0.022\n",
      "477/2800 (epoch 8), train_loss = 10.962, time/batch = 0.000\n",
      "478/2800 (epoch 8), train_loss = 9.236, time/batch = 0.016\n",
      "479/2800 (epoch 8), train_loss = 11.071, time/batch = 0.016\n",
      "480/2800 (epoch 8), train_loss = 9.180, time/batch = 0.016\n",
      "481/2800 (epoch 8), train_loss = 11.028, time/batch = 0.016\n",
      "482/2800 (epoch 8), train_loss = 12.002, time/batch = 0.016\n",
      "483/2800 (epoch 8), train_loss = 10.981, time/batch = 0.000\n",
      "484/2800 (epoch 8), train_loss = 11.720, time/batch = 0.022\n",
      "485/2800 (epoch 8), train_loss = 10.789, time/batch = 0.016\n",
      "486/2800 (epoch 8), train_loss = 10.916, time/batch = 0.000\n",
      "487/2800 (epoch 8), train_loss = 10.503, time/batch = 0.016\n",
      "488/2800 (epoch 8), train_loss = 10.939, time/batch = 0.016\n",
      "489/2800 (epoch 8), train_loss = 10.380, time/batch = 0.016\n",
      "490/2800 (epoch 8), train_loss = 11.093, time/batch = 0.016\n",
      "491/2800 (epoch 8), train_loss = 10.398, time/batch = 0.020\n",
      "492/2800 (epoch 8), train_loss = 11.358, time/batch = 0.003\n",
      "493/2800 (epoch 8), train_loss = 10.439, time/batch = 0.000\n",
      "494/2800 (epoch 8), train_loss = 11.473, time/batch = 0.016\n",
      "495/2800 (epoch 8), train_loss = 10.239, time/batch = 0.027\n",
      "496/2800 (epoch 8), train_loss = 11.212, time/batch = 0.016\n",
      "497/2800 (epoch 8), train_loss = 10.187, time/batch = 0.025\n",
      "498/2800 (epoch 8), train_loss = 11.383, time/batch = 0.002\n",
      "499/2800 (epoch 8), train_loss = 10.059, time/batch = 0.000\n",
      "500/2800 (epoch 8), train_loss = 10.828, time/batch = 0.016\n",
      "model saved to save\\model.ckpt\n",
      "501/2800 (epoch 8), train_loss = 10.163, time/batch = 0.015\n",
      "502/2800 (epoch 8), train_loss = 10.035, time/batch = 0.014\n",
      "503/2800 (epoch 8), train_loss = 9.676, time/batch = 0.015\n",
      "504/2800 (epoch 9), train_loss = 9.690, time/batch = 0.014\n",
      "505/2800 (epoch 9), train_loss = 9.329, time/batch = 0.013\n",
      "506/2800 (epoch 9), train_loss = 9.688, time/batch = 0.014\n",
      "507/2800 (epoch 9), train_loss = 10.341, time/batch = 0.014\n",
      "508/2800 (epoch 9), train_loss = 9.283, time/batch = 0.005\n",
      "509/2800 (epoch 9), train_loss = 10.127, time/batch = 0.016\n",
      "510/2800 (epoch 9), train_loss = 9.237, time/batch = 0.016\n",
      "511/2800 (epoch 9), train_loss = 10.997, time/batch = 0.000\n",
      "512/2800 (epoch 9), train_loss = 9.913, time/batch = 0.016\n",
      "513/2800 (epoch 9), train_loss = 10.508, time/batch = 0.016\n",
      "514/2800 (epoch 9), train_loss = 9.344, time/batch = 0.016\n",
      "515/2800 (epoch 9), train_loss = 10.037, time/batch = 0.000\n",
      "516/2800 (epoch 9), train_loss = 9.184, time/batch = 0.022\n",
      "517/2800 (epoch 9), train_loss = 9.888, time/batch = 0.016\n",
      "518/2800 (epoch 9), train_loss = 9.040, time/batch = 0.016\n",
      "519/2800 (epoch 9), train_loss = 10.443, time/batch = 0.016\n",
      "520/2800 (epoch 9), train_loss = 9.580, time/batch = 0.016\n",
      "521/2800 (epoch 9), train_loss = 9.776, time/batch = 0.016\n",
      "522/2800 (epoch 9), train_loss = 9.090, time/batch = 0.023\n",
      "523/2800 (epoch 9), train_loss = 10.735, time/batch = 0.018\n",
      "524/2800 (epoch 9), train_loss = 9.313, time/batch = 0.015\n",
      "525/2800 (epoch 9), train_loss = 10.095, time/batch = 0.016\n",
      "526/2800 (epoch 9), train_loss = 9.631, time/batch = 0.016\n",
      "527/2800 (epoch 9), train_loss = 10.132, time/batch = 0.016\n",
      "528/2800 (epoch 9), train_loss = 10.121, time/batch = 0.015\n",
      "529/2800 (epoch 9), train_loss = 9.670, time/batch = 0.014\n",
      "530/2800 (epoch 9), train_loss = 10.102, time/batch = 0.009\n",
      "531/2800 (epoch 9), train_loss = 9.771, time/batch = 0.031\n",
      "532/2800 (epoch 9), train_loss = 9.710, time/batch = 0.016\n",
      "533/2800 (epoch 9), train_loss = 9.641, time/batch = 0.016\n",
      "534/2800 (epoch 9), train_loss = 10.058, time/batch = 0.000\n",
      "535/2800 (epoch 9), train_loss = 10.387, time/batch = 0.016\n",
      "536/2800 (epoch 9), train_loss = 9.919, time/batch = 0.022\n",
      "537/2800 (epoch 9), train_loss = 9.647, time/batch = 0.016\n",
      "538/2800 (epoch 9), train_loss = 9.375, time/batch = 0.016\n",
      "539/2800 (epoch 9), train_loss = 9.695, time/batch = 0.016\n",
      "540/2800 (epoch 9), train_loss = 9.522, time/batch = 0.016\n",
      "541/2800 (epoch 9), train_loss = 12.389, time/batch = 0.016\n",
      "542/2800 (epoch 9), train_loss = 11.731, time/batch = 0.019\n",
      "543/2800 (epoch 9), train_loss = 11.073, time/batch = 0.019\n",
      "544/2800 (epoch 9), train_loss = 11.218, time/batch = 0.016\n",
      "545/2800 (epoch 9), train_loss = 10.881, time/batch = 0.016\n",
      "546/2800 (epoch 9), train_loss = 10.606, time/batch = 0.016\n",
      "547/2800 (epoch 9), train_loss = 10.616, time/batch = 0.034\n",
      "548/2800 (epoch 9), train_loss = 10.780, time/batch = 0.018\n",
      "549/2800 (epoch 9), train_loss = 10.631, time/batch = 0.017\n",
      "550/2800 (epoch 9), train_loss = 10.468, time/batch = 0.015\n",
      "551/2800 (epoch 9), train_loss = 11.041, time/batch = 0.016\n",
      "552/2800 (epoch 9), train_loss = 10.565, time/batch = 0.014\n",
      "553/2800 (epoch 9), train_loss = 10.252, time/batch = 0.019\n",
      "554/2800 (epoch 9), train_loss = 12.015, time/batch = 0.016\n",
      "555/2800 (epoch 9), train_loss = 10.509, time/batch = 0.019\n",
      "556/2800 (epoch 9), train_loss = 10.255, time/batch = 0.016\n",
      "557/2800 (epoch 9), train_loss = 10.367, time/batch = 0.019\n",
      "558/2800 (epoch 9), train_loss = 9.939, time/batch = 0.014\n",
      "559/2800 (epoch 9), train_loss = 12.120, time/batch = 0.013\n",
      "560/2800 (epoch 10), train_loss = 9.671, time/batch = 0.004\n",
      "561/2800 (epoch 10), train_loss = 9.550, time/batch = 0.016\n",
      "562/2800 (epoch 10), train_loss = 9.522, time/batch = 0.000\n",
      "563/2800 (epoch 10), train_loss = 10.402, time/batch = 0.000\n",
      "564/2800 (epoch 10), train_loss = 9.299, time/batch = 0.016\n",
      "565/2800 (epoch 10), train_loss = 9.139, time/batch = 0.016\n",
      "566/2800 (epoch 10), train_loss = 11.123, time/batch = 0.000\n",
      "567/2800 (epoch 10), train_loss = 9.189, time/batch = 0.016\n",
      "568/2800 (epoch 10), train_loss = 10.595, time/batch = 0.022\n",
      "569/2800 (epoch 10), train_loss = 9.238, time/batch = 0.000\n",
      "570/2800 (epoch 10), train_loss = 10.869, time/batch = 0.016\n",
      "571/2800 (epoch 10), train_loss = 9.568, time/batch = 0.016\n",
      "572/2800 (epoch 10), train_loss = 9.755, time/batch = 0.016\n",
      "573/2800 (epoch 10), train_loss = 8.957, time/batch = 0.000\n",
      "574/2800 (epoch 10), train_loss = 10.574, time/batch = 0.016\n",
      "575/2800 (epoch 10), train_loss = 8.726, time/batch = 0.016\n",
      "576/2800 (epoch 10), train_loss = 11.307, time/batch = 0.022\n",
      "577/2800 (epoch 10), train_loss = 8.766, time/batch = 0.016\n",
      "578/2800 (epoch 10), train_loss = 11.429, time/batch = 0.000\n",
      "579/2800 (epoch 10), train_loss = 8.771, time/batch = 0.016\n",
      "580/2800 (epoch 10), train_loss = 10.828, time/batch = 0.016\n",
      "581/2800 (epoch 10), train_loss = 8.632, time/batch = 0.016\n",
      "582/2800 (epoch 10), train_loss = 12.429, time/batch = 0.000\n",
      "583/2800 (epoch 10), train_loss = 9.147, time/batch = 0.016\n",
      "584/2800 (epoch 10), train_loss = 9.757, time/batch = 0.021\n",
      "585/2800 (epoch 10), train_loss = 9.661, time/batch = 0.000\n",
      "586/2800 (epoch 10), train_loss = 9.765, time/batch = 0.016\n",
      "587/2800 (epoch 10), train_loss = 9.834, time/batch = 0.016\n",
      "588/2800 (epoch 10), train_loss = 9.538, time/batch = 0.000\n",
      "589/2800 (epoch 10), train_loss = 9.988, time/batch = 0.016\n",
      "590/2800 (epoch 10), train_loss = 9.378, time/batch = 0.016\n",
      "591/2800 (epoch 10), train_loss = 10.494, time/batch = 0.016\n",
      "592/2800 (epoch 10), train_loss = 10.254, time/batch = 0.022\n",
      "593/2800 (epoch 10), train_loss = 9.784, time/batch = 0.016\n",
      "594/2800 (epoch 10), train_loss = 9.708, time/batch = 0.000\n",
      "595/2800 (epoch 10), train_loss = 9.673, time/batch = 0.016\n",
      "596/2800 (epoch 10), train_loss = 9.452, time/batch = 0.016\n",
      "597/2800 (epoch 10), train_loss = 10.032, time/batch = 0.016\n",
      "598/2800 (epoch 10), train_loss = 12.168, time/batch = 0.000\n",
      "599/2800 (epoch 10), train_loss = 11.282, time/batch = 0.016\n",
      "600/2800 (epoch 10), train_loss = 11.515, time/batch = 0.019\n",
      "601/2800 (epoch 10), train_loss = 10.811, time/batch = 0.002\n",
      "602/2800 (epoch 10), train_loss = 10.818, time/batch = 0.016\n",
      "603/2800 (epoch 10), train_loss = 10.623, time/batch = 0.016\n",
      "604/2800 (epoch 10), train_loss = 10.671, time/batch = 0.000\n",
      "605/2800 (epoch 10), train_loss = 10.759, time/batch = 0.016\n",
      "606/2800 (epoch 10), train_loss = 10.951, time/batch = 0.016\n",
      "607/2800 (epoch 10), train_loss = 10.432, time/batch = 0.016\n",
      "608/2800 (epoch 10), train_loss = 10.564, time/batch = 0.020\n",
      "609/2800 (epoch 10), train_loss = 10.268, time/batch = 0.002\n",
      "610/2800 (epoch 10), train_loss = 12.131, time/batch = 0.016\n",
      "611/2800 (epoch 10), train_loss = 10.357, time/batch = 0.016\n",
      "612/2800 (epoch 10), train_loss = 11.341, time/batch = 0.000\n",
      "613/2800 (epoch 10), train_loss = 10.754, time/batch = 0.016\n",
      "614/2800 (epoch 10), train_loss = 10.361, time/batch = 0.016\n",
      "615/2800 (epoch 10), train_loss = 10.464, time/batch = 0.016\n",
      "616/2800 (epoch 11), train_loss = 9.970, time/batch = 0.000\n",
      "617/2800 (epoch 11), train_loss = 9.513, time/batch = 0.022\n",
      "618/2800 (epoch 11), train_loss = 9.621, time/batch = 0.000\n",
      "619/2800 (epoch 11), train_loss = 9.940, time/batch = 0.016\n",
      "620/2800 (epoch 11), train_loss = 9.444, time/batch = 0.016\n",
      "621/2800 (epoch 11), train_loss = 10.373, time/batch = 0.016\n",
      "622/2800 (epoch 11), train_loss = 9.207, time/batch = 0.016\n",
      "623/2800 (epoch 11), train_loss = 10.653, time/batch = 0.000\n",
      "624/2800 (epoch 11), train_loss = 9.774, time/batch = 0.016\n",
      "625/2800 (epoch 11), train_loss = 10.393, time/batch = 0.022\n",
      "626/2800 (epoch 11), train_loss = 9.510, time/batch = 0.000\n",
      "627/2800 (epoch 11), train_loss = 9.480, time/batch = 0.016\n",
      "628/2800 (epoch 11), train_loss = 9.725, time/batch = 0.016\n",
      "629/2800 (epoch 11), train_loss = 9.534, time/batch = 0.016\n",
      "630/2800 (epoch 11), train_loss = 9.319, time/batch = 0.000\n",
      "631/2800 (epoch 11), train_loss = 9.655, time/batch = 0.016\n",
      "632/2800 (epoch 11), train_loss = 9.436, time/batch = 0.016\n",
      "633/2800 (epoch 11), train_loss = 9.571, time/batch = 0.017\n",
      "634/2800 (epoch 11), train_loss = 9.646, time/batch = 0.006\n",
      "635/2800 (epoch 11), train_loss = 9.777, time/batch = 0.016\n",
      "636/2800 (epoch 11), train_loss = 9.445, time/batch = 0.000\n",
      "637/2800 (epoch 11), train_loss = 10.129, time/batch = 0.016\n",
      "638/2800 (epoch 11), train_loss = 9.695, time/batch = 0.016\n",
      "639/2800 (epoch 11), train_loss = 9.778, time/batch = 0.016\n",
      "640/2800 (epoch 11), train_loss = 9.814, time/batch = 0.016\n",
      "641/2800 (epoch 11), train_loss = 9.962, time/batch = 0.000\n",
      "642/2800 (epoch 11), train_loss = 10.109, time/batch = 0.006\n",
      "643/2800 (epoch 11), train_loss = 9.652, time/batch = 0.016\n",
      "644/2800 (epoch 11), train_loss = 9.524, time/batch = 0.000\n",
      "645/2800 (epoch 11), train_loss = 9.801, time/batch = 0.016\n",
      "646/2800 (epoch 11), train_loss = 9.733, time/batch = 0.016\n",
      "647/2800 (epoch 11), train_loss = 9.850, time/batch = 0.016\n",
      "648/2800 (epoch 11), train_loss = 9.945, time/batch = 0.000\n",
      "649/2800 (epoch 11), train_loss = 9.637, time/batch = 0.016\n",
      "650/2800 (epoch 11), train_loss = 9.949, time/batch = 0.021\n",
      "651/2800 (epoch 11), train_loss = 9.602, time/batch = 0.001\n",
      "652/2800 (epoch 11), train_loss = 9.397, time/batch = 0.016\n",
      "653/2800 (epoch 11), train_loss = 10.011, time/batch = 0.016\n",
      "654/2800 (epoch 11), train_loss = 11.888, time/batch = 0.000\n",
      "655/2800 (epoch 11), train_loss = 10.944, time/batch = 0.016\n",
      "656/2800 (epoch 11), train_loss = 11.181, time/batch = 0.016\n",
      "657/2800 (epoch 11), train_loss = 11.072, time/batch = 0.016\n",
      "658/2800 (epoch 11), train_loss = 10.983, time/batch = 0.020\n",
      "659/2800 (epoch 11), train_loss = 10.438, time/batch = 0.003\n",
      "660/2800 (epoch 11), train_loss = 10.852, time/batch = 0.016\n",
      "661/2800 (epoch 11), train_loss = 10.457, time/batch = 0.016\n",
      "662/2800 (epoch 11), train_loss = 10.924, time/batch = 0.000\n",
      "663/2800 (epoch 11), train_loss = 10.534, time/batch = 0.016\n",
      "664/2800 (epoch 11), train_loss = 11.059, time/batch = 0.016\n",
      "665/2800 (epoch 11), train_loss = 10.607, time/batch = 0.016\n",
      "666/2800 (epoch 11), train_loss = 10.291, time/batch = 0.000\n",
      "667/2800 (epoch 11), train_loss = 11.311, time/batch = 0.022\n",
      "668/2800 (epoch 11), train_loss = 10.575, time/batch = 0.000\n",
      "669/2800 (epoch 11), train_loss = 10.569, time/batch = 0.000\n",
      "670/2800 (epoch 11), train_loss = 10.780, time/batch = 0.016\n",
      "671/2800 (epoch 11), train_loss = 10.057, time/batch = 0.016\n",
      "672/2800 (epoch 12), train_loss = 9.782, time/batch = 0.016\n",
      "673/2800 (epoch 12), train_loss = 9.843, time/batch = 0.000\n",
      "674/2800 (epoch 12), train_loss = 9.465, time/batch = 0.000\n",
      "675/2800 (epoch 12), train_loss = 11.205, time/batch = 0.022\n",
      "676/2800 (epoch 12), train_loss = 9.246, time/batch = 0.016\n",
      "677/2800 (epoch 12), train_loss = 9.861, time/batch = 0.000\n",
      "678/2800 (epoch 12), train_loss = 9.127, time/batch = 0.016\n",
      "679/2800 (epoch 12), train_loss = 10.928, time/batch = 0.016\n",
      "680/2800 (epoch 12), train_loss = 9.349, time/batch = 0.016\n",
      "681/2800 (epoch 12), train_loss = 10.582, time/batch = 0.000\n",
      "682/2800 (epoch 12), train_loss = 9.367, time/batch = 0.016\n",
      "683/2800 (epoch 12), train_loss = 10.482, time/batch = 0.020\n",
      "684/2800 (epoch 12), train_loss = 9.554, time/batch = 0.002\n",
      "685/2800 (epoch 12), train_loss = 9.698, time/batch = 0.016\n",
      "686/2800 (epoch 12), train_loss = 9.163, time/batch = 0.016\n",
      "687/2800 (epoch 12), train_loss = 9.931, time/batch = 0.000\n",
      "688/2800 (epoch 12), train_loss = 9.188, time/batch = 0.016\n",
      "689/2800 (epoch 12), train_loss = 10.037, time/batch = 0.016\n",
      "690/2800 (epoch 12), train_loss = 9.266, time/batch = 0.016\n",
      "691/2800 (epoch 12), train_loss = 10.107, time/batch = 0.019\n",
      "692/2800 (epoch 12), train_loss = 9.181, time/batch = 0.004\n",
      "693/2800 (epoch 12), train_loss = 9.997, time/batch = 0.016\n",
      "694/2800 (epoch 12), train_loss = 9.044, time/batch = 0.016\n",
      "695/2800 (epoch 12), train_loss = 10.118, time/batch = 0.000\n",
      "696/2800 (epoch 12), train_loss = 9.578, time/batch = 0.016\n",
      "697/2800 (epoch 12), train_loss = 10.179, time/batch = 0.016\n",
      "698/2800 (epoch 12), train_loss = 9.265, time/batch = 0.016\n",
      "699/2800 (epoch 12), train_loss = 10.227, time/batch = 0.019\n",
      "700/2800 (epoch 12), train_loss = 9.213, time/batch = 0.003\n",
      "701/2800 (epoch 12), train_loss = 10.685, time/batch = 0.016\n",
      "702/2800 (epoch 12), train_loss = 9.457, time/batch = 0.016\n",
      "703/2800 (epoch 12), train_loss = 10.604, time/batch = 0.031\n",
      "704/2800 (epoch 12), train_loss = 9.727, time/batch = 0.016\n",
      "705/2800 (epoch 12), train_loss = 10.415, time/batch = 0.007\n",
      "706/2800 (epoch 12), train_loss = 9.479, time/batch = 0.016\n",
      "707/2800 (epoch 12), train_loss = 9.996, time/batch = 0.016\n",
      "708/2800 (epoch 12), train_loss = 9.305, time/batch = 0.016\n",
      "709/2800 (epoch 12), train_loss = 9.997, time/batch = 0.016\n",
      "710/2800 (epoch 12), train_loss = 10.856, time/batch = 0.016\n",
      "711/2800 (epoch 12), train_loss = 11.873, time/batch = 0.022\n",
      "712/2800 (epoch 12), train_loss = 10.928, time/batch = 0.016\n",
      "713/2800 (epoch 12), train_loss = 10.821, time/batch = 0.000\n",
      "714/2800 (epoch 12), train_loss = 10.759, time/batch = 0.016\n",
      "715/2800 (epoch 12), train_loss = 10.679, time/batch = 0.016\n",
      "716/2800 (epoch 12), train_loss = 10.616, time/batch = 0.016\n",
      "717/2800 (epoch 12), train_loss = 10.611, time/batch = 0.032\n",
      "718/2800 (epoch 12), train_loss = 10.681, time/batch = 0.016\n",
      "719/2800 (epoch 12), train_loss = 10.525, time/batch = 0.017\n",
      "720/2800 (epoch 12), train_loss = 10.695, time/batch = 0.017\n",
      "721/2800 (epoch 12), train_loss = 10.894, time/batch = 0.014\n",
      "722/2800 (epoch 12), train_loss = 10.900, time/batch = 0.014\n",
      "723/2800 (epoch 12), train_loss = 10.172, time/batch = 0.013\n",
      "724/2800 (epoch 12), train_loss = 12.045, time/batch = 0.005\n",
      "725/2800 (epoch 12), train_loss = 10.731, time/batch = 0.016\n",
      "726/2800 (epoch 12), train_loss = 10.438, time/batch = 0.016\n",
      "727/2800 (epoch 12), train_loss = 10.910, time/batch = 0.016\n",
      "728/2800 (epoch 13), train_loss = 9.957, time/batch = 0.000\n",
      "729/2800 (epoch 13), train_loss = 10.045, time/batch = 0.016\n",
      "730/2800 (epoch 13), train_loss = 9.688, time/batch = 0.016\n",
      "731/2800 (epoch 13), train_loss = 10.722, time/batch = 0.018\n",
      "732/2800 (epoch 13), train_loss = 9.249, time/batch = 0.004\n",
      "733/2800 (epoch 13), train_loss = 10.263, time/batch = 0.016\n",
      "734/2800 (epoch 13), train_loss = 9.141, time/batch = 0.016\n",
      "735/2800 (epoch 13), train_loss = 11.360, time/batch = 0.016\n",
      "736/2800 (epoch 13), train_loss = 9.129, time/batch = 0.016\n",
      "737/2800 (epoch 13), train_loss = 11.621, time/batch = 0.000\n",
      "738/2800 (epoch 13), train_loss = 8.967, time/batch = 0.016\n",
      "739/2800 (epoch 13), train_loss = 11.631, time/batch = 0.020\n",
      "740/2800 (epoch 13), train_loss = 9.026, time/batch = 0.002\n",
      "741/2800 (epoch 13), train_loss = 10.274, time/batch = 0.016\n",
      "742/2800 (epoch 13), train_loss = 10.055, time/batch = 0.016\n",
      "743/2800 (epoch 13), train_loss = 9.997, time/batch = 0.000\n",
      "744/2800 (epoch 13), train_loss = 9.373, time/batch = 0.016\n",
      "745/2800 (epoch 13), train_loss = 9.608, time/batch = 0.016\n",
      "746/2800 (epoch 13), train_loss = 9.387, time/batch = 0.000\n",
      "747/2800 (epoch 13), train_loss = 9.490, time/batch = 0.016\n",
      "748/2800 (epoch 13), train_loss = 9.355, time/batch = 0.022\n",
      "749/2800 (epoch 13), train_loss = 9.284, time/batch = 0.016\n",
      "750/2800 (epoch 13), train_loss = 9.647, time/batch = 0.016\n",
      "751/2800 (epoch 13), train_loss = 10.420, time/batch = 0.016\n",
      "752/2800 (epoch 13), train_loss = 9.984, time/batch = 0.016\n",
      "753/2800 (epoch 13), train_loss = 9.903, time/batch = 0.016\n",
      "754/2800 (epoch 13), train_loss = 10.010, time/batch = 0.017\n",
      "755/2800 (epoch 13), train_loss = 9.578, time/batch = 0.006\n",
      "756/2800 (epoch 13), train_loss = 9.743, time/batch = 0.016\n",
      "757/2800 (epoch 13), train_loss = 9.806, time/batch = 0.016\n",
      "758/2800 (epoch 13), train_loss = 10.290, time/batch = 0.016\n",
      "759/2800 (epoch 13), train_loss = 9.489, time/batch = 0.016\n",
      "760/2800 (epoch 13), train_loss = 9.838, time/batch = 0.016\n",
      "761/2800 (epoch 13), train_loss = 9.792, time/batch = 0.022\n",
      "762/2800 (epoch 13), train_loss = 9.619, time/batch = 0.016\n",
      "763/2800 (epoch 13), train_loss = 10.274, time/batch = 0.016\n",
      "764/2800 (epoch 13), train_loss = 11.634, time/batch = 0.016\n",
      "765/2800 (epoch 13), train_loss = 11.261, time/batch = 0.016\n",
      "766/2800 (epoch 13), train_loss = 11.250, time/batch = 0.016\n",
      "767/2800 (epoch 13), train_loss = 11.112, time/batch = 0.022\n",
      "768/2800 (epoch 13), train_loss = 10.743, time/batch = 0.000\n",
      "769/2800 (epoch 13), train_loss = 10.668, time/batch = 0.016\n",
      "770/2800 (epoch 13), train_loss = 10.746, time/batch = 0.016\n",
      "771/2800 (epoch 13), train_loss = 10.605, time/batch = 0.016\n",
      "772/2800 (epoch 13), train_loss = 11.072, time/batch = 0.016\n",
      "773/2800 (epoch 13), train_loss = 10.340, time/batch = 0.016\n",
      "774/2800 (epoch 13), train_loss = 10.810, time/batch = 0.020\n",
      "775/2800 (epoch 13), train_loss = 10.976, time/batch = 0.002\n",
      "776/2800 (epoch 13), train_loss = 10.410, time/batch = 0.016\n",
      "777/2800 (epoch 13), train_loss = 11.148, time/batch = 0.016\n",
      "778/2800 (epoch 13), train_loss = 11.099, time/batch = 0.016\n",
      "779/2800 (epoch 13), train_loss = 10.119, time/batch = 0.016\n",
      "780/2800 (epoch 13), train_loss = 10.332, time/batch = 0.016\n",
      "781/2800 (epoch 13), train_loss = 11.264, time/batch = 0.016\n",
      "782/2800 (epoch 13), train_loss = 10.132, time/batch = 0.007\n",
      "783/2800 (epoch 13), train_loss = 11.188, time/batch = 0.016\n",
      "784/2800 (epoch 14), train_loss = 9.800, time/batch = 0.016\n",
      "785/2800 (epoch 14), train_loss = 10.330, time/batch = 0.016\n",
      "786/2800 (epoch 14), train_loss = 9.450, time/batch = 0.016\n",
      "787/2800 (epoch 14), train_loss = 9.704, time/batch = 0.016\n",
      "788/2800 (epoch 14), train_loss = 10.044, time/batch = 0.022\n",
      "789/2800 (epoch 14), train_loss = 9.065, time/batch = 0.016\n",
      "790/2800 (epoch 14), train_loss = 10.334, time/batch = 0.016\n",
      "791/2800 (epoch 14), train_loss = 9.250, time/batch = 0.016\n",
      "792/2800 (epoch 14), train_loss = 10.404, time/batch = 0.016\n",
      "793/2800 (epoch 14), train_loss = 9.062, time/batch = 0.016\n",
      "794/2800 (epoch 14), train_loss = 10.624, time/batch = 0.024\n",
      "795/2800 (epoch 14), train_loss = 9.702, time/batch = 0.013\n",
      "796/2800 (epoch 14), train_loss = 9.558, time/batch = 0.013\n",
      "797/2800 (epoch 14), train_loss = 8.840, time/batch = 0.015\n",
      "798/2800 (epoch 14), train_loss = 10.323, time/batch = 0.014\n",
      "799/2800 (epoch 14), train_loss = 8.557, time/batch = 0.011\n",
      "800/2800 (epoch 14), train_loss = 13.716, time/batch = 0.012\n",
      "801/2800 (epoch 14), train_loss = 8.575, time/batch = 0.013\n",
      "802/2800 (epoch 14), train_loss = 11.668, time/batch = 0.011\n",
      "803/2800 (epoch 14), train_loss = 8.728, time/batch = 0.012\n",
      "804/2800 (epoch 14), train_loss = 11.266, time/batch = 0.001\n",
      "805/2800 (epoch 14), train_loss = 8.494, time/batch = 0.016\n",
      "806/2800 (epoch 14), train_loss = 11.778, time/batch = 0.016\n",
      "807/2800 (epoch 14), train_loss = 8.908, time/batch = 0.016\n",
      "808/2800 (epoch 14), train_loss = 10.025, time/batch = 0.016\n",
      "809/2800 (epoch 14), train_loss = 9.598, time/batch = 0.016\n",
      "810/2800 (epoch 14), train_loss = 10.831, time/batch = 0.022\n",
      "811/2800 (epoch 14), train_loss = 9.880, time/batch = 0.016\n",
      "812/2800 (epoch 14), train_loss = 9.965, time/batch = 0.016\n",
      "813/2800 (epoch 14), train_loss = 9.400, time/batch = 0.016\n",
      "814/2800 (epoch 14), train_loss = 10.655, time/batch = 0.016\n",
      "815/2800 (epoch 14), train_loss = 9.608, time/batch = 0.016\n",
      "816/2800 (epoch 14), train_loss = 9.966, time/batch = 0.000\n",
      "817/2800 (epoch 14), train_loss = 9.512, time/batch = 0.007\n",
      "818/2800 (epoch 14), train_loss = 10.054, time/batch = 0.016\n",
      "819/2800 (epoch 14), train_loss = 9.516, time/batch = 0.031\n",
      "820/2800 (epoch 14), train_loss = 12.112, time/batch = 0.016\n",
      "821/2800 (epoch 14), train_loss = 11.206, time/batch = 0.016\n",
      "822/2800 (epoch 14), train_loss = 11.178, time/batch = 0.022\n",
      "823/2800 (epoch 14), train_loss = 11.137, time/batch = 0.016\n",
      "824/2800 (epoch 14), train_loss = 10.834, time/batch = 0.000\n",
      "825/2800 (epoch 14), train_loss = 10.648, time/batch = 0.016\n",
      "826/2800 (epoch 14), train_loss = 10.695, time/batch = 0.016\n",
      "827/2800 (epoch 14), train_loss = 10.687, time/batch = 0.016\n",
      "828/2800 (epoch 14), train_loss = 10.503, time/batch = 0.000\n",
      "829/2800 (epoch 14), train_loss = 10.885, time/batch = 0.016\n",
      "830/2800 (epoch 14), train_loss = 10.633, time/batch = 0.022\n",
      "831/2800 (epoch 14), train_loss = 10.605, time/batch = 0.000\n",
      "832/2800 (epoch 14), train_loss = 10.355, time/batch = 0.016\n",
      "833/2800 (epoch 14), train_loss = 11.056, time/batch = 0.016\n",
      "834/2800 (epoch 14), train_loss = 10.677, time/batch = 0.016\n",
      "835/2800 (epoch 14), train_loss = 10.428, time/batch = 0.016\n",
      "836/2800 (epoch 14), train_loss = 10.481, time/batch = 0.016\n",
      "837/2800 (epoch 14), train_loss = 9.841, time/batch = 0.018\n",
      "838/2800 (epoch 14), train_loss = 10.074, time/batch = 0.004\n",
      "839/2800 (epoch 14), train_loss = 10.991, time/batch = 0.016\n",
      "840/2800 (epoch 15), train_loss = 9.688, time/batch = 0.016\n",
      "841/2800 (epoch 15), train_loss = 9.470, time/batch = 0.000\n",
      "842/2800 (epoch 15), train_loss = 10.033, time/batch = 0.016\n",
      "843/2800 (epoch 15), train_loss = 9.413, time/batch = 0.016\n",
      "844/2800 (epoch 15), train_loss = 10.899, time/batch = 0.016\n",
      "845/2800 (epoch 15), train_loss = 9.195, time/batch = 0.000\n",
      "846/2800 (epoch 15), train_loss = 10.600, time/batch = 0.022\n",
      "847/2800 (epoch 15), train_loss = 9.076, time/batch = 0.000\n",
      "848/2800 (epoch 15), train_loss = 10.579, time/batch = 0.016\n",
      "849/2800 (epoch 15), train_loss = 9.203, time/batch = 0.016\n",
      "850/2800 (epoch 15), train_loss = 10.529, time/batch = 0.016\n",
      "851/2800 (epoch 15), train_loss = 9.034, time/batch = 0.016\n",
      "852/2800 (epoch 15), train_loss = 10.194, time/batch = 0.016\n",
      "853/2800 (epoch 15), train_loss = 8.947, time/batch = 0.018\n",
      "854/2800 (epoch 15), train_loss = 9.552, time/batch = 0.004\n",
      "855/2800 (epoch 15), train_loss = 11.413, time/batch = 0.016\n",
      "856/2800 (epoch 15), train_loss = 9.159, time/batch = 0.016\n",
      "857/2800 (epoch 15), train_loss = 9.965, time/batch = 0.000\n",
      "858/2800 (epoch 15), train_loss = 9.204, time/batch = 0.016\n",
      "859/2800 (epoch 15), train_loss = 9.889, time/batch = 0.016\n",
      "860/2800 (epoch 15), train_loss = 9.055, time/batch = 0.016\n",
      "861/2800 (epoch 15), train_loss = 10.522, time/batch = 0.000\n",
      "862/2800 (epoch 15), train_loss = 9.423, time/batch = 0.022\n",
      "863/2800 (epoch 15), train_loss = 9.588, time/batch = 0.000\n",
      "864/2800 (epoch 15), train_loss = 9.812, time/batch = 0.016\n",
      "865/2800 (epoch 15), train_loss = 10.203, time/batch = 0.016\n",
      "866/2800 (epoch 15), train_loss = 9.898, time/batch = 0.016\n",
      "867/2800 (epoch 15), train_loss = 9.757, time/batch = 0.016\n",
      "868/2800 (epoch 15), train_loss = 9.839, time/batch = 0.016\n",
      "869/2800 (epoch 15), train_loss = 9.700, time/batch = 0.000\n",
      "870/2800 (epoch 15), train_loss = 9.555, time/batch = 0.022\n",
      "871/2800 (epoch 15), train_loss = 9.800, time/batch = 0.016\n",
      "872/2800 (epoch 15), train_loss = 9.485, time/batch = 0.000\n",
      "873/2800 (epoch 15), train_loss = 9.588, time/batch = 0.016\n",
      "874/2800 (epoch 15), train_loss = 9.649, time/batch = 0.016\n",
      "875/2800 (epoch 15), train_loss = 11.680, time/batch = 0.000\n",
      "876/2800 (epoch 15), train_loss = 11.350, time/batch = 0.016\n",
      "877/2800 (epoch 15), train_loss = 10.984, time/batch = 0.016\n",
      "878/2800 (epoch 15), train_loss = 11.103, time/batch = 0.019\n",
      "879/2800 (epoch 15), train_loss = 10.644, time/batch = 0.003\n",
      "880/2800 (epoch 15), train_loss = 10.845, time/batch = 0.016\n",
      "881/2800 (epoch 15), train_loss = 10.558, time/batch = 0.016\n",
      "882/2800 (epoch 15), train_loss = 10.805, time/batch = 0.000\n",
      "883/2800 (epoch 15), train_loss = 10.686, time/batch = 0.016\n",
      "884/2800 (epoch 15), train_loss = 10.741, time/batch = 0.016\n",
      "885/2800 (epoch 15), train_loss = 10.524, time/batch = 0.016\n",
      "886/2800 (epoch 15), train_loss = 11.831, time/batch = 0.020\n",
      "887/2800 (epoch 15), train_loss = 10.306, time/batch = 0.002\n",
      "888/2800 (epoch 15), train_loss = 11.022, time/batch = 0.016\n",
      "889/2800 (epoch 15), train_loss = 10.315, time/batch = 0.016\n",
      "890/2800 (epoch 15), train_loss = 10.482, time/batch = 0.000\n",
      "891/2800 (epoch 15), train_loss = 10.740, time/batch = 0.016\n",
      "892/2800 (epoch 15), train_loss = 10.484, time/batch = 0.016\n",
      "893/2800 (epoch 15), train_loss = 10.538, time/batch = 0.016\n",
      "894/2800 (epoch 15), train_loss = 10.305, time/batch = 0.000\n",
      "895/2800 (epoch 15), train_loss = 9.948, time/batch = 0.022\n",
      "896/2800 (epoch 16), train_loss = 9.654, time/batch = 0.000\n",
      "897/2800 (epoch 16), train_loss = 9.796, time/batch = 0.016\n",
      "898/2800 (epoch 16), train_loss = 10.063, time/batch = 0.016\n",
      "899/2800 (epoch 16), train_loss = 9.436, time/batch = 0.016\n",
      "900/2800 (epoch 16), train_loss = 10.374, time/batch = 0.016\n",
      "901/2800 (epoch 16), train_loss = 9.357, time/batch = 0.016\n",
      "902/2800 (epoch 16), train_loss = 10.188, time/batch = 0.000\n",
      "903/2800 (epoch 16), train_loss = 9.152, time/batch = 0.022\n",
      "904/2800 (epoch 16), train_loss = 10.597, time/batch = 0.016\n",
      "905/2800 (epoch 16), train_loss = 9.071, time/batch = 0.000\n",
      "906/2800 (epoch 16), train_loss = 10.839, time/batch = 0.016\n",
      "907/2800 (epoch 16), train_loss = 8.899, time/batch = 0.016\n",
      "908/2800 (epoch 16), train_loss = 12.499, time/batch = 0.016\n",
      "909/2800 (epoch 16), train_loss = 9.208, time/batch = 0.000\n",
      "910/2800 (epoch 16), train_loss = 9.535, time/batch = 0.016\n",
      "911/2800 (epoch 16), train_loss = 9.292, time/batch = 0.021\n",
      "912/2800 (epoch 16), train_loss = 9.987, time/batch = 0.001\n",
      "913/2800 (epoch 16), train_loss = 9.114, time/batch = 0.016\n",
      "914/2800 (epoch 16), train_loss = 9.921, time/batch = 0.016\n",
      "915/2800 (epoch 16), train_loss = 9.201, time/batch = 0.016\n",
      "916/2800 (epoch 16), train_loss = 9.332, time/batch = 0.016\n",
      "917/2800 (epoch 16), train_loss = 9.972, time/batch = 0.000\n",
      "918/2800 (epoch 16), train_loss = 10.064, time/batch = 0.016\n",
      "919/2800 (epoch 16), train_loss = 10.339, time/batch = 0.023\n",
      "920/2800 (epoch 16), train_loss = 9.777, time/batch = 0.000\n",
      "921/2800 (epoch 16), train_loss = 10.352, time/batch = 0.016\n",
      "922/2800 (epoch 16), train_loss = 9.526, time/batch = 0.016\n",
      "923/2800 (epoch 16), train_loss = 10.100, time/batch = 0.016\n",
      "924/2800 (epoch 16), train_loss = 9.415, time/batch = 0.000\n",
      "925/2800 (epoch 16), train_loss = 10.123, time/batch = 0.016\n",
      "926/2800 (epoch 16), train_loss = 9.567, time/batch = 0.016\n",
      "927/2800 (epoch 16), train_loss = 9.549, time/batch = 0.017\n",
      "928/2800 (epoch 16), train_loss = 9.601, time/batch = 0.005\n",
      "929/2800 (epoch 16), train_loss = 9.979, time/batch = 0.016\n",
      "930/2800 (epoch 16), train_loss = 9.824, time/batch = 0.000\n",
      "931/2800 (epoch 16), train_loss = 11.100, time/batch = 0.016\n",
      "932/2800 (epoch 16), train_loss = 11.209, time/batch = 0.016\n",
      "933/2800 (epoch 16), train_loss = 11.259, time/batch = 0.016\n",
      "934/2800 (epoch 16), train_loss = 10.853, time/batch = 0.000\n",
      "935/2800 (epoch 16), train_loss = 10.851, time/batch = 0.007\n",
      "936/2800 (epoch 16), train_loss = 10.545, time/batch = 0.016\n",
      "937/2800 (epoch 16), train_loss = 10.903, time/batch = 0.000\n",
      "938/2800 (epoch 16), train_loss = 10.500, time/batch = 0.016\n",
      "939/2800 (epoch 16), train_loss = 11.255, time/batch = 0.016\n",
      "940/2800 (epoch 16), train_loss = 10.568, time/batch = 0.016\n",
      "941/2800 (epoch 16), train_loss = 10.913, time/batch = 0.000\n",
      "942/2800 (epoch 16), train_loss = 10.696, time/batch = 0.016\n",
      "943/2800 (epoch 16), train_loss = 11.146, time/batch = 0.022\n",
      "944/2800 (epoch 16), train_loss = 10.529, time/batch = 0.000\n",
      "945/2800 (epoch 16), train_loss = 11.224, time/batch = 0.016\n",
      "946/2800 (epoch 16), train_loss = 10.976, time/batch = 0.016\n",
      "947/2800 (epoch 16), train_loss = 10.349, time/batch = 0.000\n",
      "948/2800 (epoch 16), train_loss = 10.810, time/batch = 0.016\n",
      "949/2800 (epoch 16), train_loss = 9.954, time/batch = 0.016\n",
      "950/2800 (epoch 16), train_loss = 10.993, time/batch = 0.016\n",
      "951/2800 (epoch 16), train_loss = 10.162, time/batch = 0.022\n",
      "952/2800 (epoch 17), train_loss = 9.714, time/batch = 0.000\n",
      "953/2800 (epoch 17), train_loss = 9.943, time/batch = 0.016\n",
      "954/2800 (epoch 17), train_loss = 9.875, time/batch = 0.016\n",
      "955/2800 (epoch 17), train_loss = 9.330, time/batch = 0.016\n",
      "956/2800 (epoch 17), train_loss = 10.019, time/batch = 0.000\n",
      "957/2800 (epoch 17), train_loss = 8.972, time/batch = 0.016\n",
      "958/2800 (epoch 17), train_loss = 10.999, time/batch = 0.016\n",
      "959/2800 (epoch 17), train_loss = 9.054, time/batch = 0.017\n",
      "960/2800 (epoch 17), train_loss = 10.356, time/batch = 0.004\n",
      "961/2800 (epoch 17), train_loss = 9.007, time/batch = 0.016\n",
      "962/2800 (epoch 17), train_loss = 10.497, time/batch = 0.000\n",
      "963/2800 (epoch 17), train_loss = 9.594, time/batch = 0.016\n",
      "964/2800 (epoch 17), train_loss = 9.466, time/batch = 0.016\n",
      "965/2800 (epoch 17), train_loss = 8.747, time/batch = 0.016\n",
      "966/2800 (epoch 17), train_loss = 9.513, time/batch = 0.016\n",
      "967/2800 (epoch 17), train_loss = 9.570, time/batch = 0.000\n",
      "968/2800 (epoch 17), train_loss = 10.364, time/batch = 0.007\n",
      "969/2800 (epoch 17), train_loss = 9.388, time/batch = 0.016\n",
      "970/2800 (epoch 17), train_loss = 9.672, time/batch = 0.016\n",
      "971/2800 (epoch 17), train_loss = 9.249, time/batch = 0.000\n",
      "972/2800 (epoch 17), train_loss = 9.604, time/batch = 0.016\n",
      "973/2800 (epoch 17), train_loss = 9.314, time/batch = 0.016\n",
      "974/2800 (epoch 17), train_loss = 9.768, time/batch = 0.016\n",
      "975/2800 (epoch 17), train_loss = 9.596, time/batch = 0.000\n",
      "976/2800 (epoch 17), train_loss = 10.176, time/batch = 0.022\n",
      "977/2800 (epoch 17), train_loss = 9.477, time/batch = 0.000\n",
      "978/2800 (epoch 17), train_loss = 10.235, time/batch = 0.016\n",
      "979/2800 (epoch 17), train_loss = 9.434, time/batch = 0.016\n",
      "980/2800 (epoch 17), train_loss = 11.130, time/batch = 0.016\n",
      "981/2800 (epoch 17), train_loss = 9.263, time/batch = 0.000\n",
      "982/2800 (epoch 17), train_loss = 10.315, time/batch = 0.016\n",
      "983/2800 (epoch 17), train_loss = 9.793, time/batch = 0.016\n",
      "984/2800 (epoch 17), train_loss = 10.314, time/batch = 0.022\n",
      "985/2800 (epoch 17), train_loss = 9.144, time/batch = 0.000\n",
      "986/2800 (epoch 17), train_loss = 10.868, time/batch = 0.016\n",
      "987/2800 (epoch 17), train_loss = 9.479, time/batch = 0.016\n",
      "988/2800 (epoch 17), train_loss = 9.834, time/batch = 0.016\n",
      "989/2800 (epoch 17), train_loss = 11.011, time/batch = 0.000\n",
      "990/2800 (epoch 17), train_loss = 11.652, time/batch = 0.016\n",
      "991/2800 (epoch 17), train_loss = 10.945, time/batch = 0.016\n",
      "992/2800 (epoch 17), train_loss = 11.558, time/batch = 0.018\n",
      "993/2800 (epoch 17), train_loss = 10.763, time/batch = 0.004\n",
      "994/2800 (epoch 17), train_loss = 10.914, time/batch = 0.016\n",
      "995/2800 (epoch 17), train_loss = 10.546, time/batch = 0.000\n",
      "996/2800 (epoch 17), train_loss = 11.004, time/batch = 0.016\n",
      "997/2800 (epoch 17), train_loss = 10.534, time/batch = 0.016\n",
      "998/2800 (epoch 17), train_loss = 11.572, time/batch = 0.016\n",
      "999/2800 (epoch 17), train_loss = 10.604, time/batch = 0.016\n",
      "1000/2800 (epoch 17), train_loss = 10.948, time/batch = 0.000\n",
      "model saved to save\\model.ckpt\n",
      "1001/2800 (epoch 17), train_loss = 10.403, time/batch = 0.031\n",
      "1002/2800 (epoch 17), train_loss = 10.683, time/batch = 0.031\n",
      "1003/2800 (epoch 17), train_loss = 10.771, time/batch = 0.036\n",
      "1004/2800 (epoch 17), train_loss = 10.326, time/batch = 0.018\n",
      "1005/2800 (epoch 17), train_loss = 11.076, time/batch = 0.031\n",
      "1006/2800 (epoch 17), train_loss = 10.263, time/batch = 0.031\n",
      "1007/2800 (epoch 17), train_loss = 10.143, time/batch = 0.038\n",
      "1008/2800 (epoch 18), train_loss = 9.735, time/batch = 0.031\n",
      "1009/2800 (epoch 18), train_loss = 9.317, time/batch = 0.049\n",
      "1010/2800 (epoch 18), train_loss = 9.531, time/batch = 0.035\n",
      "1011/2800 (epoch 18), train_loss = 9.754, time/batch = 0.031\n",
      "1012/2800 (epoch 18), train_loss = 9.675, time/batch = 0.038\n",
      "1013/2800 (epoch 18), train_loss = 9.213, time/batch = 0.031\n",
      "1014/2800 (epoch 18), train_loss = 9.653, time/batch = 0.031\n",
      "1015/2800 (epoch 18), train_loss = 9.274, time/batch = 0.038\n",
      "1016/2800 (epoch 18), train_loss = 9.857, time/batch = 0.063\n",
      "1017/2800 (epoch 18), train_loss = 9.483, time/batch = 0.041\n",
      "1018/2800 (epoch 18), train_loss = 11.702, time/batch = 0.033\n",
      "1019/2800 (epoch 18), train_loss = 8.996, time/batch = 0.043\n",
      "1020/2800 (epoch 18), train_loss = 10.129, time/batch = 0.039\n",
      "1021/2800 (epoch 18), train_loss = 9.091, time/batch = 0.040\n",
      "1022/2800 (epoch 18), train_loss = 9.702, time/batch = 0.042\n",
      "1023/2800 (epoch 18), train_loss = 9.691, time/batch = 0.019\n",
      "1024/2800 (epoch 18), train_loss = 9.720, time/batch = 0.047\n",
      "1025/2800 (epoch 18), train_loss = 9.260, time/batch = 0.031\n",
      "1026/2800 (epoch 18), train_loss = 9.306, time/batch = 0.053\n",
      "1027/2800 (epoch 18), train_loss = 9.062, time/batch = 0.047\n",
      "1028/2800 (epoch 18), train_loss = 9.642, time/batch = 0.038\n",
      "1029/2800 (epoch 18), train_loss = 9.054, time/batch = 0.031\n",
      "1030/2800 (epoch 18), train_loss = 9.998, time/batch = 0.053\n",
      "1031/2800 (epoch 18), train_loss = 9.823, time/batch = 0.047\n",
      "1032/2800 (epoch 18), train_loss = 9.557, time/batch = 0.031\n",
      "1033/2800 (epoch 18), train_loss = 10.055, time/batch = 0.038\n",
      "1034/2800 (epoch 18), train_loss = 9.910, time/batch = 0.031\n",
      "1035/2800 (epoch 18), train_loss = 9.412, time/batch = 0.031\n",
      "1036/2800 (epoch 18), train_loss = 9.544, time/batch = 0.022\n",
      "1037/2800 (epoch 18), train_loss = 10.006, time/batch = 0.031\n",
      "1038/2800 (epoch 18), train_loss = 9.689, time/batch = 0.047\n",
      "1039/2800 (epoch 18), train_loss = 10.680, time/batch = 0.038\n",
      "1040/2800 (epoch 18), train_loss = 9.358, time/batch = 0.031\n",
      "1041/2800 (epoch 18), train_loss = 9.697, time/batch = 0.031\n",
      "1042/2800 (epoch 18), train_loss = 9.814, time/batch = 0.022\n",
      "1043/2800 (epoch 18), train_loss = 9.511, time/batch = 0.031\n",
      "1044/2800 (epoch 18), train_loss = 11.757, time/batch = 0.031\n",
      "1045/2800 (epoch 18), train_loss = 11.374, time/batch = 0.038\n",
      "1046/2800 (epoch 18), train_loss = 10.961, time/batch = 0.031\n",
      "1047/2800 (epoch 18), train_loss = 10.729, time/batch = 0.031\n",
      "1048/2800 (epoch 18), train_loss = 10.935, time/batch = 0.037\n",
      "1049/2800 (epoch 18), train_loss = 10.527, time/batch = 0.016\n",
      "1050/2800 (epoch 18), train_loss = 10.819, time/batch = 0.031\n",
      "1051/2800 (epoch 18), train_loss = 10.596, time/batch = 0.031\n",
      "1052/2800 (epoch 18), train_loss = 11.196, time/batch = 0.022\n",
      "1053/2800 (epoch 18), train_loss = 10.427, time/batch = 0.031\n",
      "1054/2800 (epoch 18), train_loss = 10.955, time/batch = 0.031\n",
      "1055/2800 (epoch 18), train_loss = 10.400, time/batch = 0.016\n",
      "1056/2800 (epoch 18), train_loss = 11.817, time/batch = 0.022\n",
      "1057/2800 (epoch 18), train_loss = 10.499, time/batch = 0.016\n",
      "1058/2800 (epoch 18), train_loss = 11.583, time/batch = 0.031\n",
      "1059/2800 (epoch 18), train_loss = 10.454, time/batch = 0.016\n",
      "1060/2800 (epoch 18), train_loss = 10.596, time/batch = 0.016\n",
      "1061/2800 (epoch 18), train_loss = 10.315, time/batch = 0.038\n",
      "1062/2800 (epoch 18), train_loss = 10.234, time/batch = 0.016\n",
      "1063/2800 (epoch 18), train_loss = 10.385, time/batch = 0.031\n",
      "1064/2800 (epoch 19), train_loss = 10.430, time/batch = 0.016\n",
      "1065/2800 (epoch 19), train_loss = 9.714, time/batch = 0.022\n",
      "1066/2800 (epoch 19), train_loss = 9.651, time/batch = 0.031\n",
      "1067/2800 (epoch 19), train_loss = 9.896, time/batch = 0.016\n",
      "1068/2800 (epoch 19), train_loss = 9.264, time/batch = 0.016\n",
      "1069/2800 (epoch 19), train_loss = 10.119, time/batch = 0.033\n",
      "1070/2800 (epoch 19), train_loss = 9.084, time/batch = 0.020\n",
      "1071/2800 (epoch 19), train_loss = 10.650, time/batch = 0.031\n",
      "1072/2800 (epoch 19), train_loss = 8.898, time/batch = 0.016\n",
      "1073/2800 (epoch 19), train_loss = 10.984, time/batch = 0.033\n",
      "1074/2800 (epoch 19), train_loss = 9.782, time/batch = 0.020\n",
      "1075/2800 (epoch 19), train_loss = 9.571, time/batch = 0.016\n",
      "1076/2800 (epoch 19), train_loss = 9.164, time/batch = 0.016\n",
      "1077/2800 (epoch 19), train_loss = 9.828, time/batch = 0.016\n",
      "1078/2800 (epoch 19), train_loss = 8.983, time/batch = 0.020\n",
      "1079/2800 (epoch 19), train_loss = 9.545, time/batch = 0.018\n",
      "1080/2800 (epoch 19), train_loss = 8.942, time/batch = 0.016\n",
      "1081/2800 (epoch 19), train_loss = 10.670, time/batch = 0.031\n",
      "1082/2800 (epoch 19), train_loss = 9.728, time/batch = 0.032\n",
      "1083/2800 (epoch 19), train_loss = 10.280, time/batch = 0.021\n",
      "1084/2800 (epoch 19), train_loss = 9.064, time/batch = 0.016\n",
      "1085/2800 (epoch 19), train_loss = 10.324, time/batch = 0.031\n",
      "1086/2800 (epoch 19), train_loss = 8.951, time/batch = 0.016\n",
      "1087/2800 (epoch 19), train_loss = 10.621, time/batch = 0.022\n",
      "1088/2800 (epoch 19), train_loss = 9.337, time/batch = 0.016\n",
      "1089/2800 (epoch 19), train_loss = 10.031, time/batch = 0.031\n",
      "1090/2800 (epoch 19), train_loss = 9.498, time/batch = 0.016\n",
      "1091/2800 (epoch 19), train_loss = 11.334, time/batch = 0.022\n",
      "1092/2800 (epoch 19), train_loss = 9.326, time/batch = 0.016\n",
      "1093/2800 (epoch 19), train_loss = 9.760, time/batch = 0.016\n",
      "1094/2800 (epoch 19), train_loss = 9.517, time/batch = 0.031\n",
      "1095/2800 (epoch 19), train_loss = 9.967, time/batch = 0.016\n",
      "1096/2800 (epoch 19), train_loss = 9.809, time/batch = 0.022\n",
      "1097/2800 (epoch 19), train_loss = 9.962, time/batch = 0.031\n",
      "1098/2800 (epoch 19), train_loss = 9.409, time/batch = 0.031\n",
      "1099/2800 (epoch 19), train_loss = 9.682, time/batch = 0.037\n",
      "1100/2800 (epoch 19), train_loss = 9.769, time/batch = 0.016\n",
      "1101/2800 (epoch 19), train_loss = 12.012, time/batch = 0.031\n",
      "1102/2800 (epoch 19), train_loss = 11.281, time/batch = 0.016\n",
      "1103/2800 (epoch 19), train_loss = 11.092, time/batch = 0.016\n",
      "1104/2800 (epoch 19), train_loss = 10.632, time/batch = 0.022\n",
      "1105/2800 (epoch 19), train_loss = 11.030, time/batch = 0.016\n",
      "1106/2800 (epoch 19), train_loss = 10.581, time/batch = 0.016\n",
      "1107/2800 (epoch 19), train_loss = 10.760, time/batch = 0.031\n",
      "1108/2800 (epoch 19), train_loss = 10.520, time/batch = 0.016\n",
      "1109/2800 (epoch 19), train_loss = 11.025, time/batch = 0.022\n",
      "1110/2800 (epoch 19), train_loss = 10.549, time/batch = 0.031\n",
      "1111/2800 (epoch 19), train_loss = 10.192, time/batch = 0.016\n",
      "1112/2800 (epoch 19), train_loss = 11.386, time/batch = 0.016\n",
      "1113/2800 (epoch 19), train_loss = 10.329, time/batch = 0.016\n",
      "1114/2800 (epoch 19), train_loss = 10.333, time/batch = 0.022\n",
      "1115/2800 (epoch 19), train_loss = 11.275, time/batch = 0.016\n",
      "1116/2800 (epoch 19), train_loss = 10.790, time/batch = 0.016\n",
      "1117/2800 (epoch 19), train_loss = 10.222, time/batch = 0.016\n",
      "1118/2800 (epoch 19), train_loss = 10.857, time/batch = 0.031\n",
      "1119/2800 (epoch 19), train_loss = 10.319, time/batch = 0.022\n",
      "1120/2800 (epoch 20), train_loss = 10.200, time/batch = 0.016\n",
      "1121/2800 (epoch 20), train_loss = 9.514, time/batch = 0.016\n",
      "1122/2800 (epoch 20), train_loss = 10.347, time/batch = 0.031\n",
      "1123/2800 (epoch 20), train_loss = 9.401, time/batch = 0.016\n",
      "1124/2800 (epoch 20), train_loss = 10.139, time/batch = 0.021\n",
      "1125/2800 (epoch 20), train_loss = 9.035, time/batch = 0.016\n",
      "1126/2800 (epoch 20), train_loss = 10.416, time/batch = 0.016\n",
      "1127/2800 (epoch 20), train_loss = 9.512, time/batch = 0.016\n",
      "1128/2800 (epoch 20), train_loss = 10.581, time/batch = 0.016\n",
      "1129/2800 (epoch 20), train_loss = 8.884, time/batch = 0.016\n",
      "1130/2800 (epoch 20), train_loss = 11.450, time/batch = 0.023\n",
      "1131/2800 (epoch 20), train_loss = 9.167, time/batch = 0.016\n",
      "1132/2800 (epoch 20), train_loss = 11.379, time/batch = 0.031\n",
      "1133/2800 (epoch 20), train_loss = 9.386, time/batch = 0.016\n",
      "1134/2800 (epoch 20), train_loss = 9.255, time/batch = 0.016\n",
      "1135/2800 (epoch 20), train_loss = 9.500, time/batch = 0.022\n",
      "1136/2800 (epoch 20), train_loss = 9.163, time/batch = 0.016\n",
      "1137/2800 (epoch 20), train_loss = 9.701, time/batch = 0.016\n",
      "1138/2800 (epoch 20), train_loss = 9.235, time/batch = 0.016\n",
      "1139/2800 (epoch 20), train_loss = 9.267, time/batch = 0.016\n",
      "1140/2800 (epoch 20), train_loss = 9.076, time/batch = 0.016\n",
      "1141/2800 (epoch 20), train_loss = 9.897, time/batch = 0.022\n",
      "1142/2800 (epoch 20), train_loss = 9.189, time/batch = 0.016\n",
      "1143/2800 (epoch 20), train_loss = 9.492, time/batch = 0.016\n",
      "1144/2800 (epoch 20), train_loss = 9.721, time/batch = 0.016\n",
      "1145/2800 (epoch 20), train_loss = 10.894, time/batch = 0.016\n",
      "1146/2800 (epoch 20), train_loss = 9.527, time/batch = 0.022\n",
      "1147/2800 (epoch 20), train_loss = 10.256, time/batch = 0.016\n",
      "1148/2800 (epoch 20), train_loss = 9.831, time/batch = 0.016\n",
      "1149/2800 (epoch 20), train_loss = 10.303, time/batch = 0.016\n",
      "1150/2800 (epoch 20), train_loss = 9.443, time/batch = 0.016\n",
      "1151/2800 (epoch 20), train_loss = 10.120, time/batch = 0.016\n",
      "1152/2800 (epoch 20), train_loss = 9.960, time/batch = 0.022\n",
      "1153/2800 (epoch 20), train_loss = 9.366, time/batch = 0.016\n",
      "1154/2800 (epoch 20), train_loss = 9.829, time/batch = 0.031\n",
      "1155/2800 (epoch 20), train_loss = 9.932, time/batch = 0.016\n",
      "1156/2800 (epoch 20), train_loss = 9.563, time/batch = 0.016\n",
      "1157/2800 (epoch 20), train_loss = 11.232, time/batch = 0.022\n",
      "1158/2800 (epoch 20), train_loss = 11.402, time/batch = 0.016\n",
      "1159/2800 (epoch 20), train_loss = 10.924, time/batch = 0.016\n",
      "1160/2800 (epoch 20), train_loss = 11.255, time/batch = 0.016\n",
      "1161/2800 (epoch 20), train_loss = 10.669, time/batch = 0.016\n",
      "1162/2800 (epoch 20), train_loss = 10.509, time/batch = 0.016\n",
      "1163/2800 (epoch 20), train_loss = 10.383, time/batch = 0.022\n",
      "1164/2800 (epoch 20), train_loss = 10.923, time/batch = 0.016\n",
      "1165/2800 (epoch 20), train_loss = 10.435, time/batch = 0.031\n",
      "1166/2800 (epoch 20), train_loss = 11.064, time/batch = 0.016\n",
      "1167/2800 (epoch 20), train_loss = 10.289, time/batch = 0.016\n",
      "1168/2800 (epoch 20), train_loss = 11.253, time/batch = 0.021\n",
      "1169/2800 (epoch 20), train_loss = 10.570, time/batch = 0.000\n",
      "1170/2800 (epoch 20), train_loss = 10.451, time/batch = 0.016\n",
      "1171/2800 (epoch 20), train_loss = 10.617, time/batch = 0.016\n",
      "1172/2800 (epoch 20), train_loss = 10.499, time/batch = 0.000\n",
      "1173/2800 (epoch 20), train_loss = 10.479, time/batch = 0.016\n",
      "1174/2800 (epoch 20), train_loss = 10.666, time/batch = 0.016\n",
      "1175/2800 (epoch 20), train_loss = 10.076, time/batch = 0.000\n",
      "1176/2800 (epoch 21), train_loss = 10.307, time/batch = 0.016\n",
      "1177/2800 (epoch 21), train_loss = 9.621, time/batch = 0.022\n",
      "1178/2800 (epoch 21), train_loss = 9.711, time/batch = 0.016\n",
      "1179/2800 (epoch 21), train_loss = 10.217, time/batch = 0.016\n",
      "1180/2800 (epoch 21), train_loss = 9.103, time/batch = 0.016\n",
      "1181/2800 (epoch 21), train_loss = 10.610, time/batch = 0.016\n",
      "1182/2800 (epoch 21), train_loss = 9.421, time/batch = 0.000\n",
      "1183/2800 (epoch 21), train_loss = 10.435, time/batch = 0.016\n",
      "1184/2800 (epoch 21), train_loss = 9.187, time/batch = 0.020\n",
      "1185/2800 (epoch 21), train_loss = 11.149, time/batch = 0.001\n",
      "1186/2800 (epoch 21), train_loss = 9.151, time/batch = 0.016\n",
      "1187/2800 (epoch 21), train_loss = 10.688, time/batch = 0.000\n",
      "1188/2800 (epoch 21), train_loss = 9.259, time/batch = 0.016\n",
      "1189/2800 (epoch 21), train_loss = 9.973, time/batch = 0.016\n",
      "1190/2800 (epoch 21), train_loss = 9.012, time/batch = 0.016\n",
      "1191/2800 (epoch 21), train_loss = 9.844, time/batch = 0.000\n",
      "1192/2800 (epoch 21), train_loss = 9.001, time/batch = 0.016\n",
      "1193/2800 (epoch 21), train_loss = 9.888, time/batch = 0.019\n",
      "1194/2800 (epoch 21), train_loss = 8.919, time/batch = 0.003\n",
      "1195/2800 (epoch 21), train_loss = 9.895, time/batch = 0.016\n",
      "1196/2800 (epoch 21), train_loss = 8.874, time/batch = 0.016\n",
      "1197/2800 (epoch 21), train_loss = 10.676, time/batch = 0.016\n",
      "1198/2800 (epoch 21), train_loss = 8.806, time/batch = 0.016\n",
      "1199/2800 (epoch 21), train_loss = 9.668, time/batch = 0.016\n",
      "1200/2800 (epoch 21), train_loss = 9.693, time/batch = 0.000\n",
      "1201/2800 (epoch 21), train_loss = 9.483, time/batch = 0.022\n",
      "1202/2800 (epoch 21), train_loss = 9.517, time/batch = 0.000\n",
      "1203/2800 (epoch 21), train_loss = 10.211, time/batch = 0.016\n",
      "1204/2800 (epoch 21), train_loss = 9.636, time/batch = 0.016\n",
      "1205/2800 (epoch 21), train_loss = 9.885, time/batch = 0.000\n",
      "1206/2800 (epoch 21), train_loss = 9.747, time/batch = 0.016\n",
      "1207/2800 (epoch 21), train_loss = 10.237, time/batch = 0.016\n",
      "1208/2800 (epoch 21), train_loss = 9.466, time/batch = 0.000\n",
      "1209/2800 (epoch 21), train_loss = 9.822, time/batch = 0.016\n",
      "1210/2800 (epoch 21), train_loss = 9.797, time/batch = 0.022\n",
      "1211/2800 (epoch 21), train_loss = 11.650, time/batch = 0.000\n",
      "1212/2800 (epoch 21), train_loss = 10.992, time/batch = 0.016\n",
      "1213/2800 (epoch 21), train_loss = 11.265, time/batch = 0.016\n",
      "1214/2800 (epoch 21), train_loss = 10.775, time/batch = 0.016\n",
      "1215/2800 (epoch 21), train_loss = 11.054, time/batch = 0.016\n",
      "1216/2800 (epoch 21), train_loss = 10.436, time/batch = 0.016\n",
      "1217/2800 (epoch 21), train_loss = 10.854, time/batch = 0.000\n",
      "1218/2800 (epoch 21), train_loss = 10.429, time/batch = 0.022\n",
      "1219/2800 (epoch 21), train_loss = 10.972, time/batch = 0.016\n",
      "1220/2800 (epoch 21), train_loss = 10.550, time/batch = 0.000\n",
      "1221/2800 (epoch 21), train_loss = 10.674, time/batch = 0.016\n",
      "1222/2800 (epoch 21), train_loss = 10.417, time/batch = 0.016\n",
      "1223/2800 (epoch 21), train_loss = 11.846, time/batch = 0.016\n",
      "1224/2800 (epoch 21), train_loss = 10.434, time/batch = 0.000\n",
      "1225/2800 (epoch 21), train_loss = 10.938, time/batch = 0.016\n",
      "1226/2800 (epoch 21), train_loss = 10.377, time/batch = 0.021\n",
      "1227/2800 (epoch 21), train_loss = 11.076, time/batch = 0.000\n",
      "1228/2800 (epoch 21), train_loss = 10.522, time/batch = 0.016\n",
      "1229/2800 (epoch 21), train_loss = 10.256, time/batch = 0.016\n",
      "1230/2800 (epoch 21), train_loss = 10.238, time/batch = 0.016\n",
      "1231/2800 (epoch 21), train_loss = 10.307, time/batch = 0.016\n",
      "1232/2800 (epoch 22), train_loss = 10.090, time/batch = 0.016\n",
      "1233/2800 (epoch 22), train_loss = 9.504, time/batch = 0.000\n",
      "1234/2800 (epoch 22), train_loss = 9.764, time/batch = 0.022\n",
      "1235/2800 (epoch 22), train_loss = 10.573, time/batch = 0.016\n",
      "1236/2800 (epoch 22), train_loss = 9.122, time/batch = 0.000\n",
      "1237/2800 (epoch 22), train_loss = 10.549, time/batch = 0.016\n",
      "1238/2800 (epoch 22), train_loss = 9.194, time/batch = 0.016\n",
      "1239/2800 (epoch 22), train_loss = 9.715, time/batch = 0.000\n",
      "1240/2800 (epoch 22), train_loss = 9.379, time/batch = 0.016\n",
      "1241/2800 (epoch 22), train_loss = 10.611, time/batch = 0.016\n",
      "1242/2800 (epoch 22), train_loss = 9.310, time/batch = 0.017\n",
      "1243/2800 (epoch 22), train_loss = 10.871, time/batch = 0.006\n",
      "1244/2800 (epoch 22), train_loss = 8.794, time/batch = 0.016\n",
      "1245/2800 (epoch 22), train_loss = 11.079, time/batch = 0.000\n",
      "1246/2800 (epoch 22), train_loss = 9.013, time/batch = 0.016\n",
      "1247/2800 (epoch 22), train_loss = 10.117, time/batch = 0.016\n",
      "1248/2800 (epoch 22), train_loss = 9.016, time/batch = 0.016\n",
      "1249/2800 (epoch 22), train_loss = 10.093, time/batch = 0.016\n",
      "1250/2800 (epoch 22), train_loss = 9.048, time/batch = 0.017\n",
      "1251/2800 (epoch 22), train_loss = 9.733, time/batch = 0.005\n",
      "1252/2800 (epoch 22), train_loss = 9.328, time/batch = 0.016\n",
      "1253/2800 (epoch 22), train_loss = 9.770, time/batch = 0.000\n",
      "1254/2800 (epoch 22), train_loss = 9.443, time/batch = 0.016\n",
      "1255/2800 (epoch 22), train_loss = 9.899, time/batch = 0.016\n",
      "1256/2800 (epoch 22), train_loss = 9.617, time/batch = 0.016\n",
      "1257/2800 (epoch 22), train_loss = 10.369, time/batch = 0.000\n",
      "1258/2800 (epoch 22), train_loss = 9.333, time/batch = 0.016\n",
      "1259/2800 (epoch 22), train_loss = 10.376, time/batch = 0.019\n",
      "1260/2800 (epoch 22), train_loss = 9.466, time/batch = 0.003\n",
      "1261/2800 (epoch 22), train_loss = 9.994, time/batch = 0.016\n",
      "1262/2800 (epoch 22), train_loss = 9.726, time/batch = 0.000\n",
      "1263/2800 (epoch 22), train_loss = 9.797, time/batch = 0.016\n",
      "1264/2800 (epoch 22), train_loss = 9.520, time/batch = 0.016\n",
      "1265/2800 (epoch 22), train_loss = 9.538, time/batch = 0.016\n",
      "1266/2800 (epoch 22), train_loss = 9.421, time/batch = 0.016\n",
      "1267/2800 (epoch 22), train_loss = 11.004, time/batch = 0.021\n",
      "1268/2800 (epoch 22), train_loss = 10.967, time/batch = 0.000\n",
      "1269/2800 (epoch 22), train_loss = 10.815, time/batch = 0.016\n",
      "1270/2800 (epoch 22), train_loss = 11.463, time/batch = 0.016\n",
      "1271/2800 (epoch 22), train_loss = 10.370, time/batch = 0.000\n",
      "1272/2800 (epoch 22), train_loss = 10.835, time/batch = 0.016\n",
      "1273/2800 (epoch 22), train_loss = 10.594, time/batch = 0.016\n",
      "1274/2800 (epoch 22), train_loss = 10.757, time/batch = 0.016\n",
      "1275/2800 (epoch 22), train_loss = 10.745, time/batch = 0.000\n",
      "1276/2800 (epoch 22), train_loss = 10.880, time/batch = 0.021\n",
      "1277/2800 (epoch 22), train_loss = 10.565, time/batch = 0.000\n",
      "1278/2800 (epoch 22), train_loss = 10.923, time/batch = 0.016\n",
      "1279/2800 (epoch 22), train_loss = 10.251, time/batch = 0.016\n",
      "1280/2800 (epoch 22), train_loss = 11.249, time/batch = 0.016\n",
      "1281/2800 (epoch 22), train_loss = 10.547, time/batch = 0.000\n",
      "1282/2800 (epoch 22), train_loss = 10.403, time/batch = 0.016\n",
      "1283/2800 (epoch 22), train_loss = 10.338, time/batch = 0.016\n",
      "1284/2800 (epoch 22), train_loss = 9.962, time/batch = 0.022\n",
      "1285/2800 (epoch 22), train_loss = 10.842, time/batch = 0.000\n",
      "1286/2800 (epoch 22), train_loss = 10.185, time/batch = 0.016\n",
      "1287/2800 (epoch 22), train_loss = 10.417, time/batch = 0.016\n",
      "1288/2800 (epoch 23), train_loss = 9.894, time/batch = 0.016\n",
      "1289/2800 (epoch 23), train_loss = 9.330, time/batch = 0.000\n",
      "1290/2800 (epoch 23), train_loss = 9.632, time/batch = 0.016\n",
      "1291/2800 (epoch 23), train_loss = 10.136, time/batch = 0.016\n",
      "1292/2800 (epoch 23), train_loss = 9.063, time/batch = 0.000\n",
      "1293/2800 (epoch 23), train_loss = 10.213, time/batch = 0.022\n",
      "1294/2800 (epoch 23), train_loss = 9.664, time/batch = 0.000\n",
      "1295/2800 (epoch 23), train_loss = 9.889, time/batch = 0.016\n",
      "1296/2800 (epoch 23), train_loss = 9.439, time/batch = 0.016\n",
      "1297/2800 (epoch 23), train_loss = 10.043, time/batch = 0.016\n",
      "1298/2800 (epoch 23), train_loss = 9.886, time/batch = 0.016\n",
      "1299/2800 (epoch 23), train_loss = 9.681, time/batch = 0.016\n",
      "1300/2800 (epoch 23), train_loss = 9.263, time/batch = 0.021\n",
      "1301/2800 (epoch 23), train_loss = 9.401, time/batch = 0.001\n",
      "1302/2800 (epoch 23), train_loss = 8.794, time/batch = 0.016\n",
      "1303/2800 (epoch 23), train_loss = 11.538, time/batch = 0.016\n",
      "1304/2800 (epoch 23), train_loss = 8.730, time/batch = 0.000\n",
      "1305/2800 (epoch 23), train_loss = 10.151, time/batch = 0.016\n",
      "1306/2800 (epoch 23), train_loss = 9.084, time/batch = 0.016\n",
      "1307/2800 (epoch 23), train_loss = 10.559, time/batch = 0.000\n",
      "1308/2800 (epoch 23), train_loss = 8.948, time/batch = 0.000\n",
      "1309/2800 (epoch 23), train_loss = 10.754, time/batch = 0.022\n",
      "1310/2800 (epoch 23), train_loss = 9.213, time/batch = 0.000\n",
      "1311/2800 (epoch 23), train_loss = 9.669, time/batch = 0.016\n",
      "1312/2800 (epoch 23), train_loss = 9.407, time/batch = 0.016\n",
      "1313/2800 (epoch 23), train_loss = 9.844, time/batch = 0.016\n",
      "1314/2800 (epoch 23), train_loss = 10.171, time/batch = 0.000\n",
      "1315/2800 (epoch 23), train_loss = 9.656, time/batch = 0.016\n",
      "1316/2800 (epoch 23), train_loss = 10.196, time/batch = 0.016\n",
      "1317/2800 (epoch 23), train_loss = 9.801, time/batch = 0.022\n",
      "1318/2800 (epoch 23), train_loss = 9.650, time/batch = 0.000\n",
      "1319/2800 (epoch 23), train_loss = 9.632, time/batch = 0.016\n",
      "1320/2800 (epoch 23), train_loss = 9.623, time/batch = 0.016\n",
      "1321/2800 (epoch 23), train_loss = 9.403, time/batch = 0.000\n",
      "1322/2800 (epoch 23), train_loss = 11.448, time/batch = 0.016\n",
      "1323/2800 (epoch 23), train_loss = 11.517, time/batch = 0.016\n",
      "1324/2800 (epoch 23), train_loss = 10.890, time/batch = 0.016\n",
      "1325/2800 (epoch 23), train_loss = 11.440, time/batch = 0.000\n",
      "1326/2800 (epoch 23), train_loss = 10.643, time/batch = 0.022\n",
      "1327/2800 (epoch 23), train_loss = 10.927, time/batch = 0.000\n",
      "1328/2800 (epoch 23), train_loss = 10.486, time/batch = 0.016\n",
      "1329/2800 (epoch 23), train_loss = 10.942, time/batch = 0.016\n",
      "1330/2800 (epoch 23), train_loss = 10.438, time/batch = 0.016\n",
      "1331/2800 (epoch 23), train_loss = 10.413, time/batch = 0.016\n",
      "1332/2800 (epoch 23), train_loss = 10.560, time/batch = 0.000\n",
      "1333/2800 (epoch 23), train_loss = 11.482, time/batch = 0.000\n",
      "1334/2800 (epoch 23), train_loss = 10.389, time/batch = 0.022\n",
      "1335/2800 (epoch 23), train_loss = 11.041, time/batch = 0.000\n",
      "1336/2800 (epoch 23), train_loss = 10.159, time/batch = 0.000\n",
      "1337/2800 (epoch 23), train_loss = 10.926, time/batch = 0.016\n",
      "1338/2800 (epoch 23), train_loss = 10.332, time/batch = 0.016\n",
      "1339/2800 (epoch 23), train_loss = 10.308, time/batch = 0.000\n",
      "1340/2800 (epoch 23), train_loss = 10.805, time/batch = 0.016\n",
      "1341/2800 (epoch 23), train_loss = 10.189, time/batch = 0.016\n",
      "1342/2800 (epoch 23), train_loss = 9.856, time/batch = 0.000\n",
      "1343/2800 (epoch 23), train_loss = 10.782, time/batch = 0.022\n",
      "1344/2800 (epoch 24), train_loss = 9.371, time/batch = 0.000\n",
      "1345/2800 (epoch 24), train_loss = 9.418, time/batch = 0.016\n",
      "1346/2800 (epoch 24), train_loss = 9.455, time/batch = 0.016\n",
      "1347/2800 (epoch 24), train_loss = 10.406, time/batch = 0.016\n",
      "1348/2800 (epoch 24), train_loss = 9.211, time/batch = 0.016\n",
      "1349/2800 (epoch 24), train_loss = 10.330, time/batch = 0.016\n",
      "1350/2800 (epoch 24), train_loss = 9.257, time/batch = 0.000\n",
      "1351/2800 (epoch 24), train_loss = 10.794, time/batch = 0.022\n",
      "1352/2800 (epoch 24), train_loss = 9.040, time/batch = 0.016\n",
      "1353/2800 (epoch 24), train_loss = 10.483, time/batch = 0.000\n",
      "1354/2800 (epoch 24), train_loss = 9.032, time/batch = 0.016\n",
      "1355/2800 (epoch 24), train_loss = 10.520, time/batch = 0.016\n",
      "1356/2800 (epoch 24), train_loss = 9.012, time/batch = 0.000\n",
      "1357/2800 (epoch 24), train_loss = 10.933, time/batch = 0.016\n",
      "1358/2800 (epoch 24), train_loss = 9.202, time/batch = 0.016\n",
      "1359/2800 (epoch 24), train_loss = 9.131, time/batch = 0.000\n",
      "1360/2800 (epoch 24), train_loss = 9.348, time/batch = 0.022\n",
      "1361/2800 (epoch 24), train_loss = 10.100, time/batch = 0.000\n",
      "1362/2800 (epoch 24), train_loss = 9.138, time/batch = 0.016\n",
      "1363/2800 (epoch 24), train_loss = 10.297, time/batch = 0.016\n",
      "1364/2800 (epoch 24), train_loss = 9.013, time/batch = 0.016\n",
      "1365/2800 (epoch 24), train_loss = 9.942, time/batch = 0.016\n",
      "1366/2800 (epoch 24), train_loss = 9.896, time/batch = 0.016\n",
      "1367/2800 (epoch 24), train_loss = 9.943, time/batch = 0.017\n",
      "1368/2800 (epoch 24), train_loss = 9.289, time/batch = 0.005\n",
      "1369/2800 (epoch 24), train_loss = 9.741, time/batch = 0.016\n",
      "1370/2800 (epoch 24), train_loss = 8.949, time/batch = 0.016\n",
      "1371/2800 (epoch 24), train_loss = 11.538, time/batch = 0.000\n",
      "1372/2800 (epoch 24), train_loss = 9.280, time/batch = 0.016\n",
      "1373/2800 (epoch 24), train_loss = 10.827, time/batch = 0.016\n",
      "1374/2800 (epoch 24), train_loss = 9.694, time/batch = 0.000\n",
      "1375/2800 (epoch 24), train_loss = 10.615, time/batch = 0.016\n",
      "1376/2800 (epoch 24), train_loss = 9.265, time/batch = 0.021\n",
      "1377/2800 (epoch 24), train_loss = 10.181, time/batch = 0.000\n",
      "1378/2800 (epoch 24), train_loss = 9.060, time/batch = 0.016\n",
      "1379/2800 (epoch 24), train_loss = 10.184, time/batch = 0.016\n",
      "1380/2800 (epoch 24), train_loss = 11.421, time/batch = 0.000\n",
      "1381/2800 (epoch 24), train_loss = 11.177, time/batch = 0.016\n",
      "1382/2800 (epoch 24), train_loss = 11.052, time/batch = 0.016\n",
      "1383/2800 (epoch 24), train_loss = 11.057, time/batch = 0.016\n",
      "1384/2800 (epoch 24), train_loss = 10.603, time/batch = 0.023\n",
      "1385/2800 (epoch 24), train_loss = 10.807, time/batch = 0.000\n",
      "1386/2800 (epoch 24), train_loss = 10.578, time/batch = 0.016\n",
      "1387/2800 (epoch 24), train_loss = 10.777, time/batch = 0.016\n",
      "1388/2800 (epoch 24), train_loss = 10.449, time/batch = 0.016\n",
      "1389/2800 (epoch 24), train_loss = 10.158, time/batch = 0.000\n",
      "1390/2800 (epoch 24), train_loss = 11.892, time/batch = 0.016\n",
      "1391/2800 (epoch 24), train_loss = 10.547, time/batch = 0.016\n",
      "1392/2800 (epoch 24), train_loss = 10.401, time/batch = 0.018\n",
      "1393/2800 (epoch 24), train_loss = 10.567, time/batch = 0.004\n",
      "1394/2800 (epoch 24), train_loss = 11.552, time/batch = 0.016\n",
      "1395/2800 (epoch 24), train_loss = 10.143, time/batch = 0.000\n",
      "1396/2800 (epoch 24), train_loss = 11.487, time/batch = 0.016\n",
      "1397/2800 (epoch 24), train_loss = 10.044, time/batch = 0.016\n",
      "1398/2800 (epoch 24), train_loss = 11.106, time/batch = 0.016\n",
      "1399/2800 (epoch 24), train_loss = 10.277, time/batch = 0.016\n",
      "1400/2800 (epoch 25), train_loss = 10.188, time/batch = 0.016\n",
      "1401/2800 (epoch 25), train_loss = 9.872, time/batch = 0.006\n",
      "1402/2800 (epoch 25), train_loss = 9.748, time/batch = 0.016\n",
      "1403/2800 (epoch 25), train_loss = 9.418, time/batch = 0.000\n",
      "1404/2800 (epoch 25), train_loss = 9.905, time/batch = 0.000\n",
      "1405/2800 (epoch 25), train_loss = 9.231, time/batch = 0.016\n",
      "1406/2800 (epoch 25), train_loss = 10.355, time/batch = 0.016\n",
      "1407/2800 (epoch 25), train_loss = 9.265, time/batch = 0.000\n",
      "1408/2800 (epoch 25), train_loss = 10.286, time/batch = 0.016\n",
      "1409/2800 (epoch 25), train_loss = 9.148, time/batch = 0.018\n",
      "1410/2800 (epoch 25), train_loss = 10.128, time/batch = 0.003\n",
      "1411/2800 (epoch 25), train_loss = 9.226, time/batch = 0.016\n",
      "1412/2800 (epoch 25), train_loss = 10.093, time/batch = 0.000\n",
      "1413/2800 (epoch 25), train_loss = 8.802, time/batch = 0.016\n",
      "1414/2800 (epoch 25), train_loss = 10.429, time/batch = 0.016\n",
      "1415/2800 (epoch 25), train_loss = 9.198, time/batch = 0.016\n",
      "1416/2800 (epoch 25), train_loss = 9.748, time/batch = 0.016\n",
      "1417/2800 (epoch 25), train_loss = 9.150, time/batch = 0.022\n",
      "1418/2800 (epoch 25), train_loss = 9.590, time/batch = 0.016\n",
      "1419/2800 (epoch 25), train_loss = 9.014, time/batch = 0.000\n",
      "1420/2800 (epoch 25), train_loss = 10.115, time/batch = 0.000\n",
      "1421/2800 (epoch 25), train_loss = 8.936, time/batch = 0.016\n",
      "1422/2800 (epoch 25), train_loss = 9.843, time/batch = 0.016\n",
      "1423/2800 (epoch 25), train_loss = 9.965, time/batch = 0.000\n",
      "1424/2800 (epoch 25), train_loss = 10.269, time/batch = 0.016\n",
      "1425/2800 (epoch 25), train_loss = 9.262, time/batch = 0.019\n",
      "1426/2800 (epoch 25), train_loss = 10.218, time/batch = 0.002\n",
      "1427/2800 (epoch 25), train_loss = 9.520, time/batch = 0.016\n",
      "1428/2800 (epoch 25), train_loss = 9.644, time/batch = 0.000\n",
      "1429/2800 (epoch 25), train_loss = 9.457, time/batch = 0.016\n",
      "1430/2800 (epoch 25), train_loss = 10.034, time/batch = 0.016\n",
      "1431/2800 (epoch 25), train_loss = 9.407, time/batch = 0.016\n",
      "1432/2800 (epoch 25), train_loss = 10.291, time/batch = 0.016\n",
      "1433/2800 (epoch 25), train_loss = 9.433, time/batch = 0.018\n",
      "1434/2800 (epoch 25), train_loss = 10.086, time/batch = 0.004\n",
      "1435/2800 (epoch 25), train_loss = 9.087, time/batch = 0.016\n",
      "1436/2800 (epoch 25), train_loss = 10.032, time/batch = 0.016\n",
      "1437/2800 (epoch 25), train_loss = 9.449, time/batch = 0.016\n",
      "1438/2800 (epoch 25), train_loss = 14.513, time/batch = 0.000\n",
      "1439/2800 (epoch 25), train_loss = 11.023, time/batch = 0.016\n",
      "1440/2800 (epoch 25), train_loss = 11.321, time/batch = 0.016\n",
      "1441/2800 (epoch 25), train_loss = 10.784, time/batch = 0.000\n",
      "1442/2800 (epoch 25), train_loss = 10.870, time/batch = 0.022\n",
      "1443/2800 (epoch 25), train_loss = 10.398, time/batch = 0.000\n",
      "1444/2800 (epoch 25), train_loss = 11.003, time/batch = 0.016\n",
      "1445/2800 (epoch 25), train_loss = 10.498, time/batch = 0.016\n",
      "1446/2800 (epoch 25), train_loss = 10.840, time/batch = 0.000\n",
      "1447/2800 (epoch 25), train_loss = 10.265, time/batch = 0.016\n",
      "1448/2800 (epoch 25), train_loss = 11.287, time/batch = 0.016\n",
      "1449/2800 (epoch 25), train_loss = 10.474, time/batch = 0.016\n",
      "1450/2800 (epoch 25), train_loss = 10.314, time/batch = 0.022\n",
      "1451/2800 (epoch 25), train_loss = 10.811, time/batch = 0.000\n",
      "1452/2800 (epoch 25), train_loss = 10.444, time/batch = 0.016\n",
      "1453/2800 (epoch 25), train_loss = 10.468, time/batch = 0.016\n",
      "1454/2800 (epoch 25), train_loss = 10.505, time/batch = 0.016\n",
      "1455/2800 (epoch 25), train_loss = 10.544, time/batch = 0.016\n",
      "1456/2800 (epoch 26), train_loss = 9.949, time/batch = 0.000\n",
      "1457/2800 (epoch 26), train_loss = 9.600, time/batch = 0.016\n",
      "1458/2800 (epoch 26), train_loss = 9.466, time/batch = 0.018\n",
      "1459/2800 (epoch 26), train_loss = 10.536, time/batch = 0.003\n",
      "1460/2800 (epoch 26), train_loss = 9.348, time/batch = 0.016\n",
      "1461/2800 (epoch 26), train_loss = 9.811, time/batch = 0.000\n",
      "1462/2800 (epoch 26), train_loss = 9.111, time/batch = 0.016\n",
      "1463/2800 (epoch 26), train_loss = 10.431, time/batch = 0.016\n",
      "1464/2800 (epoch 26), train_loss = 9.203, time/batch = 0.000\n",
      "1465/2800 (epoch 26), train_loss = 10.399, time/batch = 0.000\n",
      "1466/2800 (epoch 26), train_loss = 9.224, time/batch = 0.016\n",
      "1467/2800 (epoch 26), train_loss = 10.068, time/batch = 0.022\n",
      "1468/2800 (epoch 26), train_loss = 9.357, time/batch = 0.016\n",
      "1469/2800 (epoch 26), train_loss = 9.828, time/batch = 0.016\n",
      "1470/2800 (epoch 26), train_loss = 9.034, time/batch = 0.000\n",
      "1471/2800 (epoch 26), train_loss = 11.066, time/batch = 0.016\n",
      "1472/2800 (epoch 26), train_loss = 9.161, time/batch = 0.016\n",
      "1473/2800 (epoch 26), train_loss = 9.279, time/batch = 0.016\n",
      "1474/2800 (epoch 26), train_loss = 8.657, time/batch = 0.000\n",
      "1475/2800 (epoch 26), train_loss = 10.498, time/batch = 0.022\n",
      "1476/2800 (epoch 26), train_loss = 9.617, time/batch = 0.000\n",
      "1477/2800 (epoch 26), train_loss = 11.510, time/batch = 0.016\n",
      "1478/2800 (epoch 26), train_loss = 10.328, time/batch = 0.016\n",
      "1479/2800 (epoch 26), train_loss = 10.250, time/batch = 0.000\n",
      "1480/2800 (epoch 26), train_loss = 9.156, time/batch = 0.016\n",
      "1481/2800 (epoch 26), train_loss = 10.211, time/batch = 0.016\n",
      "1482/2800 (epoch 26), train_loss = 9.919, time/batch = 0.016\n",
      "1483/2800 (epoch 26), train_loss = 10.081, time/batch = 0.016\n",
      "1484/2800 (epoch 26), train_loss = 9.465, time/batch = 0.006\n",
      "1485/2800 (epoch 26), train_loss = 10.248, time/batch = 0.016\n",
      "1486/2800 (epoch 26), train_loss = 9.580, time/batch = 0.016\n",
      "1487/2800 (epoch 26), train_loss = 9.869, time/batch = 0.016\n",
      "1488/2800 (epoch 26), train_loss = 9.417, time/batch = 0.000\n",
      "1489/2800 (epoch 26), train_loss = 9.497, time/batch = 0.016\n",
      "1490/2800 (epoch 26), train_loss = 9.337, time/batch = 0.016\n",
      "1491/2800 (epoch 26), train_loss = 10.559, time/batch = 0.016\n",
      "1492/2800 (epoch 26), train_loss = 12.358, time/batch = 0.005\n",
      "1493/2800 (epoch 26), train_loss = 10.703, time/batch = 0.017\n",
      "1494/2800 (epoch 26), train_loss = 11.564, time/batch = 0.011\n",
      "1495/2800 (epoch 26), train_loss = 10.645, time/batch = 0.012\n",
      "1496/2800 (epoch 26), train_loss = 10.626, time/batch = 0.000\n",
      "1497/2800 (epoch 26), train_loss = 10.427, time/batch = 0.016\n",
      "1498/2800 (epoch 26), train_loss = 10.721, time/batch = 0.016\n",
      "1499/2800 (epoch 26), train_loss = 10.415, time/batch = 0.000\n",
      "1500/2800 (epoch 26), train_loss = 11.018, time/batch = 0.027\n",
      "model saved to save\\model.ckpt\n",
      "1501/2800 (epoch 26), train_loss = 10.346, time/batch = 0.031\n",
      "1502/2800 (epoch 26), train_loss = 10.055, time/batch = 0.038\n",
      "1503/2800 (epoch 26), train_loss = 11.973, time/batch = 0.031\n",
      "1504/2800 (epoch 26), train_loss = 10.400, time/batch = 0.031\n",
      "1505/2800 (epoch 26), train_loss = 10.229, time/batch = 0.022\n",
      "1506/2800 (epoch 26), train_loss = 11.574, time/batch = 0.031\n",
      "1507/2800 (epoch 26), train_loss = 10.791, time/batch = 0.047\n",
      "1508/2800 (epoch 26), train_loss = 10.437, time/batch = 0.038\n",
      "1509/2800 (epoch 26), train_loss = 10.694, time/batch = 0.047\n",
      "1510/2800 (epoch 26), train_loss = 10.517, time/batch = 0.040\n",
      "1511/2800 (epoch 26), train_loss = 10.674, time/batch = 0.028\n",
      "1512/2800 (epoch 27), train_loss = 9.835, time/batch = 0.047\n",
      "1513/2800 (epoch 27), train_loss = 9.878, time/batch = 0.031\n",
      "1514/2800 (epoch 27), train_loss = 9.419, time/batch = 0.038\n",
      "1515/2800 (epoch 27), train_loss = 10.780, time/batch = 0.047\n",
      "1516/2800 (epoch 27), train_loss = 9.018, time/batch = 0.053\n",
      "1517/2800 (epoch 27), train_loss = 9.862, time/batch = 0.031\n",
      "1518/2800 (epoch 27), train_loss = 11.017, time/batch = 0.053\n",
      "1519/2800 (epoch 27), train_loss = 9.947, time/batch = 0.031\n",
      "1520/2800 (epoch 27), train_loss = 9.707, time/batch = 0.047\n",
      "1521/2800 (epoch 27), train_loss = 9.470, time/batch = 0.055\n",
      "1522/2800 (epoch 27), train_loss = 9.450, time/batch = 0.040\n",
      "1523/2800 (epoch 27), train_loss = 9.662, time/batch = 0.040\n",
      "1524/2800 (epoch 27), train_loss = 9.667, time/batch = 0.038\n",
      "1525/2800 (epoch 27), train_loss = 9.081, time/batch = 0.038\n",
      "1526/2800 (epoch 27), train_loss = 9.577, time/batch = 0.035\n",
      "1527/2800 (epoch 27), train_loss = 9.151, time/batch = 0.042\n",
      "1528/2800 (epoch 27), train_loss = 9.876, time/batch = 0.045\n",
      "1529/2800 (epoch 27), train_loss = 9.315, time/batch = 0.048\n",
      "1530/2800 (epoch 27), train_loss = 9.574, time/batch = 0.034\n",
      "1531/2800 (epoch 27), train_loss = 9.269, time/batch = 0.034\n",
      "1532/2800 (epoch 27), train_loss = 9.889, time/batch = 0.031\n",
      "1533/2800 (epoch 27), train_loss = 10.157, time/batch = 0.028\n",
      "1534/2800 (epoch 27), train_loss = 9.711, time/batch = 0.032\n",
      "1535/2800 (epoch 27), train_loss = 9.819, time/batch = 0.015\n",
      "1536/2800 (epoch 27), train_loss = 9.370, time/batch = 0.032\n",
      "1537/2800 (epoch 27), train_loss = 9.979, time/batch = 0.031\n",
      "1538/2800 (epoch 27), train_loss = 9.105, time/batch = 0.038\n",
      "1539/2800 (epoch 27), train_loss = 9.804, time/batch = 0.031\n",
      "1540/2800 (epoch 27), train_loss = 9.566, time/batch = 0.031\n",
      "1541/2800 (epoch 27), train_loss = 10.265, time/batch = 0.038\n",
      "1542/2800 (epoch 27), train_loss = 9.529, time/batch = 0.031\n",
      "1543/2800 (epoch 27), train_loss = 9.602, time/batch = 0.048\n",
      "1544/2800 (epoch 27), train_loss = 9.208, time/batch = 0.036\n",
      "1545/2800 (epoch 27), train_loss = 9.519, time/batch = 0.031\n",
      "1546/2800 (epoch 27), train_loss = 12.338, time/batch = 0.031\n",
      "1547/2800 (epoch 27), train_loss = 10.748, time/batch = 0.024\n",
      "1548/2800 (epoch 27), train_loss = 10.899, time/batch = 0.025\n",
      "1549/2800 (epoch 27), train_loss = 10.962, time/batch = 0.027\n",
      "1550/2800 (epoch 27), train_loss = 10.585, time/batch = 0.026\n",
      "1551/2800 (epoch 27), train_loss = 10.623, time/batch = 0.027\n",
      "1552/2800 (epoch 27), train_loss = 10.485, time/batch = 0.026\n",
      "1553/2800 (epoch 27), train_loss = 10.844, time/batch = 0.028\n",
      "1554/2800 (epoch 27), train_loss = 10.508, time/batch = 0.013\n",
      "1555/2800 (epoch 27), train_loss = 10.376, time/batch = 0.031\n",
      "1556/2800 (epoch 27), train_loss = 11.034, time/batch = 0.016\n",
      "1557/2800 (epoch 27), train_loss = 10.765, time/batch = 0.016\n",
      "1558/2800 (epoch 27), train_loss = 10.320, time/batch = 0.032\n",
      "1559/2800 (epoch 27), train_loss = 10.649, time/batch = 0.021\n",
      "1560/2800 (epoch 27), train_loss = 10.439, time/batch = 0.016\n",
      "1561/2800 (epoch 27), train_loss = 11.115, time/batch = 0.031\n",
      "1562/2800 (epoch 27), train_loss = 10.291, time/batch = 0.036\n",
      "1563/2800 (epoch 27), train_loss = 10.559, time/batch = 0.016\n",
      "1564/2800 (epoch 27), train_loss = 10.276, time/batch = 0.016\n",
      "1565/2800 (epoch 27), train_loss = 10.266, time/batch = 0.031\n",
      "1566/2800 (epoch 27), train_loss = 10.218, time/batch = 0.016\n",
      "1567/2800 (epoch 27), train_loss = 9.377, time/batch = 0.022\n",
      "1568/2800 (epoch 28), train_loss = 10.418, time/batch = 0.032\n",
      "1569/2800 (epoch 28), train_loss = 9.077, time/batch = 0.016\n",
      "1570/2800 (epoch 28), train_loss = 9.219, time/batch = 0.031\n",
      "1571/2800 (epoch 28), train_loss = 9.143, time/batch = 0.022\n",
      "1572/2800 (epoch 28), train_loss = 9.722, time/batch = 0.031\n",
      "1573/2800 (epoch 28), train_loss = 9.332, time/batch = 0.016\n",
      "1574/2800 (epoch 28), train_loss = 9.474, time/batch = 0.016\n",
      "1575/2800 (epoch 28), train_loss = 9.460, time/batch = 0.036\n",
      "1576/2800 (epoch 28), train_loss = 10.219, time/batch = 0.017\n",
      "1577/2800 (epoch 28), train_loss = 9.168, time/batch = 0.016\n",
      "1578/2800 (epoch 28), train_loss = 10.226, time/batch = 0.031\n",
      "1579/2800 (epoch 28), train_loss = 9.762, time/batch = 0.016\n",
      "1580/2800 (epoch 28), train_loss = 9.730, time/batch = 0.023\n",
      "1581/2800 (epoch 28), train_loss = 9.132, time/batch = 0.016\n",
      "1582/2800 (epoch 28), train_loss = 9.755, time/batch = 0.031\n",
      "1583/2800 (epoch 28), train_loss = 9.499, time/batch = 0.016\n",
      "1584/2800 (epoch 28), train_loss = 9.297, time/batch = 0.022\n",
      "1585/2800 (epoch 28), train_loss = 9.335, time/batch = 0.031\n",
      "1586/2800 (epoch 28), train_loss = 9.312, time/batch = 0.016\n",
      "1587/2800 (epoch 28), train_loss = 9.257, time/batch = 0.031\n",
      "1588/2800 (epoch 28), train_loss = 9.568, time/batch = 0.022\n",
      "1589/2800 (epoch 28), train_loss = 9.185, time/batch = 0.031\n",
      "1590/2800 (epoch 28), train_loss = 10.022, time/batch = 0.031\n",
      "1591/2800 (epoch 28), train_loss = 10.013, time/batch = 0.016\n",
      "1592/2800 (epoch 28), train_loss = 10.019, time/batch = 0.022\n",
      "1593/2800 (epoch 28), train_loss = 9.764, time/batch = 0.016\n",
      "1594/2800 (epoch 28), train_loss = 10.161, time/batch = 0.031\n",
      "1595/2800 (epoch 28), train_loss = 9.449, time/batch = 0.031\n",
      "1596/2800 (epoch 28), train_loss = 10.046, time/batch = 0.022\n",
      "1597/2800 (epoch 28), train_loss = 9.419, time/batch = 0.016\n",
      "1598/2800 (epoch 28), train_loss = 10.029, time/batch = 0.016\n",
      "1599/2800 (epoch 28), train_loss = 9.668, time/batch = 0.036\n",
      "1600/2800 (epoch 28), train_loss = 9.612, time/batch = 0.017\n",
      "1601/2800 (epoch 28), train_loss = 9.323, time/batch = 0.016\n",
      "1602/2800 (epoch 28), train_loss = 9.682, time/batch = 0.031\n",
      "1603/2800 (epoch 28), train_loss = 9.512, time/batch = 0.016\n",
      "1604/2800 (epoch 28), train_loss = 11.480, time/batch = 0.023\n",
      "1605/2800 (epoch 28), train_loss = 11.238, time/batch = 0.031\n",
      "1606/2800 (epoch 28), train_loss = 10.796, time/batch = 0.016\n",
      "1607/2800 (epoch 28), train_loss = 10.878, time/batch = 0.016\n",
      "1608/2800 (epoch 28), train_loss = 10.740, time/batch = 0.016\n",
      "1609/2800 (epoch 28), train_loss = 10.537, time/batch = 0.022\n",
      "1610/2800 (epoch 28), train_loss = 10.695, time/batch = 0.016\n",
      "1611/2800 (epoch 28), train_loss = 10.520, time/batch = 0.016\n",
      "1612/2800 (epoch 28), train_loss = 10.800, time/batch = 0.016\n",
      "1613/2800 (epoch 28), train_loss = 10.486, time/batch = 0.016\n",
      "1614/2800 (epoch 28), train_loss = 10.518, time/batch = 0.022\n",
      "1615/2800 (epoch 28), train_loss = 10.983, time/batch = 0.016\n",
      "1616/2800 (epoch 28), train_loss = 10.687, time/batch = 0.031\n",
      "1617/2800 (epoch 28), train_loss = 10.163, time/batch = 0.016\n",
      "1618/2800 (epoch 28), train_loss = 11.809, time/batch = 0.016\n",
      "1619/2800 (epoch 28), train_loss = 10.693, time/batch = 0.022\n",
      "1620/2800 (epoch 28), train_loss = 10.488, time/batch = 0.016\n",
      "1621/2800 (epoch 28), train_loss = 10.767, time/batch = 0.016\n",
      "1622/2800 (epoch 28), train_loss = 10.239, time/batch = 0.016\n",
      "1623/2800 (epoch 28), train_loss = 10.601, time/batch = 0.031\n",
      "1624/2800 (epoch 29), train_loss = 9.828, time/batch = 0.022\n",
      "1625/2800 (epoch 29), train_loss = 9.668, time/batch = 0.016\n",
      "1626/2800 (epoch 29), train_loss = 9.723, time/batch = 0.016\n",
      "1627/2800 (epoch 29), train_loss = 10.322, time/batch = 0.031\n",
      "1628/2800 (epoch 29), train_loss = 9.466, time/batch = 0.016\n",
      "1629/2800 (epoch 29), train_loss = 9.814, time/batch = 0.022\n",
      "1630/2800 (epoch 29), train_loss = 9.115, time/batch = 0.016\n",
      "1631/2800 (epoch 29), train_loss = 10.064, time/batch = 0.016\n",
      "1632/2800 (epoch 29), train_loss = 9.368, time/batch = 0.016\n",
      "1633/2800 (epoch 29), train_loss = 9.879, time/batch = 0.016\n",
      "1634/2800 (epoch 29), train_loss = 9.700, time/batch = 0.016\n",
      "1635/2800 (epoch 29), train_loss = 9.171, time/batch = 0.022\n",
      "1636/2800 (epoch 29), train_loss = 10.219, time/batch = 0.031\n",
      "1637/2800 (epoch 29), train_loss = 9.140, time/batch = 0.016\n",
      "1638/2800 (epoch 29), train_loss = 9.502, time/batch = 0.016\n",
      "1639/2800 (epoch 29), train_loss = 9.820, time/batch = 0.036\n",
      "1640/2800 (epoch 29), train_loss = 9.791, time/batch = 0.017\n",
      "1641/2800 (epoch 29), train_loss = 9.188, time/batch = 0.016\n",
      "1642/2800 (epoch 29), train_loss = 9.465, time/batch = 0.016\n",
      "1643/2800 (epoch 29), train_loss = 9.427, time/batch = 0.016\n",
      "1644/2800 (epoch 29), train_loss = 9.164, time/batch = 0.016\n",
      "1645/2800 (epoch 29), train_loss = 9.582, time/batch = 0.022\n",
      "1646/2800 (epoch 29), train_loss = 9.172, time/batch = 0.016\n",
      "1647/2800 (epoch 29), train_loss = 10.121, time/batch = 0.031\n",
      "1648/2800 (epoch 29), train_loss = 9.605, time/batch = 0.016\n",
      "1649/2800 (epoch 29), train_loss = 9.942, time/batch = 0.033\n",
      "1650/2800 (epoch 29), train_loss = 9.848, time/batch = 0.022\n",
      "1651/2800 (epoch 29), train_loss = 9.694, time/batch = 0.017\n",
      "1652/2800 (epoch 29), train_loss = 9.308, time/batch = 0.016\n",
      "1653/2800 (epoch 29), train_loss = 9.464, time/batch = 0.024\n",
      "1654/2800 (epoch 29), train_loss = 10.099, time/batch = 0.017\n",
      "1655/2800 (epoch 29), train_loss = 9.798, time/batch = 0.006\n",
      "1656/2800 (epoch 29), train_loss = 9.728, time/batch = 0.021\n",
      "1657/2800 (epoch 29), train_loss = 9.202, time/batch = 0.031\n",
      "1658/2800 (epoch 29), train_loss = 10.092, time/batch = 0.016\n",
      "1659/2800 (epoch 29), train_loss = 10.961, time/batch = 0.016\n",
      "1660/2800 (epoch 29), train_loss = 11.506, time/batch = 0.037\n",
      "1661/2800 (epoch 29), train_loss = 10.798, time/batch = 0.020\n",
      "1662/2800 (epoch 29), train_loss = 10.944, time/batch = 0.016\n",
      "1663/2800 (epoch 29), train_loss = 10.606, time/batch = 0.016\n",
      "1664/2800 (epoch 29), train_loss = 10.579, time/batch = 0.016\n",
      "1665/2800 (epoch 29), train_loss = 10.577, time/batch = 0.016\n",
      "1666/2800 (epoch 29), train_loss = 10.589, time/batch = 0.016\n",
      "1667/2800 (epoch 29), train_loss = 10.881, time/batch = 0.022\n",
      "1668/2800 (epoch 29), train_loss = 10.506, time/batch = 0.031\n",
      "1669/2800 (epoch 29), train_loss = 10.678, time/batch = 0.031\n",
      "1670/2800 (epoch 29), train_loss = 10.440, time/batch = 0.016\n",
      "1671/2800 (epoch 29), train_loss = 10.705, time/batch = 0.022\n",
      "1672/2800 (epoch 29), train_loss = 10.501, time/batch = 0.016\n",
      "1673/2800 (epoch 29), train_loss = 10.687, time/batch = 0.016\n",
      "1674/2800 (epoch 29), train_loss = 10.531, time/batch = 0.016\n",
      "1675/2800 (epoch 29), train_loss = 10.090, time/batch = 0.016\n",
      "1676/2800 (epoch 29), train_loss = 12.320, time/batch = 0.016\n",
      "1677/2800 (epoch 29), train_loss = 10.012, time/batch = 0.022\n",
      "1678/2800 (epoch 29), train_loss = 11.235, time/batch = 0.016\n",
      "1679/2800 (epoch 29), train_loss = 10.202, time/batch = 0.031\n",
      "1680/2800 (epoch 30), train_loss = 9.864, time/batch = 0.016\n",
      "1681/2800 (epoch 30), train_loss = 9.797, time/batch = 0.016\n",
      "1682/2800 (epoch 30), train_loss = 9.878, time/batch = 0.022\n",
      "1683/2800 (epoch 30), train_loss = 9.388, time/batch = 0.016\n",
      "1684/2800 (epoch 30), train_loss = 9.988, time/batch = 0.031\n",
      "1685/2800 (epoch 30), train_loss = 9.439, time/batch = 0.016\n",
      "1686/2800 (epoch 30), train_loss = 9.778, time/batch = 0.016\n",
      "1687/2800 (epoch 30), train_loss = 9.103, time/batch = 0.021\n",
      "1688/2800 (epoch 30), train_loss = 10.468, time/batch = 0.016\n",
      "1689/2800 (epoch 30), train_loss = 8.995, time/batch = 0.016\n",
      "1690/2800 (epoch 30), train_loss = 8.752, time/batch = 0.016\n",
      "1691/2800 (epoch 30), train_loss = 11.541, time/batch = 0.016\n",
      "1692/2800 (epoch 30), train_loss = 9.215, time/batch = 0.021\n",
      "1693/2800 (epoch 30), train_loss = 10.178, time/batch = 0.017\n",
      "1694/2800 (epoch 30), train_loss = 9.122, time/batch = 0.016\n",
      "1695/2800 (epoch 30), train_loss = 9.314, time/batch = 0.016\n",
      "1696/2800 (epoch 30), train_loss = 9.552, time/batch = 0.016\n",
      "1697/2800 (epoch 30), train_loss = 9.242, time/batch = 0.016\n",
      "1698/2800 (epoch 30), train_loss = 9.054, time/batch = 0.022\n",
      "1699/2800 (epoch 30), train_loss = 9.229, time/batch = 0.016\n",
      "1700/2800 (epoch 30), train_loss = 9.424, time/batch = 0.016\n",
      "1701/2800 (epoch 30), train_loss = 9.800, time/batch = 0.016\n",
      "1702/2800 (epoch 30), train_loss = 9.522, time/batch = 0.031\n",
      "1703/2800 (epoch 30), train_loss = 9.334, time/batch = 0.022\n",
      "1704/2800 (epoch 30), train_loss = 9.907, time/batch = 0.016\n",
      "1705/2800 (epoch 30), train_loss = 9.285, time/batch = 0.016\n",
      "1706/2800 (epoch 30), train_loss = 9.562, time/batch = 0.016\n",
      "1707/2800 (epoch 30), train_loss = 10.156, time/batch = 0.016\n",
      "1708/2800 (epoch 30), train_loss = 9.596, time/batch = 0.016\n",
      "1709/2800 (epoch 30), train_loss = 9.948, time/batch = 0.022\n",
      "1710/2800 (epoch 30), train_loss = 9.639, time/batch = 0.016\n",
      "1711/2800 (epoch 30), train_loss = 9.608, time/batch = 0.016\n",
      "1712/2800 (epoch 30), train_loss = 9.666, time/batch = 0.016\n",
      "1713/2800 (epoch 30), train_loss = 10.027, time/batch = 0.031\n",
      "1714/2800 (epoch 30), train_loss = 9.512, time/batch = 0.022\n",
      "1715/2800 (epoch 30), train_loss = 9.771, time/batch = 0.016\n",
      "1716/2800 (epoch 30), train_loss = 9.468, time/batch = 0.016\n",
      "1717/2800 (epoch 30), train_loss = 9.351, time/batch = 0.000\n",
      "1718/2800 (epoch 30), train_loss = 10.862, time/batch = 0.000\n",
      "1719/2800 (epoch 30), train_loss = 11.891, time/batch = 0.016\n",
      "1720/2800 (epoch 30), train_loss = 10.718, time/batch = 0.016\n",
      "1721/2800 (epoch 30), train_loss = 11.228, time/batch = 0.000\n",
      "1722/2800 (epoch 30), train_loss = 10.541, time/batch = 0.022\n",
      "1723/2800 (epoch 30), train_loss = 10.790, time/batch = 0.000\n",
      "1724/2800 (epoch 30), train_loss = 10.323, time/batch = 0.016\n",
      "1725/2800 (epoch 30), train_loss = 10.882, time/batch = 0.016\n",
      "1726/2800 (epoch 30), train_loss = 10.495, time/batch = 0.016\n",
      "1727/2800 (epoch 30), train_loss = 10.908, time/batch = 0.016\n",
      "1728/2800 (epoch 30), train_loss = 10.356, time/batch = 0.000\n",
      "1729/2800 (epoch 30), train_loss = 11.465, time/batch = 0.016\n",
      "1730/2800 (epoch 30), train_loss = 10.401, time/batch = 0.022\n",
      "1731/2800 (epoch 30), train_loss = 10.521, time/batch = 0.000\n",
      "1732/2800 (epoch 30), train_loss = 10.857, time/batch = 0.016\n",
      "1733/2800 (epoch 30), train_loss = 10.772, time/batch = 0.016\n",
      "1734/2800 (epoch 30), train_loss = 10.248, time/batch = 0.000\n",
      "1735/2800 (epoch 30), train_loss = 10.963, time/batch = 0.000\n",
      "1736/2800 (epoch 31), train_loss = 9.768, time/batch = 0.016\n",
      "1737/2800 (epoch 31), train_loss = 9.751, time/batch = 0.016\n",
      "1738/2800 (epoch 31), train_loss = 9.433, time/batch = 0.000\n",
      "1739/2800 (epoch 31), train_loss = 10.368, time/batch = 0.022\n",
      "1740/2800 (epoch 31), train_loss = 9.322, time/batch = 0.000\n",
      "1741/2800 (epoch 31), train_loss = 9.630, time/batch = 0.016\n",
      "1742/2800 (epoch 31), train_loss = 9.108, time/batch = 0.016\n",
      "1743/2800 (epoch 31), train_loss = 10.287, time/batch = 0.016\n",
      "1744/2800 (epoch 31), train_loss = 9.167, time/batch = 0.016\n",
      "1745/2800 (epoch 31), train_loss = 10.027, time/batch = 0.016\n",
      "1746/2800 (epoch 31), train_loss = 8.893, time/batch = 0.000\n",
      "1747/2800 (epoch 31), train_loss = 9.856, time/batch = 0.022\n",
      "1748/2800 (epoch 31), train_loss = 10.018, time/batch = 0.016\n",
      "1749/2800 (epoch 31), train_loss = 9.523, time/batch = 0.000\n",
      "1750/2800 (epoch 31), train_loss = 8.793, time/batch = 0.016\n",
      "1751/2800 (epoch 31), train_loss = 9.730, time/batch = 0.016\n",
      "1752/2800 (epoch 31), train_loss = 9.363, time/batch = 0.000\n",
      "1753/2800 (epoch 31), train_loss = 9.846, time/batch = 0.016\n",
      "1754/2800 (epoch 31), train_loss = 9.112, time/batch = 0.016\n",
      "1755/2800 (epoch 31), train_loss = 9.286, time/batch = 0.016\n",
      "1756/2800 (epoch 31), train_loss = 9.131, time/batch = 0.005\n",
      "1757/2800 (epoch 31), train_loss = 9.315, time/batch = 0.016\n",
      "1758/2800 (epoch 31), train_loss = 9.041, time/batch = 0.000\n",
      "1759/2800 (epoch 31), train_loss = 9.756, time/batch = 0.031\n",
      "1760/2800 (epoch 31), train_loss = 9.216, time/batch = 0.016\n",
      "1761/2800 (epoch 31), train_loss = 9.219, time/batch = 0.000\n",
      "1762/2800 (epoch 31), train_loss = 11.310, time/batch = 0.000\n",
      "1763/2800 (epoch 31), train_loss = 9.470, time/batch = 0.022\n",
      "1764/2800 (epoch 31), train_loss = 10.650, time/batch = 0.016\n",
      "1765/2800 (epoch 31), train_loss = 9.272, time/batch = 0.000\n",
      "1766/2800 (epoch 31), train_loss = 10.131, time/batch = 0.016\n",
      "1767/2800 (epoch 31), train_loss = 9.507, time/batch = 0.016\n",
      "1768/2800 (epoch 31), train_loss = 10.383, time/batch = 0.000\n",
      "1769/2800 (epoch 31), train_loss = 9.143, time/batch = 0.016\n",
      "1770/2800 (epoch 31), train_loss = 10.016, time/batch = 0.016\n",
      "1771/2800 (epoch 31), train_loss = 9.442, time/batch = 0.000\n",
      "1772/2800 (epoch 31), train_loss = 9.785, time/batch = 0.022\n",
      "1773/2800 (epoch 31), train_loss = 9.594, time/batch = 0.000\n",
      "1774/2800 (epoch 31), train_loss = 10.770, time/batch = 0.016\n",
      "1775/2800 (epoch 31), train_loss = 11.285, time/batch = 0.016\n",
      "1776/2800 (epoch 31), train_loss = 10.854, time/batch = 0.016\n",
      "1777/2800 (epoch 31), train_loss = 10.714, time/batch = 0.016\n",
      "1778/2800 (epoch 31), train_loss = 10.642, time/batch = 0.000\n",
      "1779/2800 (epoch 31), train_loss = 10.588, time/batch = 0.016\n",
      "1780/2800 (epoch 31), train_loss = 10.700, time/batch = 0.022\n",
      "1781/2800 (epoch 31), train_loss = 10.477, time/batch = 0.016\n",
      "1782/2800 (epoch 31), train_loss = 10.752, time/batch = 0.016\n",
      "1783/2800 (epoch 31), train_loss = 10.666, time/batch = 0.000\n",
      "1784/2800 (epoch 31), train_loss = 10.560, time/batch = 0.016\n",
      "1785/2800 (epoch 31), train_loss = 10.881, time/batch = 0.016\n",
      "1786/2800 (epoch 31), train_loss = 10.853, time/batch = 0.016\n",
      "1787/2800 (epoch 31), train_loss = 10.486, time/batch = 0.000\n",
      "1788/2800 (epoch 31), train_loss = 10.894, time/batch = 0.022\n",
      "1789/2800 (epoch 31), train_loss = 10.744, time/batch = 0.000\n",
      "1790/2800 (epoch 31), train_loss = 10.382, time/batch = 0.016\n",
      "1791/2800 (epoch 31), train_loss = 10.301, time/batch = 0.016\n",
      "1792/2800 (epoch 32), train_loss = 9.921, time/batch = 0.000\n",
      "1793/2800 (epoch 32), train_loss = 9.428, time/batch = 0.016\n",
      "1794/2800 (epoch 32), train_loss = 9.419, time/batch = 0.016\n",
      "1795/2800 (epoch 32), train_loss = 9.522, time/batch = 0.016\n",
      "1796/2800 (epoch 32), train_loss = 9.196, time/batch = 0.020\n",
      "1797/2800 (epoch 32), train_loss = 9.573, time/batch = 0.002\n",
      "1798/2800 (epoch 32), train_loss = 9.754, time/batch = 0.016\n",
      "1799/2800 (epoch 32), train_loss = 9.799, time/batch = 0.016\n",
      "1800/2800 (epoch 32), train_loss = 9.641, time/batch = 0.016\n",
      "1801/2800 (epoch 32), train_loss = 9.769, time/batch = 0.000\n",
      "1802/2800 (epoch 32), train_loss = 9.535, time/batch = 0.016\n",
      "1803/2800 (epoch 32), train_loss = 9.529, time/batch = 0.016\n",
      "1804/2800 (epoch 32), train_loss = 9.126, time/batch = 0.000\n",
      "1805/2800 (epoch 32), train_loss = 10.486, time/batch = 0.007\n",
      "1806/2800 (epoch 32), train_loss = 9.221, time/batch = 0.000\n",
      "1807/2800 (epoch 32), train_loss = 9.289, time/batch = 0.016\n",
      "1808/2800 (epoch 32), train_loss = 9.616, time/batch = 0.016\n",
      "1809/2800 (epoch 32), train_loss = 9.203, time/batch = 0.016\n",
      "1810/2800 (epoch 32), train_loss = 9.330, time/batch = 0.000\n",
      "1811/2800 (epoch 32), train_loss = 9.158, time/batch = 0.016\n",
      "1812/2800 (epoch 32), train_loss = 9.524, time/batch = 0.016\n",
      "1813/2800 (epoch 32), train_loss = 9.275, time/batch = 0.022\n",
      "1814/2800 (epoch 32), train_loss = 9.252, time/batch = 0.000\n",
      "1815/2800 (epoch 32), train_loss = 9.511, time/batch = 0.016\n",
      "1816/2800 (epoch 32), train_loss = 9.763, time/batch = 0.016\n",
      "1817/2800 (epoch 32), train_loss = 9.724, time/batch = 0.016\n",
      "1818/2800 (epoch 32), train_loss = 9.875, time/batch = 0.000\n",
      "1819/2800 (epoch 32), train_loss = 9.707, time/batch = 0.016\n",
      "1820/2800 (epoch 32), train_loss = 9.279, time/batch = 0.016\n",
      "1821/2800 (epoch 32), train_loss = 9.332, time/batch = 0.000\n",
      "1822/2800 (epoch 32), train_loss = 9.800, time/batch = 0.007\n",
      "1823/2800 (epoch 32), train_loss = 9.806, time/batch = 0.000\n",
      "1824/2800 (epoch 32), train_loss = 9.955, time/batch = 0.016\n",
      "1825/2800 (epoch 32), train_loss = 9.216, time/batch = 0.016\n",
      "1826/2800 (epoch 32), train_loss = 9.773, time/batch = 0.000\n",
      "1827/2800 (epoch 32), train_loss = 9.103, time/batch = 0.000\n",
      "1828/2800 (epoch 32), train_loss = 10.597, time/batch = 0.016\n",
      "1829/2800 (epoch 32), train_loss = 10.727, time/batch = 0.016\n",
      "1830/2800 (epoch 32), train_loss = 11.341, time/batch = 0.021\n",
      "1831/2800 (epoch 32), train_loss = 11.010, time/batch = 0.000\n",
      "1832/2800 (epoch 32), train_loss = 11.428, time/batch = 0.016\n",
      "1833/2800 (epoch 32), train_loss = 10.691, time/batch = 0.016\n",
      "1834/2800 (epoch 32), train_loss = 10.697, time/batch = 0.016\n",
      "1835/2800 (epoch 32), train_loss = 10.447, time/batch = 0.000\n",
      "1836/2800 (epoch 32), train_loss = 10.768, time/batch = 0.016\n",
      "1837/2800 (epoch 32), train_loss = 10.646, time/batch = 0.016\n",
      "1838/2800 (epoch 32), train_loss = 11.008, time/batch = 0.000\n",
      "1839/2800 (epoch 32), train_loss = 10.365, time/batch = 0.022\n",
      "1840/2800 (epoch 32), train_loss = 11.455, time/batch = 0.000\n",
      "1841/2800 (epoch 32), train_loss = 10.280, time/batch = 0.016\n",
      "1842/2800 (epoch 32), train_loss = 10.437, time/batch = 0.016\n",
      "1843/2800 (epoch 32), train_loss = 10.505, time/batch = 0.000\n",
      "1844/2800 (epoch 32), train_loss = 11.644, time/batch = 0.016\n",
      "1845/2800 (epoch 32), train_loss = 10.294, time/batch = 0.016\n",
      "1846/2800 (epoch 32), train_loss = 10.710, time/batch = 0.016\n",
      "1847/2800 (epoch 32), train_loss = 10.045, time/batch = 0.020\n",
      "1848/2800 (epoch 33), train_loss = 10.568, time/batch = 0.002\n",
      "1849/2800 (epoch 33), train_loss = 9.507, time/batch = 0.016\n",
      "1850/2800 (epoch 33), train_loss = 10.125, time/batch = 0.016\n",
      "1851/2800 (epoch 33), train_loss = 9.186, time/batch = 0.016\n",
      "1852/2800 (epoch 33), train_loss = 10.767, time/batch = 0.000\n",
      "1853/2800 (epoch 33), train_loss = 9.014, time/batch = 0.016\n",
      "1854/2800 (epoch 33), train_loss = 10.249, time/batch = 0.016\n",
      "1855/2800 (epoch 33), train_loss = 9.058, time/batch = 0.000\n",
      "1856/2800 (epoch 33), train_loss = 10.377, time/batch = 0.022\n",
      "1857/2800 (epoch 33), train_loss = 8.933, time/batch = 0.000\n",
      "1858/2800 (epoch 33), train_loss = 11.221, time/batch = 0.016\n",
      "1859/2800 (epoch 33), train_loss = 9.017, time/batch = 0.016\n",
      "1860/2800 (epoch 33), train_loss = 9.920, time/batch = 0.000\n",
      "1861/2800 (epoch 33), train_loss = 9.506, time/batch = 0.016\n",
      "1862/2800 (epoch 33), train_loss = 9.304, time/batch = 0.016\n",
      "1863/2800 (epoch 33), train_loss = 9.801, time/batch = 0.016\n",
      "1864/2800 (epoch 33), train_loss = 9.200, time/batch = 0.019\n",
      "1865/2800 (epoch 33), train_loss = 10.118, time/batch = 0.003\n",
      "1866/2800 (epoch 33), train_loss = 9.264, time/batch = 0.016\n",
      "1867/2800 (epoch 33), train_loss = 9.599, time/batch = 0.016\n",
      "1868/2800 (epoch 33), train_loss = 9.471, time/batch = 0.016\n",
      "1869/2800 (epoch 33), train_loss = 9.719, time/batch = 0.000\n",
      "1870/2800 (epoch 33), train_loss = 9.155, time/batch = 0.016\n",
      "1871/2800 (epoch 33), train_loss = 10.354, time/batch = 0.016\n",
      "1872/2800 (epoch 33), train_loss = 9.297, time/batch = 0.000\n",
      "1873/2800 (epoch 33), train_loss = 10.525, time/batch = 0.022\n",
      "1874/2800 (epoch 33), train_loss = 9.321, time/batch = 0.000\n",
      "1875/2800 (epoch 33), train_loss = 10.199, time/batch = 0.016\n",
      "1876/2800 (epoch 33), train_loss = 9.117, time/batch = 0.016\n",
      "1877/2800 (epoch 33), train_loss = 10.362, time/batch = 0.000\n",
      "1878/2800 (epoch 33), train_loss = 9.655, time/batch = 0.016\n",
      "1879/2800 (epoch 33), train_loss = 9.835, time/batch = 0.031\n",
      "1880/2800 (epoch 33), train_loss = 9.437, time/batch = 0.000\n",
      "1881/2800 (epoch 33), train_loss = 9.699, time/batch = 0.023\n",
      "1882/2800 (epoch 33), train_loss = 9.377, time/batch = 0.016\n",
      "1883/2800 (epoch 33), train_loss = 10.187, time/batch = 0.016\n",
      "1884/2800 (epoch 33), train_loss = 11.530, time/batch = 0.016\n",
      "1885/2800 (epoch 33), train_loss = 10.868, time/batch = 0.000\n",
      "1886/2800 (epoch 33), train_loss = 11.309, time/batch = 0.016\n",
      "1887/2800 (epoch 33), train_loss = 10.548, time/batch = 0.016\n",
      "1888/2800 (epoch 33), train_loss = 10.773, time/batch = 0.000\n",
      "1889/2800 (epoch 33), train_loss = 10.405, time/batch = 0.022\n",
      "1890/2800 (epoch 33), train_loss = 10.745, time/batch = 0.000\n",
      "1891/2800 (epoch 33), train_loss = 10.458, time/batch = 0.016\n",
      "1892/2800 (epoch 33), train_loss = 10.990, time/batch = 0.016\n",
      "1893/2800 (epoch 33), train_loss = 10.532, time/batch = 0.000\n",
      "1894/2800 (epoch 33), train_loss = 10.494, time/batch = 0.016\n",
      "1895/2800 (epoch 33), train_loss = 10.303, time/batch = 0.016\n",
      "1896/2800 (epoch 33), train_loss = 11.506, time/batch = 0.016\n",
      "1897/2800 (epoch 33), train_loss = 10.850, time/batch = 0.022\n",
      "1898/2800 (epoch 33), train_loss = 10.207, time/batch = 0.001\n",
      "1899/2800 (epoch 33), train_loss = 10.164, time/batch = 0.016\n",
      "1900/2800 (epoch 33), train_loss = 10.187, time/batch = 0.016\n",
      "1901/2800 (epoch 33), train_loss = 11.168, time/batch = 0.016\n",
      "1902/2800 (epoch 33), train_loss = 10.493, time/batch = 0.000\n",
      "1903/2800 (epoch 33), train_loss = 10.255, time/batch = 0.016\n",
      "1904/2800 (epoch 34), train_loss = 9.999, time/batch = 0.016\n",
      "1905/2800 (epoch 34), train_loss = 9.360, time/batch = 0.017\n",
      "1906/2800 (epoch 34), train_loss = 9.885, time/batch = 0.004\n",
      "1907/2800 (epoch 34), train_loss = 10.182, time/batch = 0.016\n",
      "1908/2800 (epoch 34), train_loss = 9.143, time/batch = 0.000\n",
      "1909/2800 (epoch 34), train_loss = 10.024, time/batch = 0.016\n",
      "1910/2800 (epoch 34), train_loss = 9.498, time/batch = 0.016\n",
      "1911/2800 (epoch 34), train_loss = 10.258, time/batch = 0.016\n",
      "1912/2800 (epoch 34), train_loss = 8.911, time/batch = 0.000\n",
      "1913/2800 (epoch 34), train_loss = 10.443, time/batch = 0.000\n",
      "1914/2800 (epoch 34), train_loss = 9.425, time/batch = 0.022\n",
      "1915/2800 (epoch 34), train_loss = 9.700, time/batch = 0.016\n",
      "1916/2800 (epoch 34), train_loss = 8.722, time/batch = 0.000\n",
      "1917/2800 (epoch 34), train_loss = 12.039, time/batch = 0.016\n",
      "1918/2800 (epoch 34), train_loss = 9.822, time/batch = 0.016\n",
      "1919/2800 (epoch 34), train_loss = 10.464, time/batch = 0.016\n",
      "1920/2800 (epoch 34), train_loss = 9.168, time/batch = 0.000\n",
      "1921/2800 (epoch 34), train_loss = 9.777, time/batch = 0.016\n",
      "1922/2800 (epoch 34), train_loss = 9.212, time/batch = 0.021\n",
      "1923/2800 (epoch 34), train_loss = 9.766, time/batch = 0.000\n",
      "1924/2800 (epoch 34), train_loss = 9.313, time/batch = 0.016\n",
      "1925/2800 (epoch 34), train_loss = 10.214, time/batch = 0.016\n",
      "1926/2800 (epoch 34), train_loss = 9.461, time/batch = 0.000\n",
      "1927/2800 (epoch 34), train_loss = 8.945, time/batch = 0.016\n",
      "1928/2800 (epoch 34), train_loss = 9.924, time/batch = 0.016\n",
      "1929/2800 (epoch 34), train_loss = 9.381, time/batch = 0.016\n",
      "1930/2800 (epoch 34), train_loss = 10.890, time/batch = 0.017\n",
      "1931/2800 (epoch 34), train_loss = 9.006, time/batch = 0.006\n",
      "1932/2800 (epoch 34), train_loss = 11.121, time/batch = 0.016\n",
      "1933/2800 (epoch 34), train_loss = 9.303, time/batch = 0.016\n",
      "1934/2800 (epoch 34), train_loss = 9.324, time/batch = 0.000\n",
      "1935/2800 (epoch 34), train_loss = 10.167, time/batch = 0.016\n",
      "1936/2800 (epoch 34), train_loss = 8.941, time/batch = 0.016\n",
      "1937/2800 (epoch 34), train_loss = 12.787, time/batch = 0.016\n",
      "1938/2800 (epoch 34), train_loss = 10.854, time/batch = 0.000\n",
      "1939/2800 (epoch 34), train_loss = 13.280, time/batch = 0.022\n",
      "1940/2800 (epoch 34), train_loss = 11.436, time/batch = 0.000\n",
      "1941/2800 (epoch 34), train_loss = 12.961, time/batch = 0.016\n",
      "1942/2800 (epoch 34), train_loss = 10.554, time/batch = 0.016\n",
      "1943/2800 (epoch 34), train_loss = 11.449, time/batch = 0.000\n",
      "1944/2800 (epoch 34), train_loss = 10.286, time/batch = 0.016\n",
      "1945/2800 (epoch 34), train_loss = 11.210, time/batch = 0.016\n",
      "1946/2800 (epoch 34), train_loss = 10.404, time/batch = 0.016\n",
      "1947/2800 (epoch 34), train_loss = 10.450, time/batch = 0.020\n",
      "1948/2800 (epoch 34), train_loss = 10.867, time/batch = 0.001\n",
      "1949/2800 (epoch 34), train_loss = 10.691, time/batch = 0.016\n",
      "1950/2800 (epoch 34), train_loss = 10.207, time/batch = 0.016\n",
      "1951/2800 (epoch 34), train_loss = 10.637, time/batch = 0.016\n",
      "1952/2800 (epoch 34), train_loss = 10.516, time/batch = 0.016\n",
      "1953/2800 (epoch 34), train_loss = 10.351, time/batch = 0.000\n",
      "1954/2800 (epoch 34), train_loss = 10.376, time/batch = 0.016\n",
      "1955/2800 (epoch 34), train_loss = 10.887, time/batch = 0.020\n",
      "1956/2800 (epoch 34), train_loss = 10.161, time/batch = 0.002\n",
      "1957/2800 (epoch 34), train_loss = 10.315, time/batch = 0.016\n",
      "1958/2800 (epoch 34), train_loss = 10.327, time/batch = 0.000\n",
      "1959/2800 (epoch 34), train_loss = 10.094, time/batch = 0.016\n",
      "1960/2800 (epoch 35), train_loss = 10.526, time/batch = 0.016\n",
      "1961/2800 (epoch 35), train_loss = 9.241, time/batch = 0.016\n",
      "1962/2800 (epoch 35), train_loss = 10.711, time/batch = 0.000\n",
      "1963/2800 (epoch 35), train_loss = 9.197, time/batch = 0.016\n",
      "1964/2800 (epoch 35), train_loss = 10.259, time/batch = 0.022\n",
      "1965/2800 (epoch 35), train_loss = 9.290, time/batch = 0.000\n",
      "1966/2800 (epoch 35), train_loss = 9.873, time/batch = 0.016\n",
      "1967/2800 (epoch 35), train_loss = 9.300, time/batch = 0.016\n",
      "1968/2800 (epoch 35), train_loss = 10.482, time/batch = 0.016\n",
      "1969/2800 (epoch 35), train_loss = 8.910, time/batch = 0.016\n",
      "1970/2800 (epoch 35), train_loss = 10.267, time/batch = 0.000\n",
      "1971/2800 (epoch 35), train_loss = 9.821, time/batch = 0.016\n",
      "1972/2800 (epoch 35), train_loss = 9.057, time/batch = 0.020\n",
      "1973/2800 (epoch 35), train_loss = 9.381, time/batch = 0.002\n",
      "1974/2800 (epoch 35), train_loss = 9.277, time/batch = 0.016\n",
      "1975/2800 (epoch 35), train_loss = 9.727, time/batch = 0.000\n",
      "1976/2800 (epoch 35), train_loss = 9.571, time/batch = 0.016\n",
      "1977/2800 (epoch 35), train_loss = 9.535, time/batch = 0.016\n",
      "1978/2800 (epoch 35), train_loss = 9.410, time/batch = 0.000\n",
      "1979/2800 (epoch 35), train_loss = 9.174, time/batch = 0.016\n",
      "1980/2800 (epoch 35), train_loss = 9.206, time/batch = 0.016\n",
      "1981/2800 (epoch 35), train_loss = 9.358, time/batch = 0.022\n",
      "1982/2800 (epoch 35), train_loss = 10.177, time/batch = 0.000\n",
      "1983/2800 (epoch 35), train_loss = 9.521, time/batch = 0.016\n",
      "1984/2800 (epoch 35), train_loss = 10.011, time/batch = 0.016\n",
      "1985/2800 (epoch 35), train_loss = 9.579, time/batch = 0.016\n",
      "1986/2800 (epoch 35), train_loss = 9.815, time/batch = 0.016\n",
      "1987/2800 (epoch 35), train_loss = 9.946, time/batch = 0.016\n",
      "1988/2800 (epoch 35), train_loss = 9.896, time/batch = 0.000\n",
      "1989/2800 (epoch 35), train_loss = 9.635, time/batch = 0.021\n",
      "1990/2800 (epoch 35), train_loss = 9.846, time/batch = 0.001\n",
      "1991/2800 (epoch 35), train_loss = 9.661, time/batch = 0.016\n",
      "1992/2800 (epoch 35), train_loss = 9.611, time/batch = 0.016\n",
      "1993/2800 (epoch 35), train_loss = 9.473, time/batch = 0.000\n",
      "1994/2800 (epoch 35), train_loss = 9.939, time/batch = 0.016\n",
      "1995/2800 (epoch 35), train_loss = 9.403, time/batch = 0.016\n",
      "1996/2800 (epoch 35), train_loss = 11.988, time/batch = 0.016\n",
      "1997/2800 (epoch 35), train_loss = 11.263, time/batch = 0.019\n",
      "1998/2800 (epoch 35), train_loss = 10.938, time/batch = 0.002\n",
      "1999/2800 (epoch 35), train_loss = 10.611, time/batch = 0.016\n",
      "2000/2800 (epoch 35), train_loss = 10.830, time/batch = 0.016\n",
      "model saved to save\\model.ckpt\n",
      "2001/2800 (epoch 35), train_loss = 10.382, time/batch = 0.031\n",
      "2002/2800 (epoch 35), train_loss = 10.834, time/batch = 0.022\n",
      "2003/2800 (epoch 35), train_loss = 10.475, time/batch = 0.032\n",
      "2004/2800 (epoch 35), train_loss = 10.947, time/batch = 0.031\n",
      "2005/2800 (epoch 35), train_loss = 10.620, time/batch = 0.038\n",
      "2006/2800 (epoch 35), train_loss = 10.176, time/batch = 0.031\n",
      "2007/2800 (epoch 35), train_loss = 10.530, time/batch = 0.031\n",
      "2008/2800 (epoch 35), train_loss = 10.938, time/batch = 0.038\n",
      "2009/2800 (epoch 35), train_loss = 10.091, time/batch = 0.031\n",
      "2010/2800 (epoch 35), train_loss = 11.068, time/batch = 0.031\n",
      "2011/2800 (epoch 35), train_loss = 10.591, time/batch = 0.038\n",
      "2012/2800 (epoch 35), train_loss = 11.099, time/batch = 0.031\n",
      "2013/2800 (epoch 35), train_loss = 10.375, time/batch = 0.031\n",
      "2014/2800 (epoch 35), train_loss = 10.588, time/batch = 0.038\n",
      "2015/2800 (epoch 35), train_loss = 9.941, time/batch = 0.031\n",
      "2016/2800 (epoch 36), train_loss = 10.363, time/batch = 0.047\n",
      "2017/2800 (epoch 36), train_loss = 9.481, time/batch = 0.053\n",
      "2018/2800 (epoch 36), train_loss = 10.351, time/batch = 0.031\n",
      "2019/2800 (epoch 36), train_loss = 8.993, time/batch = 0.038\n",
      "2020/2800 (epoch 36), train_loss = 10.829, time/batch = 0.047\n",
      "2021/2800 (epoch 36), train_loss = 8.846, time/batch = 0.049\n",
      "2022/2800 (epoch 36), train_loss = 10.835, time/batch = 0.038\n",
      "2023/2800 (epoch 36), train_loss = 8.886, time/batch = 0.048\n",
      "2024/2800 (epoch 36), train_loss = 10.863, time/batch = 0.041\n",
      "2025/2800 (epoch 36), train_loss = 9.307, time/batch = 0.038\n",
      "2026/2800 (epoch 36), train_loss = 10.270, time/batch = 0.033\n",
      "2027/2800 (epoch 36), train_loss = 9.208, time/batch = 0.052\n",
      "2028/2800 (epoch 36), train_loss = 9.550, time/batch = 0.056\n",
      "2029/2800 (epoch 36), train_loss = 9.095, time/batch = 0.049\n",
      "2030/2800 (epoch 36), train_loss = 10.084, time/batch = 0.040\n",
      "2031/2800 (epoch 36), train_loss = 9.520, time/batch = 0.026\n",
      "2032/2800 (epoch 36), train_loss = 9.754, time/batch = 0.031\n",
      "2033/2800 (epoch 36), train_loss = 9.251, time/batch = 0.031\n",
      "2034/2800 (epoch 36), train_loss = 9.475, time/batch = 0.036\n",
      "2035/2800 (epoch 36), train_loss = 9.141, time/batch = 0.017\n",
      "2036/2800 (epoch 36), train_loss = 9.595, time/batch = 0.047\n",
      "2037/2800 (epoch 36), train_loss = 9.197, time/batch = 0.035\n",
      "2038/2800 (epoch 36), train_loss = 9.865, time/batch = 0.018\n",
      "2039/2800 (epoch 36), train_loss = 9.935, time/batch = 0.031\n",
      "2040/2800 (epoch 36), train_loss = 9.483, time/batch = 0.070\n",
      "2041/2800 (epoch 36), train_loss = 10.043, time/batch = 0.016\n",
      "2042/2800 (epoch 36), train_loss = 9.627, time/batch = 0.047\n",
      "2043/2800 (epoch 36), train_loss = 9.233, time/batch = 0.022\n",
      "2044/2800 (epoch 36), train_loss = 9.576, time/batch = 0.031\n",
      "2045/2800 (epoch 36), train_loss = 9.867, time/batch = 0.031\n",
      "2046/2800 (epoch 36), train_loss = 9.655, time/batch = 0.038\n",
      "2047/2800 (epoch 36), train_loss = 10.088, time/batch = 0.031\n",
      "2048/2800 (epoch 36), train_loss = 9.418, time/batch = 0.031\n",
      "2049/2800 (epoch 36), train_loss = 9.447, time/batch = 0.035\n",
      "2050/2800 (epoch 36), train_loss = 9.989, time/batch = 0.018\n",
      "2051/2800 (epoch 36), train_loss = 9.083, time/batch = 0.016\n",
      "2052/2800 (epoch 36), train_loss = 10.103, time/batch = 0.031\n",
      "2053/2800 (epoch 36), train_loss = 10.234, time/batch = 0.033\n",
      "2054/2800 (epoch 36), train_loss = 11.604, time/batch = 0.020\n",
      "2055/2800 (epoch 36), train_loss = 10.664, time/batch = 0.016\n",
      "2056/2800 (epoch 36), train_loss = 11.727, time/batch = 0.031\n",
      "2057/2800 (epoch 36), train_loss = 10.456, time/batch = 0.031\n",
      "2058/2800 (epoch 36), train_loss = 10.834, time/batch = 0.021\n",
      "2059/2800 (epoch 36), train_loss = 10.226, time/batch = 0.016\n",
      "2060/2800 (epoch 36), train_loss = 10.564, time/batch = 0.031\n",
      "2061/2800 (epoch 36), train_loss = 10.598, time/batch = 0.016\n",
      "2062/2800 (epoch 36), train_loss = 11.269, time/batch = 0.038\n",
      "2063/2800 (epoch 36), train_loss = 10.485, time/batch = 0.016\n",
      "2064/2800 (epoch 36), train_loss = 11.258, time/batch = 0.016\n",
      "2065/2800 (epoch 36), train_loss = 10.631, time/batch = 0.031\n",
      "2066/2800 (epoch 36), train_loss = 10.368, time/batch = 0.022\n",
      "2067/2800 (epoch 36), train_loss = 10.356, time/batch = 0.031\n",
      "2068/2800 (epoch 36), train_loss = 10.691, time/batch = 0.031\n",
      "2069/2800 (epoch 36), train_loss = 10.247, time/batch = 0.016\n",
      "2070/2800 (epoch 36), train_loss = 9.972, time/batch = 0.022\n",
      "2071/2800 (epoch 36), train_loss = 11.639, time/batch = 0.031\n",
      "2072/2800 (epoch 37), train_loss = 9.389, time/batch = 0.016\n",
      "2073/2800 (epoch 37), train_loss = 9.753, time/batch = 0.031\n",
      "2074/2800 (epoch 37), train_loss = 8.842, time/batch = 0.022\n",
      "2075/2800 (epoch 37), train_loss = 11.219, time/batch = 0.016\n",
      "2076/2800 (epoch 37), train_loss = 8.992, time/batch = 0.016\n",
      "2077/2800 (epoch 37), train_loss = 10.672, time/batch = 0.016\n",
      "2078/2800 (epoch 37), train_loss = 9.110, time/batch = 0.031\n",
      "2079/2800 (epoch 37), train_loss = 11.290, time/batch = 0.022\n",
      "2080/2800 (epoch 37), train_loss = 8.880, time/batch = 0.016\n",
      "2081/2800 (epoch 37), train_loss = 10.324, time/batch = 0.031\n",
      "2082/2800 (epoch 37), train_loss = 9.370, time/batch = 0.016\n",
      "2083/2800 (epoch 37), train_loss = 9.866, time/batch = 0.031\n",
      "2084/2800 (epoch 37), train_loss = 9.624, time/batch = 0.006\n",
      "2085/2800 (epoch 37), train_loss = 9.104, time/batch = 0.016\n",
      "2086/2800 (epoch 37), train_loss = 9.495, time/batch = 0.031\n",
      "2087/2800 (epoch 37), train_loss = 9.309, time/batch = 0.016\n",
      "2088/2800 (epoch 37), train_loss = 9.214, time/batch = 0.016\n",
      "2089/2800 (epoch 37), train_loss = 9.159, time/batch = 0.022\n",
      "2090/2800 (epoch 37), train_loss = 9.354, time/batch = 0.031\n",
      "2091/2800 (epoch 37), train_loss = 9.333, time/batch = 0.016\n",
      "2092/2800 (epoch 37), train_loss = 9.727, time/batch = 0.016\n",
      "2093/2800 (epoch 37), train_loss = 10.012, time/batch = 0.016\n",
      "2094/2800 (epoch 37), train_loss = 9.802, time/batch = 0.022\n",
      "2095/2800 (epoch 37), train_loss = 10.001, time/batch = 0.016\n",
      "2096/2800 (epoch 37), train_loss = 9.660, time/batch = 0.016\n",
      "2097/2800 (epoch 37), train_loss = 9.487, time/batch = 0.031\n",
      "2098/2800 (epoch 37), train_loss = 9.580, time/batch = 0.033\n",
      "2099/2800 (epoch 37), train_loss = 9.768, time/batch = 0.021\n",
      "2100/2800 (epoch 37), train_loss = 9.827, time/batch = 0.016\n",
      "2101/2800 (epoch 37), train_loss = 9.609, time/batch = 0.016\n",
      "2102/2800 (epoch 37), train_loss = 9.514, time/batch = 0.031\n",
      "2103/2800 (epoch 37), train_loss = 9.528, time/batch = 0.022\n",
      "2104/2800 (epoch 37), train_loss = 9.227, time/batch = 0.016\n",
      "2105/2800 (epoch 37), train_loss = 10.592, time/batch = 0.016\n",
      "2106/2800 (epoch 37), train_loss = 11.580, time/batch = 0.016\n",
      "2107/2800 (epoch 37), train_loss = 10.701, time/batch = 0.016\n",
      "2108/2800 (epoch 37), train_loss = 11.351, time/batch = 0.033\n",
      "2109/2800 (epoch 37), train_loss = 10.695, time/batch = 0.020\n",
      "2110/2800 (epoch 37), train_loss = 10.476, time/batch = 0.016\n",
      "2111/2800 (epoch 37), train_loss = 10.505, time/batch = 0.016\n",
      "2112/2800 (epoch 37), train_loss = 10.704, time/batch = 0.031\n",
      "2113/2800 (epoch 37), train_loss = 10.502, time/batch = 0.022\n",
      "2114/2800 (epoch 37), train_loss = 10.714, time/batch = 0.016\n",
      "2115/2800 (epoch 37), train_loss = 10.530, time/batch = 0.016\n",
      "2116/2800 (epoch 37), train_loss = 11.100, time/batch = 0.016\n",
      "2117/2800 (epoch 37), train_loss = 10.471, time/batch = 0.016\n",
      "2118/2800 (epoch 37), train_loss = 10.215, time/batch = 0.035\n",
      "2119/2800 (epoch 37), train_loss = 10.997, time/batch = 0.018\n",
      "2120/2800 (epoch 37), train_loss = 10.621, time/batch = 0.016\n",
      "2121/2800 (epoch 37), train_loss = 10.598, time/batch = 0.016\n",
      "2122/2800 (epoch 37), train_loss = 10.211, time/batch = 0.031\n",
      "2123/2800 (epoch 37), train_loss = 10.433, time/batch = 0.022\n",
      "2124/2800 (epoch 37), train_loss = 10.275, time/batch = 0.016\n",
      "2125/2800 (epoch 37), train_loss = 10.733, time/batch = 0.016\n",
      "2126/2800 (epoch 37), train_loss = 9.744, time/batch = 0.016\n",
      "2127/2800 (epoch 37), train_loss = 9.869, time/batch = 0.016\n",
      "2128/2800 (epoch 38), train_loss = 9.288, time/batch = 0.016\n",
      "2129/2800 (epoch 38), train_loss = 9.160, time/batch = 0.022\n",
      "2130/2800 (epoch 38), train_loss = 9.198, time/batch = 0.031\n",
      "2131/2800 (epoch 38), train_loss = 9.953, time/batch = 0.016\n",
      "2132/2800 (epoch 38), train_loss = 8.919, time/batch = 0.016\n",
      "2133/2800 (epoch 38), train_loss = 11.945, time/batch = 0.034\n",
      "2134/2800 (epoch 38), train_loss = 8.893, time/batch = 0.019\n",
      "2135/2800 (epoch 38), train_loss = 11.207, time/batch = 0.016\n",
      "2136/2800 (epoch 38), train_loss = 9.230, time/batch = 0.016\n",
      "2137/2800 (epoch 38), train_loss = 9.688, time/batch = 0.016\n",
      "2138/2800 (epoch 38), train_loss = 9.143, time/batch = 0.016\n",
      "2139/2800 (epoch 38), train_loss = 9.559, time/batch = 0.022\n",
      "2140/2800 (epoch 38), train_loss = 9.240, time/batch = 0.016\n",
      "2141/2800 (epoch 38), train_loss = 10.689, time/batch = 0.016\n",
      "2142/2800 (epoch 38), train_loss = 8.761, time/batch = 0.031\n",
      "2143/2800 (epoch 38), train_loss = 10.696, time/batch = 0.016\n",
      "2144/2800 (epoch 38), train_loss = 8.997, time/batch = 0.022\n",
      "2145/2800 (epoch 38), train_loss = 10.248, time/batch = 0.031\n",
      "2146/2800 (epoch 38), train_loss = 9.218, time/batch = 0.016\n",
      "2147/2800 (epoch 38), train_loss = 10.237, time/batch = 0.016\n",
      "2148/2800 (epoch 38), train_loss = 8.743, time/batch = 0.016\n",
      "2149/2800 (epoch 38), train_loss = 9.203, time/batch = 0.022\n",
      "2150/2800 (epoch 38), train_loss = 8.183, time/batch = 0.016\n",
      "2151/2800 (epoch 38), train_loss = 14.632, time/batch = 0.031\n",
      "2152/2800 (epoch 38), train_loss = 7.859, time/batch = 0.016\n",
      "2153/2800 (epoch 38), train_loss = 14.851, time/batch = 0.016\n",
      "2154/2800 (epoch 38), train_loss = 11.115, time/batch = 0.022\n",
      "2155/2800 (epoch 38), train_loss = 10.276, time/batch = 0.031\n",
      "2156/2800 (epoch 38), train_loss = 9.141, time/batch = 0.016\n",
      "2157/2800 (epoch 38), train_loss = 10.105, time/batch = 0.016\n",
      "2158/2800 (epoch 38), train_loss = 9.408, time/batch = 0.016\n",
      "2159/2800 (epoch 38), train_loss = 9.444, time/batch = 0.022\n",
      "2160/2800 (epoch 38), train_loss = 9.181, time/batch = 0.016\n",
      "2161/2800 (epoch 38), train_loss = 11.628, time/batch = 0.031\n",
      "2162/2800 (epoch 38), train_loss = 9.502, time/batch = 0.016\n",
      "2163/2800 (epoch 38), train_loss = 10.250, time/batch = 0.016\n",
      "2164/2800 (epoch 38), train_loss = 9.248, time/batch = 0.022\n",
      "2165/2800 (epoch 38), train_loss = 10.062, time/batch = 0.016\n",
      "2166/2800 (epoch 38), train_loss = 9.121, time/batch = 0.031\n",
      "2167/2800 (epoch 38), train_loss = 11.284, time/batch = 0.016\n",
      "2168/2800 (epoch 38), train_loss = 11.876, time/batch = 0.037\n",
      "2169/2800 (epoch 38), train_loss = 11.117, time/batch = 0.016\n",
      "2170/2800 (epoch 38), train_loss = 11.554, time/batch = 0.016\n",
      "2171/2800 (epoch 38), train_loss = 10.607, time/batch = 0.016\n",
      "2172/2800 (epoch 38), train_loss = 10.646, time/batch = 0.016\n",
      "2173/2800 (epoch 38), train_loss = 10.345, time/batch = 0.036\n",
      "2174/2800 (epoch 38), train_loss = 10.999, time/batch = 0.017\n",
      "2175/2800 (epoch 38), train_loss = 10.405, time/batch = 0.016\n",
      "2176/2800 (epoch 38), train_loss = 11.076, time/batch = 0.016\n",
      "2177/2800 (epoch 38), train_loss = 10.372, time/batch = 0.016\n",
      "2178/2800 (epoch 38), train_loss = 10.808, time/batch = 0.020\n",
      "2179/2800 (epoch 38), train_loss = 10.273, time/batch = 0.002\n",
      "2180/2800 (epoch 38), train_loss = 11.124, time/batch = 0.016\n",
      "2181/2800 (epoch 38), train_loss = 11.038, time/batch = 0.016\n",
      "2182/2800 (epoch 38), train_loss = 10.528, time/batch = 0.031\n",
      "2183/2800 (epoch 38), train_loss = 10.543, time/batch = 0.016\n",
      "2184/2800 (epoch 39), train_loss = 10.012, time/batch = 0.022\n",
      "2185/2800 (epoch 39), train_loss = 9.436, time/batch = 0.016\n",
      "2186/2800 (epoch 39), train_loss = 9.443, time/batch = 0.016\n",
      "2187/2800 (epoch 39), train_loss = 10.664, time/batch = 0.031\n",
      "2188/2800 (epoch 39), train_loss = 9.114, time/batch = 0.016\n",
      "2189/2800 (epoch 39), train_loss = 10.019, time/batch = 0.022\n",
      "2190/2800 (epoch 39), train_loss = 9.124, time/batch = 0.016\n",
      "2191/2800 (epoch 39), train_loss = 10.562, time/batch = 0.016\n",
      "2192/2800 (epoch 39), train_loss = 9.327, time/batch = 0.016\n",
      "2193/2800 (epoch 39), train_loss = 10.355, time/batch = 0.016\n",
      "2194/2800 (epoch 39), train_loss = 9.041, time/batch = 0.016\n",
      "2195/2800 (epoch 39), train_loss = 11.160, time/batch = 0.022\n",
      "2196/2800 (epoch 39), train_loss = 8.996, time/batch = 0.016\n",
      "2197/2800 (epoch 39), train_loss = 10.492, time/batch = 0.000\n",
      "2198/2800 (epoch 39), train_loss = 8.847, time/batch = 0.016\n",
      "2199/2800 (epoch 39), train_loss = 10.078, time/batch = 0.016\n",
      "2200/2800 (epoch 39), train_loss = 9.688, time/batch = 0.016\n",
      "2201/2800 (epoch 39), train_loss = 9.344, time/batch = 0.016\n",
      "2202/2800 (epoch 39), train_loss = 9.178, time/batch = 0.000\n",
      "2203/2800 (epoch 39), train_loss = 9.360, time/batch = 0.022\n",
      "2204/2800 (epoch 39), train_loss = 9.262, time/batch = 0.000\n",
      "2205/2800 (epoch 39), train_loss = 10.002, time/batch = 0.016\n",
      "2206/2800 (epoch 39), train_loss = 9.323, time/batch = 0.016\n",
      "2207/2800 (epoch 39), train_loss = 9.992, time/batch = 0.000\n",
      "2208/2800 (epoch 39), train_loss = 9.914, time/batch = 0.016\n",
      "2209/2800 (epoch 39), train_loss = 9.690, time/batch = 0.016\n",
      "2210/2800 (epoch 39), train_loss = 9.676, time/batch = 0.016\n",
      "2211/2800 (epoch 39), train_loss = 9.675, time/batch = 0.018\n",
      "2212/2800 (epoch 39), train_loss = 9.452, time/batch = 0.004\n",
      "2213/2800 (epoch 39), train_loss = 10.097, time/batch = 0.016\n",
      "2214/2800 (epoch 39), train_loss = 9.362, time/batch = 0.016\n",
      "2215/2800 (epoch 39), train_loss = 10.136, time/batch = 0.016\n",
      "2216/2800 (epoch 39), train_loss = 9.549, time/batch = 0.016\n",
      "2217/2800 (epoch 39), train_loss = 10.155, time/batch = 0.000\n",
      "2218/2800 (epoch 39), train_loss = 9.444, time/batch = 0.016\n",
      "2219/2800 (epoch 39), train_loss = 9.553, time/batch = 0.020\n",
      "2220/2800 (epoch 39), train_loss = 9.530, time/batch = 0.002\n",
      "2221/2800 (epoch 39), train_loss = 10.234, time/batch = 0.016\n",
      "2222/2800 (epoch 39), train_loss = 11.754, time/batch = 0.000\n",
      "2223/2800 (epoch 39), train_loss = 10.804, time/batch = 0.016\n",
      "2224/2800 (epoch 39), train_loss = 10.881, time/batch = 0.016\n",
      "2225/2800 (epoch 39), train_loss = 10.563, time/batch = 0.016\n",
      "2226/2800 (epoch 39), train_loss = 10.553, time/batch = 0.000\n",
      "2227/2800 (epoch 39), train_loss = 10.610, time/batch = 0.000\n",
      "2228/2800 (epoch 39), train_loss = 10.498, time/batch = 0.022\n",
      "2229/2800 (epoch 39), train_loss = 10.862, time/batch = 0.016\n",
      "2230/2800 (epoch 39), train_loss = 10.424, time/batch = 0.000\n",
      "2231/2800 (epoch 39), train_loss = 10.712, time/batch = 0.016\n",
      "2232/2800 (epoch 39), train_loss = 10.542, time/batch = 0.016\n",
      "2233/2800 (epoch 39), train_loss = 10.524, time/batch = 0.016\n",
      "2234/2800 (epoch 39), train_loss = 10.173, time/batch = 0.016\n",
      "2235/2800 (epoch 39), train_loss = 11.820, time/batch = 0.017\n",
      "2236/2800 (epoch 39), train_loss = 10.607, time/batch = 0.005\n",
      "2237/2800 (epoch 39), train_loss = 10.196, time/batch = 0.016\n",
      "2238/2800 (epoch 39), train_loss = 10.152, time/batch = 0.000\n",
      "2239/2800 (epoch 39), train_loss = 10.769, time/batch = 0.016\n",
      "2240/2800 (epoch 40), train_loss = 9.639, time/batch = 0.016\n",
      "2241/2800 (epoch 40), train_loss = 9.357, time/batch = 0.000\n",
      "2242/2800 (epoch 40), train_loss = 9.511, time/batch = 0.016\n",
      "2243/2800 (epoch 40), train_loss = 10.948, time/batch = 0.016\n",
      "2244/2800 (epoch 40), train_loss = 9.339, time/batch = 0.017\n",
      "2245/2800 (epoch 40), train_loss = 9.468, time/batch = 0.005\n",
      "2246/2800 (epoch 40), train_loss = 9.427, time/batch = 0.016\n",
      "2247/2800 (epoch 40), train_loss = 9.570, time/batch = 0.016\n",
      "2248/2800 (epoch 40), train_loss = 9.375, time/batch = 0.016\n",
      "2249/2800 (epoch 40), train_loss = 9.278, time/batch = 0.000\n",
      "2250/2800 (epoch 40), train_loss = 9.849, time/batch = 0.016\n",
      "2251/2800 (epoch 40), train_loss = 9.947, time/batch = 0.016\n",
      "2252/2800 (epoch 40), train_loss = 9.282, time/batch = 0.018\n",
      "2253/2800 (epoch 40), train_loss = 8.931, time/batch = 0.005\n",
      "2254/2800 (epoch 40), train_loss = 9.825, time/batch = 0.016\n",
      "2255/2800 (epoch 40), train_loss = 9.205, time/batch = 0.000\n",
      "2256/2800 (epoch 40), train_loss = 9.510, time/batch = 0.016\n",
      "2257/2800 (epoch 40), train_loss = 9.086, time/batch = 0.016\n",
      "2258/2800 (epoch 40), train_loss = 9.623, time/batch = 0.000\n",
      "2259/2800 (epoch 40), train_loss = 9.920, time/batch = 0.016\n",
      "2260/2800 (epoch 40), train_loss = 9.975, time/batch = 0.016\n",
      "2261/2800 (epoch 40), train_loss = 9.269, time/batch = 0.018\n",
      "2262/2800 (epoch 40), train_loss = 9.601, time/batch = 0.004\n",
      "2263/2800 (epoch 40), train_loss = 9.523, time/batch = 0.016\n",
      "2264/2800 (epoch 40), train_loss = 10.130, time/batch = 0.016\n",
      "2265/2800 (epoch 40), train_loss = 10.051, time/batch = 0.016\n",
      "2266/2800 (epoch 40), train_loss = 9.357, time/batch = 0.016\n",
      "2267/2800 (epoch 40), train_loss = 9.474, time/batch = 0.000\n",
      "2268/2800 (epoch 40), train_loss = 9.930, time/batch = 0.016\n",
      "2269/2800 (epoch 40), train_loss = 9.725, time/batch = 0.021\n",
      "2270/2800 (epoch 40), train_loss = 9.793, time/batch = 0.000\n",
      "2271/2800 (epoch 40), train_loss = 10.014, time/batch = 0.016\n",
      "2272/2800 (epoch 40), train_loss = 9.618, time/batch = 0.016\n",
      "2273/2800 (epoch 40), train_loss = 9.601, time/batch = 0.000\n",
      "2274/2800 (epoch 40), train_loss = 9.469, time/batch = 0.016\n",
      "2275/2800 (epoch 40), train_loss = 9.537, time/batch = 0.016\n",
      "2276/2800 (epoch 40), train_loss = 9.708, time/batch = 0.000\n",
      "2277/2800 (epoch 40), train_loss = 12.464, time/batch = 0.016\n",
      "2278/2800 (epoch 40), train_loss = 10.716, time/batch = 0.022\n",
      "2279/2800 (epoch 40), train_loss = 10.733, time/batch = 0.016\n",
      "2280/2800 (epoch 40), train_loss = 10.944, time/batch = 0.016\n",
      "2281/2800 (epoch 40), train_loss = 10.406, time/batch = 0.016\n",
      "2282/2800 (epoch 40), train_loss = 10.594, time/batch = 0.000\n",
      "2283/2800 (epoch 40), train_loss = 10.393, time/batch = 0.016\n",
      "2284/2800 (epoch 40), train_loss = 10.741, time/batch = 0.016\n",
      "2285/2800 (epoch 40), train_loss = 10.226, time/batch = 0.021\n",
      "2286/2800 (epoch 40), train_loss = 11.134, time/batch = 0.000\n",
      "2287/2800 (epoch 40), train_loss = 10.438, time/batch = 0.016\n",
      "2288/2800 (epoch 40), train_loss = 10.700, time/batch = 0.016\n",
      "2289/2800 (epoch 40), train_loss = 10.242, time/batch = 0.000\n",
      "2290/2800 (epoch 40), train_loss = 10.882, time/batch = 0.016\n",
      "2291/2800 (epoch 40), train_loss = 10.815, time/batch = 0.016\n",
      "2292/2800 (epoch 40), train_loss = 10.160, time/batch = 0.000\n",
      "2293/2800 (epoch 40), train_loss = 10.417, time/batch = 0.016\n",
      "2294/2800 (epoch 40), train_loss = 9.947, time/batch = 0.020\n",
      "2295/2800 (epoch 40), train_loss = 10.361, time/batch = 0.002\n",
      "2296/2800 (epoch 41), train_loss = 9.709, time/batch = 0.016\n",
      "2297/2800 (epoch 41), train_loss = 9.525, time/batch = 0.016\n",
      "2298/2800 (epoch 41), train_loss = 9.234, time/batch = 0.016\n",
      "2299/2800 (epoch 41), train_loss = 10.780, time/batch = 0.016\n",
      "2300/2800 (epoch 41), train_loss = 8.903, time/batch = 0.016\n",
      "2301/2800 (epoch 41), train_loss = 10.824, time/batch = 0.018\n",
      "2302/2800 (epoch 41), train_loss = 9.162, time/batch = 0.004\n",
      "2303/2800 (epoch 41), train_loss = 9.776, time/batch = 0.016\n",
      "2304/2800 (epoch 41), train_loss = 9.124, time/batch = 0.016\n",
      "2305/2800 (epoch 41), train_loss = 10.738, time/batch = 0.000\n",
      "2306/2800 (epoch 41), train_loss = 8.823, time/batch = 0.016\n",
      "2307/2800 (epoch 41), train_loss = 9.381, time/batch = 0.016\n",
      "2308/2800 (epoch 41), train_loss = 9.559, time/batch = 0.000\n",
      "2309/2800 (epoch 41), train_loss = 9.441, time/batch = 0.016\n",
      "2310/2800 (epoch 41), train_loss = 9.718, time/batch = 0.020\n",
      "2311/2800 (epoch 41), train_loss = 9.610, time/batch = 0.002\n",
      "2312/2800 (epoch 41), train_loss = 9.190, time/batch = 0.016\n",
      "2313/2800 (epoch 41), train_loss = 9.401, time/batch = 0.016\n",
      "2314/2800 (epoch 41), train_loss = 8.989, time/batch = 0.016\n",
      "2315/2800 (epoch 41), train_loss = 10.083, time/batch = 0.000\n",
      "2316/2800 (epoch 41), train_loss = 9.365, time/batch = 0.016\n",
      "2317/2800 (epoch 41), train_loss = 10.435, time/batch = 0.016\n",
      "2318/2800 (epoch 41), train_loss = 9.656, time/batch = 0.022\n",
      "2319/2800 (epoch 41), train_loss = 9.435, time/batch = 0.000\n",
      "2320/2800 (epoch 41), train_loss = 9.635, time/batch = 0.016\n",
      "2321/2800 (epoch 41), train_loss = 9.893, time/batch = 0.016\n",
      "2322/2800 (epoch 41), train_loss = 9.462, time/batch = 0.016\n",
      "2323/2800 (epoch 41), train_loss = 9.400, time/batch = 0.000\n",
      "2324/2800 (epoch 41), train_loss = 9.559, time/batch = 0.016\n",
      "2325/2800 (epoch 41), train_loss = 9.750, time/batch = 0.016\n",
      "2326/2800 (epoch 41), train_loss = 9.881, time/batch = 0.000\n",
      "2327/2800 (epoch 41), train_loss = 9.528, time/batch = 0.022\n",
      "2328/2800 (epoch 41), train_loss = 9.408, time/batch = 0.000\n",
      "2329/2800 (epoch 41), train_loss = 9.736, time/batch = 0.016\n",
      "2330/2800 (epoch 41), train_loss = 11.268, time/batch = 0.016\n",
      "2331/2800 (epoch 41), train_loss = 10.931, time/batch = 0.016\n",
      "2332/2800 (epoch 41), train_loss = 10.796, time/batch = 0.016\n",
      "2333/2800 (epoch 41), train_loss = 10.680, time/batch = 0.000\n",
      "2334/2800 (epoch 41), train_loss = 10.774, time/batch = 0.016\n",
      "2335/2800 (epoch 41), train_loss = 10.603, time/batch = 0.022\n",
      "2336/2800 (epoch 41), train_loss = 10.710, time/batch = 0.016\n",
      "2337/2800 (epoch 41), train_loss = 10.551, time/batch = 0.000\n",
      "2338/2800 (epoch 41), train_loss = 10.811, time/batch = 0.016\n",
      "2339/2800 (epoch 41), train_loss = 10.365, time/batch = 0.016\n",
      "2340/2800 (epoch 41), train_loss = 10.570, time/batch = 0.000\n",
      "2341/2800 (epoch 41), train_loss = 11.022, time/batch = 0.016\n",
      "2342/2800 (epoch 41), train_loss = 10.576, time/batch = 0.016\n",
      "2343/2800 (epoch 41), train_loss = 10.233, time/batch = 0.000\n",
      "2344/2800 (epoch 41), train_loss = 11.084, time/batch = 0.022\n",
      "2345/2800 (epoch 41), train_loss = 10.561, time/batch = 0.000\n",
      "2346/2800 (epoch 41), train_loss = 10.113, time/batch = 0.016\n",
      "2347/2800 (epoch 41), train_loss = 10.263, time/batch = 0.016\n",
      "2348/2800 (epoch 41), train_loss = 9.941, time/batch = 0.016\n",
      "2349/2800 (epoch 41), train_loss = 10.778, time/batch = 0.016\n",
      "2350/2800 (epoch 41), train_loss = 10.194, time/batch = 0.016\n",
      "2351/2800 (epoch 41), train_loss = 9.727, time/batch = 0.017\n",
      "2352/2800 (epoch 42), train_loss = 9.500, time/batch = 0.006\n",
      "2353/2800 (epoch 42), train_loss = 9.431, time/batch = 0.016\n",
      "2354/2800 (epoch 42), train_loss = 9.697, time/batch = 0.016\n",
      "2355/2800 (epoch 42), train_loss = 9.546, time/batch = 0.000\n",
      "2356/2800 (epoch 42), train_loss = 10.634, time/batch = 0.016\n",
      "2357/2800 (epoch 42), train_loss = 9.018, time/batch = 0.016\n",
      "2358/2800 (epoch 42), train_loss = 10.213, time/batch = 0.000\n",
      "2359/2800 (epoch 42), train_loss = 9.299, time/batch = 0.016\n",
      "2360/2800 (epoch 42), train_loss = 9.950, time/batch = 0.019\n",
      "2361/2800 (epoch 42), train_loss = 8.753, time/batch = 0.003\n",
      "2362/2800 (epoch 42), train_loss = 13.096, time/batch = 0.016\n",
      "2363/2800 (epoch 42), train_loss = 8.918, time/batch = 0.016\n",
      "2364/2800 (epoch 42), train_loss = 11.265, time/batch = 0.016\n",
      "2365/2800 (epoch 42), train_loss = 8.846, time/batch = 0.000\n",
      "2366/2800 (epoch 42), train_loss = 9.742, time/batch = 0.016\n",
      "2367/2800 (epoch 42), train_loss = 8.880, time/batch = 0.016\n",
      "2368/2800 (epoch 42), train_loss = 9.985, time/batch = 0.022\n",
      "2369/2800 (epoch 42), train_loss = 8.792, time/batch = 0.000\n",
      "2370/2800 (epoch 42), train_loss = 9.717, time/batch = 0.016\n",
      "2371/2800 (epoch 42), train_loss = 8.829, time/batch = 0.016\n",
      "2372/2800 (epoch 42), train_loss = 9.668, time/batch = 0.016\n",
      "2373/2800 (epoch 42), train_loss = 8.349, time/batch = 0.000\n",
      "2374/2800 (epoch 42), train_loss = 11.160, time/batch = 0.016\n",
      "2375/2800 (epoch 42), train_loss = 8.833, time/batch = 0.016\n",
      "2376/2800 (epoch 42), train_loss = 9.029, time/batch = 0.017\n",
      "2377/2800 (epoch 42), train_loss = 10.448, time/batch = 0.005\n",
      "2378/2800 (epoch 42), train_loss = 9.600, time/batch = 0.016\n",
      "2379/2800 (epoch 42), train_loss = 10.105, time/batch = 0.016\n",
      "2380/2800 (epoch 42), train_loss = 9.389, time/batch = 0.000\n",
      "2381/2800 (epoch 42), train_loss = 9.569, time/batch = 0.016\n",
      "2382/2800 (epoch 42), train_loss = 9.475, time/batch = 0.016\n",
      "2383/2800 (epoch 42), train_loss = 9.991, time/batch = 0.016\n",
      "2384/2800 (epoch 42), train_loss = 9.349, time/batch = 0.022\n",
      "2385/2800 (epoch 42), train_loss = 9.843, time/batch = 0.001\n",
      "2386/2800 (epoch 42), train_loss = 9.185, time/batch = 0.016\n",
      "2387/2800 (epoch 42), train_loss = 9.557, time/batch = 0.016\n",
      "2388/2800 (epoch 42), train_loss = 11.066, time/batch = 0.016\n",
      "2389/2800 (epoch 42), train_loss = 11.161, time/batch = 0.000\n",
      "2390/2800 (epoch 42), train_loss = 10.753, time/batch = 0.016\n",
      "2391/2800 (epoch 42), train_loss = 10.744, time/batch = 0.016\n",
      "2392/2800 (epoch 42), train_loss = 10.509, time/batch = 0.000\n",
      "2393/2800 (epoch 42), train_loss = 10.604, time/batch = 0.022\n",
      "2394/2800 (epoch 42), train_loss = 10.573, time/batch = 0.000\n",
      "2395/2800 (epoch 42), train_loss = 10.391, time/batch = 0.016\n",
      "2396/2800 (epoch 42), train_loss = 10.614, time/batch = 0.031\n",
      "2397/2800 (epoch 42), train_loss = 10.661, time/batch = 0.000\n",
      "2398/2800 (epoch 42), train_loss = 10.810, time/batch = 0.016\n",
      "2399/2800 (epoch 42), train_loss = 10.767, time/batch = 0.016\n",
      "2400/2800 (epoch 42), train_loss = 10.825, time/batch = 0.022\n",
      "2401/2800 (epoch 42), train_loss = 10.241, time/batch = 0.016\n",
      "2402/2800 (epoch 42), train_loss = 11.246, time/batch = 0.000\n",
      "2403/2800 (epoch 42), train_loss = 10.847, time/batch = 0.016\n",
      "2404/2800 (epoch 42), train_loss = 10.154, time/batch = 0.016\n",
      "2405/2800 (epoch 42), train_loss = 10.228, time/batch = 0.000\n",
      "2406/2800 (epoch 42), train_loss = 10.307, time/batch = 0.016\n",
      "2407/2800 (epoch 42), train_loss = 11.041, time/batch = 0.016\n",
      "2408/2800 (epoch 43), train_loss = 10.238, time/batch = 0.000\n",
      "2409/2800 (epoch 43), train_loss = 9.506, time/batch = 0.007\n",
      "2410/2800 (epoch 43), train_loss = 10.187, time/batch = 0.000\n",
      "2411/2800 (epoch 43), train_loss = 9.120, time/batch = 0.016\n",
      "2412/2800 (epoch 43), train_loss = 10.448, time/batch = 0.016\n",
      "2413/2800 (epoch 43), train_loss = 9.101, time/batch = 0.016\n",
      "2414/2800 (epoch 43), train_loss = 9.607, time/batch = 0.016\n",
      "2415/2800 (epoch 43), train_loss = 9.435, time/batch = 0.000\n",
      "2416/2800 (epoch 43), train_loss = 10.098, time/batch = 0.016\n",
      "2417/2800 (epoch 43), train_loss = 8.871, time/batch = 0.022\n",
      "2418/2800 (epoch 43), train_loss = 10.170, time/batch = 0.016\n",
      "2419/2800 (epoch 43), train_loss = 8.980, time/batch = 0.000\n",
      "2420/2800 (epoch 43), train_loss = 8.981, time/batch = 0.016\n",
      "2421/2800 (epoch 43), train_loss = 9.799, time/batch = 0.016\n",
      "2422/2800 (epoch 43), train_loss = 9.305, time/batch = 0.016\n",
      "2423/2800 (epoch 43), train_loss = 9.286, time/batch = 0.000\n",
      "2424/2800 (epoch 43), train_loss = 10.160, time/batch = 0.016\n",
      "2425/2800 (epoch 43), train_loss = 9.192, time/batch = 0.017\n",
      "2426/2800 (epoch 43), train_loss = 9.440, time/batch = 0.004\n",
      "2427/2800 (epoch 43), train_loss = 9.120, time/batch = 0.016\n",
      "2428/2800 (epoch 43), train_loss = 9.416, time/batch = 0.000\n",
      "2429/2800 (epoch 43), train_loss = 8.993, time/batch = 0.016\n",
      "2430/2800 (epoch 43), train_loss = 9.683, time/batch = 0.016\n",
      "2431/2800 (epoch 43), train_loss = 9.618, time/batch = 0.016\n",
      "2432/2800 (epoch 43), train_loss = 9.174, time/batch = 0.016\n",
      "2433/2800 (epoch 43), train_loss = 10.322, time/batch = 0.000\n",
      "2434/2800 (epoch 43), train_loss = 10.130, time/batch = 0.022\n",
      "2435/2800 (epoch 43), train_loss = 9.949, time/batch = 0.016\n",
      "2436/2800 (epoch 43), train_loss = 9.454, time/batch = 0.016\n",
      "2437/2800 (epoch 43), train_loss = 10.164, time/batch = 0.000\n",
      "2438/2800 (epoch 43), train_loss = 9.451, time/batch = 0.016\n",
      "2439/2800 (epoch 43), train_loss = 9.624, time/batch = 0.016\n",
      "2440/2800 (epoch 43), train_loss = 9.225, time/batch = 0.000\n",
      "2441/2800 (epoch 43), train_loss = 9.803, time/batch = 0.016\n",
      "2442/2800 (epoch 43), train_loss = 9.735, time/batch = 0.021\n",
      "2443/2800 (epoch 43), train_loss = 12.150, time/batch = 0.001\n",
      "2444/2800 (epoch 43), train_loss = 10.801, time/batch = 0.016\n",
      "2445/2800 (epoch 43), train_loss = 11.047, time/batch = 0.016\n",
      "2446/2800 (epoch 43), train_loss = 10.524, time/batch = 0.000\n",
      "2447/2800 (epoch 43), train_loss = 10.672, time/batch = 0.016\n",
      "2448/2800 (epoch 43), train_loss = 10.528, time/batch = 0.016\n",
      "2449/2800 (epoch 43), train_loss = 10.623, time/batch = 0.016\n",
      "2450/2800 (epoch 43), train_loss = 10.688, time/batch = 0.021\n",
      "2451/2800 (epoch 43), train_loss = 10.398, time/batch = 0.001\n",
      "2452/2800 (epoch 43), train_loss = 10.606, time/batch = 0.016\n",
      "2453/2800 (epoch 43), train_loss = 10.717, time/batch = 0.016\n",
      "2454/2800 (epoch 43), train_loss = 10.962, time/batch = 0.016\n",
      "2455/2800 (epoch 43), train_loss = 10.264, time/batch = 0.016\n",
      "2456/2800 (epoch 43), train_loss = 11.534, time/batch = 0.000\n",
      "2457/2800 (epoch 43), train_loss = 10.934, time/batch = 0.016\n",
      "2458/2800 (epoch 43), train_loss = 10.232, time/batch = 0.019\n",
      "2459/2800 (epoch 43), train_loss = 10.371, time/batch = 0.002\n",
      "2460/2800 (epoch 43), train_loss = 10.005, time/batch = 0.016\n",
      "2461/2800 (epoch 43), train_loss = 9.962, time/batch = 0.000\n",
      "2462/2800 (epoch 43), train_loss = 10.113, time/batch = 0.016\n",
      "2463/2800 (epoch 43), train_loss = 10.265, time/batch = 0.016\n",
      "2464/2800 (epoch 44), train_loss = 9.555, time/batch = 0.016\n",
      "2465/2800 (epoch 44), train_loss = 9.305, time/batch = 0.016\n",
      "2466/2800 (epoch 44), train_loss = 9.233, time/batch = 0.017\n",
      "2467/2800 (epoch 44), train_loss = 10.791, time/batch = 0.006\n",
      "2468/2800 (epoch 44), train_loss = 8.947, time/batch = 0.016\n",
      "2469/2800 (epoch 44), train_loss = 9.741, time/batch = 0.016\n",
      "2470/2800 (epoch 44), train_loss = 8.855, time/batch = 0.016\n",
      "2471/2800 (epoch 44), train_loss = 12.358, time/batch = 0.000\n",
      "2472/2800 (epoch 44), train_loss = 8.825, time/batch = 0.016\n",
      "2473/2800 (epoch 44), train_loss = 10.815, time/batch = 0.016\n",
      "2474/2800 (epoch 44), train_loss = 8.890, time/batch = 0.000\n",
      "2475/2800 (epoch 44), train_loss = 9.979, time/batch = 0.022\n",
      "2476/2800 (epoch 44), train_loss = 9.266, time/batch = 0.000\n",
      "2477/2800 (epoch 44), train_loss = 9.357, time/batch = 0.016\n",
      "2478/2800 (epoch 44), train_loss = 9.473, time/batch = 0.016\n",
      "2479/2800 (epoch 44), train_loss = 9.398, time/batch = 0.000\n",
      "2480/2800 (epoch 44), train_loss = 9.027, time/batch = 0.031\n",
      "2481/2800 (epoch 44), train_loss = 9.406, time/batch = 0.000\n",
      "2482/2800 (epoch 44), train_loss = 9.127, time/batch = 0.016\n",
      "2483/2800 (epoch 44), train_loss = 9.368, time/batch = 0.022\n",
      "2484/2800 (epoch 44), train_loss = 8.864, time/batch = 0.016\n",
      "2485/2800 (epoch 44), train_loss = 9.418, time/batch = 0.000\n",
      "2486/2800 (epoch 44), train_loss = 8.973, time/batch = 0.016\n",
      "2487/2800 (epoch 44), train_loss = 10.058, time/batch = 0.016\n",
      "2488/2800 (epoch 44), train_loss = 10.078, time/batch = 0.016\n",
      "2489/2800 (epoch 44), train_loss = 9.389, time/batch = 0.016\n",
      "2490/2800 (epoch 44), train_loss = 10.349, time/batch = 0.000\n",
      "2491/2800 (epoch 44), train_loss = 9.451, time/batch = 0.022\n",
      "2492/2800 (epoch 44), train_loss = 9.461, time/batch = 0.000\n",
      "2493/2800 (epoch 44), train_loss = 9.424, time/batch = 0.016\n",
      "2494/2800 (epoch 44), train_loss = 10.106, time/batch = 0.016\n",
      "2495/2800 (epoch 44), train_loss = 9.650, time/batch = 0.000\n",
      "2496/2800 (epoch 44), train_loss = 9.978, time/batch = 0.016\n",
      "2497/2800 (epoch 44), train_loss = 9.211, time/batch = 0.016\n",
      "2498/2800 (epoch 44), train_loss = 10.221, time/batch = 0.016\n",
      "2499/2800 (epoch 44), train_loss = 12.315, time/batch = 0.000\n",
      "2500/2800 (epoch 44), train_loss = 10.803, time/batch = 0.022\n",
      "model saved to save\\model.ckpt\n",
      "2501/2800 (epoch 44), train_loss = 10.717, time/batch = 0.031\n",
      "2502/2800 (epoch 44), train_loss = 10.745, time/batch = 0.031\n",
      "2503/2800 (epoch 44), train_loss = 10.514, time/batch = 0.022\n",
      "2504/2800 (epoch 44), train_loss = 10.901, time/batch = 0.031\n",
      "2505/2800 (epoch 44), train_loss = 10.621, time/batch = 0.031\n",
      "2506/2800 (epoch 44), train_loss = 10.846, time/batch = 0.037\n",
      "2507/2800 (epoch 44), train_loss = 10.260, time/batch = 0.031\n",
      "2508/2800 (epoch 44), train_loss = 10.140, time/batch = 0.031\n",
      "2509/2800 (epoch 44), train_loss = 10.891, time/batch = 0.038\n",
      "2510/2800 (epoch 44), train_loss = 10.632, time/batch = 0.031\n",
      "2511/2800 (epoch 44), train_loss = 10.325, time/batch = 0.031\n",
      "2512/2800 (epoch 44), train_loss = 10.653, time/batch = 0.038\n",
      "2513/2800 (epoch 44), train_loss = 10.168, time/batch = 0.047\n",
      "2514/2800 (epoch 44), train_loss = 11.224, time/batch = 0.031\n",
      "2515/2800 (epoch 44), train_loss = 10.011, time/batch = 0.038\n",
      "2516/2800 (epoch 44), train_loss = 10.715, time/batch = 0.031\n",
      "2517/2800 (epoch 44), train_loss = 10.074, time/batch = 0.031\n",
      "2518/2800 (epoch 44), train_loss = 10.268, time/batch = 0.053\n",
      "2519/2800 (epoch 44), train_loss = 10.302, time/batch = 0.047\n",
      "2520/2800 (epoch 45), train_loss = 9.454, time/batch = 0.041\n",
      "2521/2800 (epoch 45), train_loss = 10.175, time/batch = 0.036\n",
      "2522/2800 (epoch 45), train_loss = 8.960, time/batch = 0.037\n",
      "2523/2800 (epoch 45), train_loss = 9.599, time/batch = 0.037\n",
      "2524/2800 (epoch 45), train_loss = 9.632, time/batch = 0.040\n",
      "2525/2800 (epoch 45), train_loss = 9.265, time/batch = 0.045\n",
      "2526/2800 (epoch 45), train_loss = 9.595, time/batch = 0.036\n",
      "2527/2800 (epoch 45), train_loss = 9.327, time/batch = 0.034\n",
      "2528/2800 (epoch 45), train_loss = 9.800, time/batch = 0.038\n",
      "2529/2800 (epoch 45), train_loss = 8.987, time/batch = 0.039\n",
      "2530/2800 (epoch 45), train_loss = 9.911, time/batch = 0.033\n",
      "2531/2800 (epoch 45), train_loss = 9.145, time/batch = 0.067\n",
      "2532/2800 (epoch 45), train_loss = 9.981, time/batch = 0.038\n",
      "2533/2800 (epoch 45), train_loss = 8.919, time/batch = 0.033\n",
      "2534/2800 (epoch 45), train_loss = 9.992, time/batch = 0.047\n",
      "2535/2800 (epoch 45), train_loss = 9.183, time/batch = 0.038\n",
      "2536/2800 (epoch 45), train_loss = 10.190, time/batch = 0.016\n",
      "2537/2800 (epoch 45), train_loss = 8.949, time/batch = 0.031\n",
      "2538/2800 (epoch 45), train_loss = 10.225, time/batch = 0.036\n",
      "2539/2800 (epoch 45), train_loss = 8.895, time/batch = 0.017\n",
      "2540/2800 (epoch 45), train_loss = 10.151, time/batch = 0.031\n",
      "2541/2800 (epoch 45), train_loss = 9.190, time/batch = 0.031\n",
      "2542/2800 (epoch 45), train_loss = 9.895, time/batch = 0.038\n",
      "2543/2800 (epoch 45), train_loss = 9.676, time/batch = 0.047\n",
      "2544/2800 (epoch 45), train_loss = 9.773, time/batch = 0.036\n",
      "2545/2800 (epoch 45), train_loss = 9.524, time/batch = 0.032\n",
      "2546/2800 (epoch 45), train_loss = 9.728, time/batch = 0.016\n",
      "2547/2800 (epoch 45), train_loss = 9.420, time/batch = 0.031\n",
      "2548/2800 (epoch 45), train_loss = 9.430, time/batch = 0.038\n",
      "2549/2800 (epoch 45), train_loss = 9.954, time/batch = 0.031\n",
      "2550/2800 (epoch 45), train_loss = 9.781, time/batch = 0.031\n",
      "2551/2800 (epoch 45), train_loss = 9.194, time/batch = 0.022\n",
      "2552/2800 (epoch 45), train_loss = 9.703, time/batch = 0.031\n",
      "2553/2800 (epoch 45), train_loss = 9.323, time/batch = 0.016\n",
      "2554/2800 (epoch 45), train_loss = 9.656, time/batch = 0.032\n",
      "2555/2800 (epoch 45), train_loss = 9.476, time/batch = 0.021\n",
      "2556/2800 (epoch 45), train_loss = 12.547, time/batch = 0.016\n",
      "2557/2800 (epoch 45), train_loss = 10.936, time/batch = 0.031\n",
      "2558/2800 (epoch 45), train_loss = 10.848, time/batch = 0.016\n",
      "2559/2800 (epoch 45), train_loss = 10.698, time/batch = 0.038\n",
      "2560/2800 (epoch 45), train_loss = 10.455, time/batch = 0.016\n",
      "2561/2800 (epoch 45), train_loss = 10.533, time/batch = 0.031\n",
      "2562/2800 (epoch 45), train_loss = 10.417, time/batch = 0.034\n",
      "2563/2800 (epoch 45), train_loss = 11.042, time/batch = 0.021\n",
      "2564/2800 (epoch 45), train_loss = 10.293, time/batch = 0.018\n",
      "2565/2800 (epoch 45), train_loss = 10.259, time/batch = 0.016\n",
      "2566/2800 (epoch 45), train_loss = 11.050, time/batch = 0.031\n",
      "2567/2800 (epoch 45), train_loss = 10.517, time/batch = 0.032\n",
      "2568/2800 (epoch 45), train_loss = 10.205, time/batch = 0.006\n",
      "2569/2800 (epoch 45), train_loss = 11.175, time/batch = 0.031\n",
      "2570/2800 (epoch 45), train_loss = 10.677, time/batch = 0.016\n",
      "2571/2800 (epoch 45), train_loss = 10.351, time/batch = 0.031\n",
      "2572/2800 (epoch 45), train_loss = 10.445, time/batch = 0.022\n",
      "2573/2800 (epoch 45), train_loss = 10.169, time/batch = 0.031\n",
      "2574/2800 (epoch 45), train_loss = 11.229, time/batch = 0.016\n",
      "2575/2800 (epoch 45), train_loss = 10.038, time/batch = 0.031\n",
      "2576/2800 (epoch 46), train_loss = 9.880, time/batch = 0.038\n",
      "2577/2800 (epoch 46), train_loss = 9.361, time/batch = 0.016\n",
      "2578/2800 (epoch 46), train_loss = 9.388, time/batch = 0.031\n",
      "2579/2800 (epoch 46), train_loss = 9.947, time/batch = 0.016\n",
      "2580/2800 (epoch 46), train_loss = 9.253, time/batch = 0.022\n",
      "2581/2800 (epoch 46), train_loss = 10.072, time/batch = 0.016\n",
      "2582/2800 (epoch 46), train_loss = 9.228, time/batch = 0.031\n",
      "2583/2800 (epoch 46), train_loss = 9.963, time/batch = 0.016\n",
      "2584/2800 (epoch 46), train_loss = 9.314, time/batch = 0.016\n",
      "2585/2800 (epoch 46), train_loss = 9.594, time/batch = 0.022\n",
      "2586/2800 (epoch 46), train_loss = 9.248, time/batch = 0.016\n",
      "2587/2800 (epoch 46), train_loss = 10.056, time/batch = 0.031\n",
      "2588/2800 (epoch 46), train_loss = 9.057, time/batch = 0.016\n",
      "2589/2800 (epoch 46), train_loss = 9.461, time/batch = 0.016\n",
      "2590/2800 (epoch 46), train_loss = 9.243, time/batch = 0.022\n",
      "2591/2800 (epoch 46), train_loss = 9.595, time/batch = 0.016\n",
      "2592/2800 (epoch 46), train_loss = 9.182, time/batch = 0.031\n",
      "2593/2800 (epoch 46), train_loss = 9.333, time/batch = 0.016\n",
      "2594/2800 (epoch 46), train_loss = 9.076, time/batch = 0.033\n",
      "2595/2800 (epoch 46), train_loss = 9.201, time/batch = 0.004\n",
      "2596/2800 (epoch 46), train_loss = 9.278, time/batch = 0.032\n",
      "2597/2800 (epoch 46), train_loss = 10.158, time/batch = 0.016\n",
      "2598/2800 (epoch 46), train_loss = 9.366, time/batch = 0.031\n",
      "2599/2800 (epoch 46), train_loss = 9.742, time/batch = 0.022\n",
      "2600/2800 (epoch 46), train_loss = 9.860, time/batch = 0.016\n",
      "2601/2800 (epoch 46), train_loss = 9.773, time/batch = 0.016\n",
      "2602/2800 (epoch 46), train_loss = 9.680, time/batch = 0.016\n",
      "2603/2800 (epoch 46), train_loss = 9.388, time/batch = 0.031\n",
      "2604/2800 (epoch 46), train_loss = 9.611, time/batch = 0.022\n",
      "2605/2800 (epoch 46), train_loss = 9.504, time/batch = 0.016\n",
      "2606/2800 (epoch 46), train_loss = 9.692, time/batch = 0.016\n",
      "2607/2800 (epoch 46), train_loss = 9.428, time/batch = 0.016\n",
      "2608/2800 (epoch 46), train_loss = 9.517, time/batch = 0.031\n",
      "2609/2800 (epoch 46), train_loss = 9.315, time/batch = 0.021\n",
      "2610/2800 (epoch 46), train_loss = 10.258, time/batch = 0.016\n",
      "2611/2800 (epoch 46), train_loss = 11.893, time/batch = 0.016\n",
      "2612/2800 (epoch 46), train_loss = 10.628, time/batch = 0.016\n",
      "2613/2800 (epoch 46), train_loss = 11.600, time/batch = 0.031\n",
      "2614/2800 (epoch 46), train_loss = 10.516, time/batch = 0.021\n",
      "2615/2800 (epoch 46), train_loss = 10.935, time/batch = 0.017\n",
      "2616/2800 (epoch 46), train_loss = 10.346, time/batch = 0.016\n",
      "2617/2800 (epoch 46), train_loss = 10.871, time/batch = 0.016\n",
      "2618/2800 (epoch 46), train_loss = 10.417, time/batch = 0.016\n",
      "2619/2800 (epoch 46), train_loss = 10.719, time/batch = 0.031\n",
      "2620/2800 (epoch 46), train_loss = 10.574, time/batch = 0.006\n",
      "2621/2800 (epoch 46), train_loss = 10.448, time/batch = 0.031\n",
      "2622/2800 (epoch 46), train_loss = 9.921, time/batch = 0.016\n",
      "2623/2800 (epoch 46), train_loss = 11.296, time/batch = 0.016\n",
      "2624/2800 (epoch 46), train_loss = 10.551, time/batch = 0.016\n",
      "2625/2800 (epoch 46), train_loss = 10.904, time/batch = 0.022\n",
      "2626/2800 (epoch 46), train_loss = 10.273, time/batch = 0.016\n",
      "2627/2800 (epoch 46), train_loss = 10.343, time/batch = 0.031\n",
      "2628/2800 (epoch 46), train_loss = 10.173, time/batch = 0.016\n",
      "2629/2800 (epoch 46), train_loss = 10.422, time/batch = 0.016\n",
      "2630/2800 (epoch 46), train_loss = 10.159, time/batch = 0.022\n",
      "2631/2800 (epoch 46), train_loss = 9.633, time/batch = 0.016\n",
      "2632/2800 (epoch 47), train_loss = 9.697, time/batch = 0.016\n",
      "2633/2800 (epoch 47), train_loss = 9.244, time/batch = 0.016\n",
      "2634/2800 (epoch 47), train_loss = 9.123, time/batch = 0.016\n",
      "2635/2800 (epoch 47), train_loss = 9.973, time/batch = 0.022\n",
      "2636/2800 (epoch 47), train_loss = 8.869, time/batch = 0.016\n",
      "2637/2800 (epoch 47), train_loss = 10.371, time/batch = 0.016\n",
      "2638/2800 (epoch 47), train_loss = 9.160, time/batch = 0.016\n",
      "2639/2800 (epoch 47), train_loss = 10.100, time/batch = 0.031\n",
      "2640/2800 (epoch 47), train_loss = 8.962, time/batch = 0.020\n",
      "2641/2800 (epoch 47), train_loss = 9.508, time/batch = 0.018\n",
      "2642/2800 (epoch 47), train_loss = 10.083, time/batch = 0.016\n",
      "2643/2800 (epoch 47), train_loss = 8.805, time/batch = 0.016\n",
      "2644/2800 (epoch 47), train_loss = 9.353, time/batch = 0.016\n",
      "2645/2800 (epoch 47), train_loss = 9.528, time/batch = 0.035\n",
      "2646/2800 (epoch 47), train_loss = 9.358, time/batch = 0.018\n",
      "2647/2800 (epoch 47), train_loss = 10.275, time/batch = 0.016\n",
      "2648/2800 (epoch 47), train_loss = 8.887, time/batch = 0.016\n",
      "2649/2800 (epoch 47), train_loss = 9.408, time/batch = 0.016\n",
      "2650/2800 (epoch 47), train_loss = 8.923, time/batch = 0.035\n",
      "2651/2800 (epoch 47), train_loss = 9.927, time/batch = 0.018\n",
      "2652/2800 (epoch 47), train_loss = 9.317, time/batch = 0.016\n",
      "2653/2800 (epoch 47), train_loss = 9.541, time/batch = 0.016\n",
      "2654/2800 (epoch 47), train_loss = 8.783, time/batch = 0.016\n",
      "2655/2800 (epoch 47), train_loss = 10.097, time/batch = 0.016\n",
      "2656/2800 (epoch 47), train_loss = 9.548, time/batch = 0.022\n",
      "2657/2800 (epoch 47), train_loss = 9.413, time/batch = 0.016\n",
      "2658/2800 (epoch 47), train_loss = 9.842, time/batch = 0.016\n",
      "2659/2800 (epoch 47), train_loss = 9.992, time/batch = 0.016\n",
      "2660/2800 (epoch 47), train_loss = 9.341, time/batch = 0.016\n",
      "2661/2800 (epoch 47), train_loss = 9.671, time/batch = 0.016\n",
      "2662/2800 (epoch 47), train_loss = 9.943, time/batch = 0.018\n",
      "2663/2800 (epoch 47), train_loss = 10.118, time/batch = 0.004\n",
      "2664/2800 (epoch 47), train_loss = 9.410, time/batch = 0.016\n",
      "2665/2800 (epoch 47), train_loss = 9.893, time/batch = 0.016\n",
      "2666/2800 (epoch 47), train_loss = 9.313, time/batch = 0.016\n",
      "2667/2800 (epoch 47), train_loss = 9.436, time/batch = 0.016\n",
      "2668/2800 (epoch 47), train_loss = 9.959, time/batch = 0.016\n",
      "2669/2800 (epoch 47), train_loss = 11.602, time/batch = 0.016\n",
      "2670/2800 (epoch 47), train_loss = 11.056, time/batch = 0.007\n",
      "2671/2800 (epoch 47), train_loss = 10.853, time/batch = 0.016\n",
      "2672/2800 (epoch 47), train_loss = 10.572, time/batch = 0.016\n",
      "2673/2800 (epoch 47), train_loss = 10.892, time/batch = 0.000\n",
      "2674/2800 (epoch 47), train_loss = 10.494, time/batch = 0.016\n",
      "2675/2800 (epoch 47), train_loss = 10.841, time/batch = 0.016\n",
      "2676/2800 (epoch 47), train_loss = 10.335, time/batch = 0.016\n",
      "2677/2800 (epoch 47), train_loss = 10.980, time/batch = 0.019\n",
      "2678/2800 (epoch 47), train_loss = 10.275, time/batch = 0.003\n",
      "2679/2800 (epoch 47), train_loss = 10.661, time/batch = 0.016\n",
      "2680/2800 (epoch 47), train_loss = 10.684, time/batch = 0.016\n",
      "2681/2800 (epoch 47), train_loss = 10.097, time/batch = 0.016\n",
      "2682/2800 (epoch 47), train_loss = 10.917, time/batch = 0.016\n",
      "2683/2800 (epoch 47), train_loss = 10.932, time/batch = 0.000\n",
      "2684/2800 (epoch 47), train_loss = 9.928, time/batch = 0.016\n",
      "2685/2800 (epoch 47), train_loss = 10.280, time/batch = 0.019\n",
      "2686/2800 (epoch 47), train_loss = 9.981, time/batch = 0.003\n",
      "2687/2800 (epoch 47), train_loss = 10.788, time/batch = 0.016\n",
      "2688/2800 (epoch 48), train_loss = 9.933, time/batch = 0.000\n",
      "2689/2800 (epoch 48), train_loss = 9.321, time/batch = 0.016\n",
      "2690/2800 (epoch 48), train_loss = 9.363, time/batch = 0.016\n",
      "2691/2800 (epoch 48), train_loss = 9.598, time/batch = 0.016\n",
      "2692/2800 (epoch 48), train_loss = 9.391, time/batch = 0.016\n",
      "2693/2800 (epoch 48), train_loss = 9.432, time/batch = 0.022\n",
      "2694/2800 (epoch 48), train_loss = 9.545, time/batch = 0.000\n",
      "2695/2800 (epoch 48), train_loss = 9.553, time/batch = 0.016\n",
      "2696/2800 (epoch 48), train_loss = 9.271, time/batch = 0.016\n",
      "2697/2800 (epoch 48), train_loss = 9.332, time/batch = 0.016\n",
      "2698/2800 (epoch 48), train_loss = 9.245, time/batch = 0.016\n",
      "2699/2800 (epoch 48), train_loss = 9.637, time/batch = 0.016\n",
      "2700/2800 (epoch 48), train_loss = 9.399, time/batch = 0.000\n",
      "2701/2800 (epoch 48), train_loss = 9.926, time/batch = 0.022\n",
      "2702/2800 (epoch 48), train_loss = 9.131, time/batch = 0.000\n",
      "2703/2800 (epoch 48), train_loss = 9.501, time/batch = 0.016\n",
      "2704/2800 (epoch 48), train_loss = 9.031, time/batch = 0.016\n",
      "2705/2800 (epoch 48), train_loss = 9.610, time/batch = 0.016\n",
      "2706/2800 (epoch 48), train_loss = 8.965, time/batch = 0.000\n",
      "2707/2800 (epoch 48), train_loss = 9.563, time/batch = 0.016\n",
      "2708/2800 (epoch 48), train_loss = 9.513, time/batch = 0.016\n",
      "2709/2800 (epoch 48), train_loss = 9.827, time/batch = 0.022\n",
      "2710/2800 (epoch 48), train_loss = 9.532, time/batch = 0.000\n",
      "2711/2800 (epoch 48), train_loss = 9.793, time/batch = 0.016\n",
      "2712/2800 (epoch 48), train_loss = 9.655, time/batch = 0.016\n",
      "2713/2800 (epoch 48), train_loss = 9.464, time/batch = 0.016\n",
      "2714/2800 (epoch 48), train_loss = 9.442, time/batch = 0.016\n",
      "2715/2800 (epoch 48), train_loss = 9.660, time/batch = 0.016\n",
      "2716/2800 (epoch 48), train_loss = 9.292, time/batch = 0.000\n",
      "2717/2800 (epoch 48), train_loss = 10.213, time/batch = 0.022\n",
      "2718/2800 (epoch 48), train_loss = 8.991, time/batch = 0.000\n",
      "2719/2800 (epoch 48), train_loss = 9.991, time/batch = 0.016\n",
      "2720/2800 (epoch 48), train_loss = 9.133, time/batch = 0.016\n",
      "2721/2800 (epoch 48), train_loss = 10.678, time/batch = 0.000\n",
      "2722/2800 (epoch 48), train_loss = 12.190, time/batch = 0.016\n",
      "2723/2800 (epoch 48), train_loss = 10.773, time/batch = 0.016\n",
      "2724/2800 (epoch 48), train_loss = 11.371, time/batch = 0.016\n",
      "2725/2800 (epoch 48), train_loss = 10.681, time/batch = 0.018\n",
      "2726/2800 (epoch 48), train_loss = 10.625, time/batch = 0.004\n",
      "2727/2800 (epoch 48), train_loss = 10.319, time/batch = 0.016\n",
      "2728/2800 (epoch 48), train_loss = 10.651, time/batch = 0.016\n",
      "2729/2800 (epoch 48), train_loss = 10.359, time/batch = 0.016\n",
      "2730/2800 (epoch 48), train_loss = 10.617, time/batch = 0.016\n",
      "2731/2800 (epoch 48), train_loss = 10.806, time/batch = 0.016\n",
      "2732/2800 (epoch 48), train_loss = 10.359, time/batch = 0.000\n",
      "2733/2800 (epoch 48), train_loss = 10.147, time/batch = 0.022\n",
      "2734/2800 (epoch 48), train_loss = 11.365, time/batch = 0.000\n",
      "2735/2800 (epoch 48), train_loss = 10.659, time/batch = 0.016\n",
      "2736/2800 (epoch 48), train_loss = 10.206, time/batch = 0.016\n",
      "2737/2800 (epoch 48), train_loss = 10.260, time/batch = 0.000\n",
      "2738/2800 (epoch 48), train_loss = 10.058, time/batch = 0.000\n",
      "2739/2800 (epoch 48), train_loss = 11.111, time/batch = 0.016\n",
      "2740/2800 (epoch 48), train_loss = 10.187, time/batch = 0.016\n",
      "2741/2800 (epoch 48), train_loss = 9.931, time/batch = 0.021\n",
      "2742/2800 (epoch 48), train_loss = 9.801, time/batch = 0.002\n",
      "2743/2800 (epoch 48), train_loss = 9.453, time/batch = 0.016\n",
      "2744/2800 (epoch 49), train_loss = 9.239, time/batch = 0.016\n",
      "2745/2800 (epoch 49), train_loss = 9.069, time/batch = 0.016\n",
      "2746/2800 (epoch 49), train_loss = 9.476, time/batch = 0.016\n",
      "2747/2800 (epoch 49), train_loss = 9.545, time/batch = 0.016\n",
      "2748/2800 (epoch 49), train_loss = 9.206, time/batch = 0.000\n",
      "2749/2800 (epoch 49), train_loss = 9.848, time/batch = 0.022\n",
      "2750/2800 (epoch 49), train_loss = 9.315, time/batch = 0.000\n",
      "2751/2800 (epoch 49), train_loss = 9.600, time/batch = 0.016\n",
      "2752/2800 (epoch 49), train_loss = 9.444, time/batch = 0.016\n",
      "2753/2800 (epoch 49), train_loss = 9.560, time/batch = 0.000\n",
      "2754/2800 (epoch 49), train_loss = 9.543, time/batch = 0.000\n",
      "2755/2800 (epoch 49), train_loss = 9.343, time/batch = 0.016\n",
      "2756/2800 (epoch 49), train_loss = 8.933, time/batch = 0.016\n",
      "2757/2800 (epoch 49), train_loss = 10.559, time/batch = 0.018\n",
      "2758/2800 (epoch 49), train_loss = 8.854, time/batch = 0.004\n",
      "2759/2800 (epoch 49), train_loss = 10.218, time/batch = 0.016\n",
      "2760/2800 (epoch 49), train_loss = 8.751, time/batch = 0.016\n",
      "2761/2800 (epoch 49), train_loss = 9.969, time/batch = 0.016\n",
      "2762/2800 (epoch 49), train_loss = 8.690, time/batch = 0.016\n",
      "2763/2800 (epoch 49), train_loss = 11.412, time/batch = 0.000\n",
      "2764/2800 (epoch 49), train_loss = 8.984, time/batch = 0.016\n",
      "2765/2800 (epoch 49), train_loss = 10.741, time/batch = 0.022\n",
      "2766/2800 (epoch 49), train_loss = 8.673, time/batch = 0.000\n",
      "2767/2800 (epoch 49), train_loss = 10.515, time/batch = 0.016\n",
      "2768/2800 (epoch 49), train_loss = 9.253, time/batch = 0.016\n",
      "2769/2800 (epoch 49), train_loss = 9.912, time/batch = 0.000\n",
      "2770/2800 (epoch 49), train_loss = 9.375, time/batch = 0.016\n",
      "2771/2800 (epoch 49), train_loss = 9.607, time/batch = 0.016\n",
      "2772/2800 (epoch 49), train_loss = 9.479, time/batch = 0.016\n",
      "2773/2800 (epoch 49), train_loss = 9.948, time/batch = 0.000\n",
      "2774/2800 (epoch 49), train_loss = 9.166, time/batch = 0.022\n",
      "2775/2800 (epoch 49), train_loss = 9.657, time/batch = 0.016\n",
      "2776/2800 (epoch 49), train_loss = 9.654, time/batch = 0.016\n",
      "2777/2800 (epoch 49), train_loss = 9.535, time/batch = 0.000\n",
      "2778/2800 (epoch 49), train_loss = 9.842, time/batch = 0.000\n",
      "2779/2800 (epoch 49), train_loss = 9.385, time/batch = 0.016\n",
      "2780/2800 (epoch 49), train_loss = 9.900, time/batch = 0.016\n",
      "2781/2800 (epoch 49), train_loss = 11.016, time/batch = 0.021\n",
      "2782/2800 (epoch 49), train_loss = 10.673, time/batch = 0.000\n",
      "2783/2800 (epoch 49), train_loss = 10.779, time/batch = 0.016\n",
      "2784/2800 (epoch 49), train_loss = 10.971, time/batch = 0.016\n",
      "2785/2800 (epoch 49), train_loss = 10.487, time/batch = 0.000\n",
      "2786/2800 (epoch 49), train_loss = 10.701, time/batch = 0.016\n",
      "2787/2800 (epoch 49), train_loss = 10.346, time/batch = 0.016\n",
      "2788/2800 (epoch 49), train_loss = 10.854, time/batch = 0.016\n",
      "2789/2800 (epoch 49), train_loss = 10.622, time/batch = 0.000\n",
      "2790/2800 (epoch 49), train_loss = 10.267, time/batch = 0.023\n",
      "2791/2800 (epoch 49), train_loss = 10.688, time/batch = 0.016\n",
      "2792/2800 (epoch 49), train_loss = 10.486, time/batch = 0.016\n",
      "2793/2800 (epoch 49), train_loss = 10.005, time/batch = 0.016\n",
      "2794/2800 (epoch 49), train_loss = 11.217, time/batch = 0.000\n",
      "2795/2800 (epoch 49), train_loss = 10.397, time/batch = 0.016\n",
      "2796/2800 (epoch 49), train_loss = 10.653, time/batch = 0.016\n",
      "2797/2800 (epoch 49), train_loss = 10.303, time/batch = 0.021\n",
      "2798/2800 (epoch 49), train_loss = 11.215, time/batch = 0.000\n",
      "2799/2800 (epoch 49), train_loss = 9.846, time/batch = 0.016\n",
      "2800/2800 (epoch 50), train_loss = 10.613, time/batch = 0.016\n",
      "2801/2800 (epoch 50), train_loss = 9.625, time/batch = 0.000\n",
      "2802/2800 (epoch 50), train_loss = 9.525, time/batch = 0.016\n",
      "2803/2800 (epoch 50), train_loss = 9.348, time/batch = 0.016\n",
      "2804/2800 (epoch 50), train_loss = 9.910, time/batch = 0.016\n",
      "2805/2800 (epoch 50), train_loss = 9.205, time/batch = 0.021\n",
      "2806/2800 (epoch 50), train_loss = 9.375, time/batch = 0.001\n",
      "2807/2800 (epoch 50), train_loss = 9.833, time/batch = 0.016\n",
      "2808/2800 (epoch 50), train_loss = 9.839, time/batch = 0.016\n",
      "2809/2800 (epoch 50), train_loss = 9.370, time/batch = 0.016\n",
      "2810/2800 (epoch 50), train_loss = 9.675, time/batch = 0.016\n",
      "2811/2800 (epoch 50), train_loss = 9.323, time/batch = 0.016\n",
      "2812/2800 (epoch 50), train_loss = 9.257, time/batch = 0.016\n",
      "2813/2800 (epoch 50), train_loss = 9.438, time/batch = 0.006\n",
      "2814/2800 (epoch 50), train_loss = 9.358, time/batch = 0.000\n",
      "2815/2800 (epoch 50), train_loss = 9.411, time/batch = 0.016\n",
      "2816/2800 (epoch 50), train_loss = 9.261, time/batch = 0.016\n",
      "2817/2800 (epoch 50), train_loss = 9.078, time/batch = 0.016\n",
      "2818/2800 (epoch 50), train_loss = 9.383, time/batch = 0.000\n",
      "2819/2800 (epoch 50), train_loss = 9.064, time/batch = 0.016\n",
      "2820/2800 (epoch 50), train_loss = 9.379, time/batch = 0.016\n",
      "2821/2800 (epoch 50), train_loss = 8.991, time/batch = 0.022\n",
      "2822/2800 (epoch 50), train_loss = 9.677, time/batch = 0.000\n",
      "2823/2800 (epoch 50), train_loss = 9.258, time/batch = 0.016\n",
      "2824/2800 (epoch 50), train_loss = 10.120, time/batch = 0.016\n",
      "2825/2800 (epoch 50), train_loss = 9.471, time/batch = 0.016\n",
      "2826/2800 (epoch 50), train_loss = 10.007, time/batch = 0.016\n",
      "2827/2800 (epoch 50), train_loss = 9.323, time/batch = 0.016\n",
      "2828/2800 (epoch 50), train_loss = 9.774, time/batch = 0.000\n",
      "2829/2800 (epoch 50), train_loss = 9.279, time/batch = 0.022\n",
      "2830/2800 (epoch 50), train_loss = 10.129, time/batch = 0.000\n",
      "2831/2800 (epoch 50), train_loss = 9.394, time/batch = 0.016\n",
      "2832/2800 (epoch 50), train_loss = 10.326, time/batch = 0.016\n",
      "2833/2800 (epoch 50), train_loss = 9.259, time/batch = 0.000\n",
      "2834/2800 (epoch 50), train_loss = 9.984, time/batch = 0.016\n",
      "2835/2800 (epoch 50), train_loss = 9.071, time/batch = 0.016\n",
      "2836/2800 (epoch 50), train_loss = 13.007, time/batch = 0.016\n",
      "2837/2800 (epoch 50), train_loss = 12.339, time/batch = 0.019\n",
      "2838/2800 (epoch 50), train_loss = 10.809, time/batch = 0.003\n",
      "2839/2800 (epoch 50), train_loss = 10.932, time/batch = 0.016\n",
      "2840/2800 (epoch 50), train_loss = 10.709, time/batch = 0.016\n",
      "2841/2800 (epoch 50), train_loss = 10.536, time/batch = 0.016\n",
      "2842/2800 (epoch 50), train_loss = 10.658, time/batch = 0.016\n",
      "2843/2800 (epoch 50), train_loss = 10.432, time/batch = 0.016\n",
      "2844/2800 (epoch 50), train_loss = 10.584, time/batch = 0.000\n",
      "2845/2800 (epoch 50), train_loss = 10.713, time/batch = 0.022\n",
      "2846/2800 (epoch 50), train_loss = 10.295, time/batch = 0.000\n",
      "2847/2800 (epoch 50), train_loss = 10.418, time/batch = 0.016\n",
      "2848/2800 (epoch 50), train_loss = 11.187, time/batch = 0.016\n",
      "2849/2800 (epoch 50), train_loss = 10.281, time/batch = 0.000\n",
      "2850/2800 (epoch 50), train_loss = 10.683, time/batch = 0.016\n",
      "2851/2800 (epoch 50), train_loss = 10.244, time/batch = 0.016\n",
      "2852/2800 (epoch 50), train_loss = 11.000, time/batch = 0.016\n",
      "2853/2800 (epoch 50), train_loss = 10.277, time/batch = 0.021\n",
      "2854/2800 (epoch 50), train_loss = 10.211, time/batch = 0.002\n",
      "2855/2800 (epoch 50), train_loss = 10.289, time/batch = 0.016\n",
      "2856/2800 (epoch 51), train_loss = 9.964, time/batch = 0.016\n",
      "2857/2800 (epoch 51), train_loss = 9.358, time/batch = 0.016\n",
      "2858/2800 (epoch 51), train_loss = 9.335, time/batch = 0.016\n",
      "2859/2800 (epoch 51), train_loss = 10.221, time/batch = 0.016\n",
      "2860/2800 (epoch 51), train_loss = 8.928, time/batch = 0.000\n",
      "2861/2800 (epoch 51), train_loss = 9.914, time/batch = 0.022\n",
      "2862/2800 (epoch 51), train_loss = 8.882, time/batch = 0.000\n",
      "2863/2800 (epoch 51), train_loss = 9.860, time/batch = 0.016\n",
      "2864/2800 (epoch 51), train_loss = 8.940, time/batch = 0.016\n",
      "2865/2800 (epoch 51), train_loss = 9.016, time/batch = 0.016\n",
      "2866/2800 (epoch 51), train_loss = 10.959, time/batch = 0.000\n",
      "2867/2800 (epoch 51), train_loss = 8.994, time/batch = 0.016\n",
      "2868/2800 (epoch 51), train_loss = 9.386, time/batch = 0.016\n",
      "2869/2800 (epoch 51), train_loss = 9.792, time/batch = 0.021\n",
      "2870/2800 (epoch 51), train_loss = 9.342, time/batch = 0.002\n",
      "2871/2800 (epoch 51), train_loss = 9.402, time/batch = 0.016\n",
      "2872/2800 (epoch 51), train_loss = 8.899, time/batch = 0.016\n",
      "2873/2800 (epoch 51), train_loss = 9.555, time/batch = 0.016\n",
      "2874/2800 (epoch 51), train_loss = 9.435, time/batch = 0.016\n",
      "2875/2800 (epoch 51), train_loss = 9.323, time/batch = 0.016\n",
      "2876/2800 (epoch 51), train_loss = 9.307, time/batch = 0.000\n",
      "2877/2800 (epoch 51), train_loss = 9.832, time/batch = 0.022\n",
      "2878/2800 (epoch 51), train_loss = 9.065, time/batch = 0.000\n",
      "2879/2800 (epoch 51), train_loss = 9.466, time/batch = 0.016\n",
      "2880/2800 (epoch 51), train_loss = 9.921, time/batch = 0.016\n",
      "2881/2800 (epoch 51), train_loss = 9.666, time/batch = 0.000\n",
      "2882/2800 (epoch 51), train_loss = 9.660, time/batch = 0.016\n",
      "2883/2800 (epoch 51), train_loss = 9.406, time/batch = 0.016\n",
      "2884/2800 (epoch 51), train_loss = 9.330, time/batch = 0.016\n",
      "2885/2800 (epoch 51), train_loss = 9.602, time/batch = 0.019\n",
      "2886/2800 (epoch 51), train_loss = 10.383, time/batch = 0.003\n",
      "2887/2800 (epoch 51), train_loss = 9.501, time/batch = 0.016\n",
      "2888/2800 (epoch 51), train_loss = 9.591, time/batch = 0.016\n",
      "2889/2800 (epoch 51), train_loss = 9.573, time/batch = 0.016\n",
      "2890/2800 (epoch 51), train_loss = 9.986, time/batch = 0.016\n",
      "2891/2800 (epoch 51), train_loss = 11.858, time/batch = 0.000\n",
      "2892/2800 (epoch 51), train_loss = 10.820, time/batch = 0.016\n",
      "2893/2800 (epoch 51), train_loss = 10.867, time/batch = 0.022\n",
      "2894/2800 (epoch 51), train_loss = 10.839, time/batch = 0.000\n",
      "2895/2800 (epoch 51), train_loss = 10.433, time/batch = 0.016\n",
      "2896/2800 (epoch 51), train_loss = 10.921, time/batch = 0.016\n",
      "2897/2800 (epoch 51), train_loss = 10.252, time/batch = 0.000\n",
      "2898/2800 (epoch 51), train_loss = 10.770, time/batch = 0.000\n",
      "2899/2800 (epoch 51), train_loss = 10.513, time/batch = 0.016\n",
      "2900/2800 (epoch 51), train_loss = 10.967, time/batch = 0.016\n",
      "2901/2800 (epoch 51), train_loss = 10.507, time/batch = 0.020\n",
      "2902/2800 (epoch 51), train_loss = 10.583, time/batch = 0.002\n",
      "2903/2800 (epoch 51), train_loss = 10.324, time/batch = 0.016\n",
      "2904/2800 (epoch 51), train_loss = 10.693, time/batch = 0.016\n",
      "2905/2800 (epoch 51), train_loss = 10.492, time/batch = 0.016\n",
      "2906/2800 (epoch 51), train_loss = 10.284, time/batch = 0.016\n",
      "2907/2800 (epoch 51), train_loss = 9.968, time/batch = 0.016\n",
      "2908/2800 (epoch 51), train_loss = 11.643, time/batch = 0.000\n",
      "2909/2800 (epoch 51), train_loss = 9.917, time/batch = 0.022\n",
      "2910/2800 (epoch 51), train_loss = 10.279, time/batch = 0.000\n",
      "2911/2800 (epoch 51), train_loss = 10.351, time/batch = 0.016\n",
      "2912/2800 (epoch 52), train_loss = 9.974, time/batch = 0.016\n",
      "2913/2800 (epoch 52), train_loss = 9.736, time/batch = 0.000\n",
      "2914/2800 (epoch 52), train_loss = 9.872, time/batch = 0.016\n",
      "2915/2800 (epoch 52), train_loss = 9.257, time/batch = 0.016\n",
      "2916/2800 (epoch 52), train_loss = 10.308, time/batch = 0.016\n",
      "2917/2800 (epoch 52), train_loss = 9.575, time/batch = 0.022\n",
      "2918/2800 (epoch 52), train_loss = 9.379, time/batch = 0.016\n",
      "2919/2800 (epoch 52), train_loss = 9.178, time/batch = 0.000\n",
      "2920/2800 (epoch 52), train_loss = 9.614, time/batch = 0.016\n",
      "2921/2800 (epoch 52), train_loss = 8.902, time/batch = 0.016\n",
      "2922/2800 (epoch 52), train_loss = 9.481, time/batch = 0.016\n",
      "2923/2800 (epoch 52), train_loss = 9.519, time/batch = 0.016\n",
      "2924/2800 (epoch 52), train_loss = 9.303, time/batch = 0.017\n",
      "2925/2800 (epoch 52), train_loss = 9.231, time/batch = 0.004\n",
      "2926/2800 (epoch 52), train_loss = 8.992, time/batch = 0.016\n",
      "2927/2800 (epoch 52), train_loss = 9.290, time/batch = 0.000\n",
      "2928/2800 (epoch 52), train_loss = 8.961, time/batch = 0.016\n",
      "2929/2800 (epoch 52), train_loss = 9.362, time/batch = 0.016\n",
      "2930/2800 (epoch 52), train_loss = 9.441, time/batch = 0.000\n",
      "2931/2800 (epoch 52), train_loss = 8.990, time/batch = 0.000\n",
      "2932/2800 (epoch 52), train_loss = 9.553, time/batch = 0.016\n",
      "2933/2800 (epoch 52), train_loss = 8.792, time/batch = 0.022\n",
      "2934/2800 (epoch 52), train_loss = 9.855, time/batch = 0.016\n",
      "2935/2800 (epoch 52), train_loss = 9.647, time/batch = 0.000\n",
      "2936/2800 (epoch 52), train_loss = 10.162, time/batch = 0.016\n",
      "2937/2800 (epoch 52), train_loss = 9.252, time/batch = 0.016\n",
      "2938/2800 (epoch 52), train_loss = 11.556, time/batch = 0.016\n",
      "2939/2800 (epoch 52), train_loss = 9.137, time/batch = 0.016\n",
      "2940/2800 (epoch 52), train_loss = 9.918, time/batch = 0.018\n",
      "2941/2800 (epoch 52), train_loss = 9.537, time/batch = 0.004\n",
      "2942/2800 (epoch 52), train_loss = 9.993, time/batch = 0.016\n",
      "2943/2800 (epoch 52), train_loss = 9.216, time/batch = 0.000\n",
      "2944/2800 (epoch 52), train_loss = 9.292, time/batch = 0.000\n",
      "2945/2800 (epoch 52), train_loss = 9.467, time/batch = 0.016\n",
      "2946/2800 (epoch 52), train_loss = 9.412, time/batch = 0.016\n",
      "2947/2800 (epoch 52), train_loss = 8.946, time/batch = 0.000\n",
      "2948/2800 (epoch 52), train_loss = 10.669, time/batch = 0.016\n",
      "2949/2800 (epoch 52), train_loss = 11.613, time/batch = 0.022\n",
      "2950/2800 (epoch 52), train_loss = 11.059, time/batch = 0.016\n",
      "2951/2800 (epoch 52), train_loss = 10.634, time/batch = 0.016\n",
      "2952/2800 (epoch 52), train_loss = 10.960, time/batch = 0.000\n",
      "2953/2800 (epoch 52), train_loss = 10.380, time/batch = 0.016\n",
      "2954/2800 (epoch 52), train_loss = 10.633, time/batch = 0.000\n",
      "2955/2800 (epoch 52), train_loss = 10.538, time/batch = 0.016\n",
      "2956/2800 (epoch 52), train_loss = 10.742, time/batch = 0.022\n",
      "2957/2800 (epoch 52), train_loss = 10.577, time/batch = 0.000\n",
      "2958/2800 (epoch 52), train_loss = 10.925, time/batch = 0.016\n",
      "2959/2800 (epoch 52), train_loss = 10.344, time/batch = 0.016\n",
      "2960/2800 (epoch 52), train_loss = 9.998, time/batch = 0.000\n",
      "2961/2800 (epoch 52), train_loss = 11.143, time/batch = 0.016\n",
      "2962/2800 (epoch 52), train_loss = 10.374, time/batch = 0.016\n",
      "2963/2800 (epoch 52), train_loss = 10.839, time/batch = 0.016\n",
      "2964/2800 (epoch 52), train_loss = 10.356, time/batch = 0.018\n",
      "2965/2800 (epoch 52), train_loss = 10.378, time/batch = 0.005\n",
      "2966/2800 (epoch 52), train_loss = 10.042, time/batch = 0.016\n",
      "2967/2800 (epoch 52), train_loss = 10.424, time/batch = 0.016\n",
      "2968/2800 (epoch 53), train_loss = 9.766, time/batch = 0.016\n",
      "2969/2800 (epoch 53), train_loss = 9.510, time/batch = 0.000\n",
      "2970/2800 (epoch 53), train_loss = 9.227, time/batch = 0.016\n",
      "2971/2800 (epoch 53), train_loss = 10.280, time/batch = 0.016\n",
      "2972/2800 (epoch 53), train_loss = 8.940, time/batch = 0.022\n",
      "2973/2800 (epoch 53), train_loss = 9.998, time/batch = 0.000\n",
      "2974/2800 (epoch 53), train_loss = 9.066, time/batch = 0.016\n",
      "2975/2800 (epoch 53), train_loss = 10.637, time/batch = 0.016\n",
      "2976/2800 (epoch 53), train_loss = 8.644, time/batch = 0.000\n",
      "2977/2800 (epoch 53), train_loss = 11.504, time/batch = 0.016\n",
      "2978/2800 (epoch 53), train_loss = 8.730, time/batch = 0.016\n",
      "2979/2800 (epoch 53), train_loss = 11.323, time/batch = 0.016\n",
      "2980/2800 (epoch 53), train_loss = 8.923, time/batch = 0.016\n",
      "2981/2800 (epoch 53), train_loss = 9.819, time/batch = 0.007\n",
      "2982/2800 (epoch 53), train_loss = 9.230, time/batch = 0.016\n",
      "2983/2800 (epoch 53), train_loss = 9.352, time/batch = 0.016\n",
      "2984/2800 (epoch 53), train_loss = 9.125, time/batch = 0.000\n",
      "2985/2800 (epoch 53), train_loss = 9.831, time/batch = 0.000\n",
      "2986/2800 (epoch 53), train_loss = 8.839, time/batch = 0.016\n",
      "2987/2800 (epoch 53), train_loss = 9.594, time/batch = 0.016\n",
      "2988/2800 (epoch 53), train_loss = 10.070, time/batch = 0.020\n",
      "2989/2800 (epoch 53), train_loss = 9.632, time/batch = 0.000\n",
      "2990/2800 (epoch 53), train_loss = 9.461, time/batch = 0.016\n",
      "2991/2800 (epoch 53), train_loss = 9.549, time/batch = 0.016\n",
      "2992/2800 (epoch 53), train_loss = 9.826, time/batch = 0.000\n",
      "2993/2800 (epoch 53), train_loss = 9.394, time/batch = 0.016\n",
      "2994/2800 (epoch 53), train_loss = 9.324, time/batch = 0.016\n",
      "2995/2800 (epoch 53), train_loss = 9.509, time/batch = 0.016\n",
      "2996/2800 (epoch 53), train_loss = 10.156, time/batch = 0.000\n",
      "2997/2800 (epoch 53), train_loss = 9.384, time/batch = 0.007\n",
      "2998/2800 (epoch 53), train_loss = 10.003, time/batch = 0.016\n",
      "2999/2800 (epoch 53), train_loss = 9.453, time/batch = 0.016\n",
      "3000/2800 (epoch 53), train_loss = 9.815, time/batch = 0.000\n",
      "model saved to save\\model.ckpt\n",
      "3001/2800 (epoch 53), train_loss = 11.614, time/batch = 0.031\n",
      "3002/2800 (epoch 53), train_loss = 10.936, time/batch = 0.037\n",
      "3003/2800 (epoch 53), train_loss = 10.665, time/batch = 0.016\n",
      "3004/2800 (epoch 53), train_loss = 10.898, time/batch = 0.031\n",
      "3005/2800 (epoch 53), train_loss = 10.446, time/batch = 0.031\n",
      "3006/2800 (epoch 53), train_loss = 10.690, time/batch = 0.037\n",
      "3007/2800 (epoch 53), train_loss = 10.399, time/batch = 0.031\n",
      "3008/2800 (epoch 53), train_loss = 10.598, time/batch = 0.031\n",
      "3009/2800 (epoch 53), train_loss = 10.302, time/batch = 0.038\n",
      "3010/2800 (epoch 53), train_loss = 10.374, time/batch = 0.031\n",
      "3011/2800 (epoch 53), train_loss = 10.958, time/batch = 0.049\n",
      "3012/2800 (epoch 53), train_loss = 10.661, time/batch = 0.020\n",
      "3013/2800 (epoch 53), train_loss = 10.295, time/batch = 0.047\n",
      "3014/2800 (epoch 53), train_loss = 10.889, time/batch = 0.038\n",
      "3015/2800 (epoch 53), train_loss = 10.555, time/batch = 0.031\n",
      "3016/2800 (epoch 53), train_loss = 10.087, time/batch = 0.031\n",
      "3017/2800 (epoch 53), train_loss = 10.491, time/batch = 0.038\n",
      "3018/2800 (epoch 53), train_loss = 10.006, time/batch = 0.047\n",
      "3019/2800 (epoch 53), train_loss = 10.255, time/batch = 0.053\n",
      "3020/2800 (epoch 53), train_loss = 10.394, time/batch = 0.031\n",
      "3021/2800 (epoch 53), train_loss = 9.644, time/batch = 0.047\n",
      "3022/2800 (epoch 53), train_loss = 9.975, time/batch = 0.040\n",
      "3023/2800 (epoch 53), train_loss = 9.406, time/batch = 0.036\n",
      "3024/2800 (epoch 54), train_loss = 9.555, time/batch = 0.035\n",
      "3025/2800 (epoch 54), train_loss = 8.892, time/batch = 0.038\n",
      "3026/2800 (epoch 54), train_loss = 10.554, time/batch = 0.053\n",
      "3027/2800 (epoch 54), train_loss = 9.210, time/batch = 0.061\n",
      "3028/2800 (epoch 54), train_loss = 9.229, time/batch = 0.039\n",
      "3029/2800 (epoch 54), train_loss = 9.753, time/batch = 0.037\n",
      "3030/2800 (epoch 54), train_loss = 9.256, time/batch = 0.034\n",
      "3031/2800 (epoch 54), train_loss = 9.481, time/batch = 0.036\n",
      "3032/2800 (epoch 54), train_loss = 9.491, time/batch = 0.034\n",
      "3033/2800 (epoch 54), train_loss = 9.831, time/batch = 0.032\n",
      "3034/2800 (epoch 54), train_loss = 9.232, time/batch = 0.028\n",
      "3035/2800 (epoch 54), train_loss = 8.914, time/batch = 0.031\n",
      "3036/2800 (epoch 54), train_loss = 8.629, time/batch = 0.031\n",
      "3037/2800 (epoch 54), train_loss = 9.214, time/batch = 0.038\n",
      "3038/2800 (epoch 54), train_loss = 15.028, time/batch = 0.031\n",
      "3039/2800 (epoch 54), train_loss = 8.952, time/batch = 0.031\n",
      "3040/2800 (epoch 54), train_loss = 9.366, time/batch = 0.022\n",
      "3041/2800 (epoch 54), train_loss = 8.732, time/batch = 0.031\n",
      "3042/2800 (epoch 54), train_loss = 10.085, time/batch = 0.031\n",
      "3043/2800 (epoch 54), train_loss = 8.884, time/batch = 0.038\n",
      "3044/2800 (epoch 54), train_loss = 9.486, time/batch = 0.031\n",
      "3045/2800 (epoch 54), train_loss = 8.992, time/batch = 0.031\n",
      "3046/2800 (epoch 54), train_loss = 9.612, time/batch = 0.037\n",
      "3047/2800 (epoch 54), train_loss = 9.302, time/batch = 0.032\n",
      "3048/2800 (epoch 54), train_loss = 10.200, time/batch = 0.031\n",
      "3049/2800 (epoch 54), train_loss = 9.252, time/batch = 0.038\n",
      "3050/2800 (epoch 54), train_loss = 9.568, time/batch = 0.031\n",
      "3051/2800 (epoch 54), train_loss = 9.800, time/batch = 0.031\n",
      "3052/2800 (epoch 54), train_loss = 9.656, time/batch = 0.016\n",
      "3053/2800 (epoch 54), train_loss = 9.790, time/batch = 0.022\n",
      "3054/2800 (epoch 54), train_loss = 9.540, time/batch = 0.031\n",
      "3055/2800 (epoch 54), train_loss = 9.508, time/batch = 0.016\n",
      "3056/2800 (epoch 54), train_loss = 9.404, time/batch = 0.031\n",
      "3057/2800 (epoch 54), train_loss = 10.163, time/batch = 0.022\n",
      "3058/2800 (epoch 54), train_loss = 9.202, time/batch = 0.047\n",
      "3059/2800 (epoch 54), train_loss = 10.781, time/batch = 0.031\n",
      "3060/2800 (epoch 54), train_loss = 9.096, time/batch = 0.027\n",
      "3061/2800 (epoch 54), train_loss = 9.608, time/batch = 0.023\n",
      "3062/2800 (epoch 54), train_loss = 8.888, time/batch = 0.025\n",
      "3063/2800 (epoch 54), train_loss = 11.006, time/batch = 0.024\n",
      "3064/2800 (epoch 54), train_loss = 11.458, time/batch = 0.024\n",
      "3065/2800 (epoch 54), train_loss = 11.300, time/batch = 0.018\n",
      "3066/2800 (epoch 54), train_loss = 10.811, time/batch = 0.016\n",
      "3067/2800 (epoch 54), train_loss = 10.750, time/batch = 0.031\n",
      "3068/2800 (epoch 54), train_loss = 10.466, time/batch = 0.016\n",
      "3069/2800 (epoch 54), train_loss = 10.652, time/batch = 0.037\n",
      "3070/2800 (epoch 54), train_loss = 10.523, time/batch = 0.016\n",
      "3071/2800 (epoch 54), train_loss = 10.760, time/batch = 0.016\n",
      "3072/2800 (epoch 54), train_loss = 10.427, time/batch = 0.031\n",
      "3073/2800 (epoch 54), train_loss = 10.805, time/batch = 0.016\n",
      "3074/2800 (epoch 54), train_loss = 10.350, time/batch = 0.022\n",
      "3075/2800 (epoch 54), train_loss = 10.467, time/batch = 0.016\n",
      "3076/2800 (epoch 54), train_loss = 10.572, time/batch = 0.016\n",
      "3077/2800 (epoch 54), train_loss = 10.590, time/batch = 0.031\n",
      "3078/2800 (epoch 54), train_loss = 10.276, time/batch = 0.022\n",
      "3079/2800 (epoch 54), train_loss = 9.843, time/batch = 0.016\n",
      "3080/2800 (epoch 55), train_loss = 10.597, time/batch = 0.031\n",
      "3081/2800 (epoch 55), train_loss = 9.188, time/batch = 0.016\n",
      "3082/2800 (epoch 55), train_loss = 10.012, time/batch = 0.016\n",
      "3083/2800 (epoch 55), train_loss = 8.923, time/batch = 0.022\n",
      "3084/2800 (epoch 55), train_loss = 11.694, time/batch = 0.032\n",
      "3085/2800 (epoch 55), train_loss = 8.775, time/batch = 0.016\n",
      "3086/2800 (epoch 55), train_loss = 11.322, time/batch = 0.016\n",
      "3087/2800 (epoch 55), train_loss = 8.778, time/batch = 0.016\n",
      "3088/2800 (epoch 55), train_loss = 10.682, time/batch = 0.022\n",
      "3089/2800 (epoch 55), train_loss = 8.552, time/batch = 0.031\n",
      "3090/2800 (epoch 55), train_loss = 10.868, time/batch = 0.016\n",
      "3091/2800 (epoch 55), train_loss = 8.855, time/batch = 0.016\n",
      "3092/2800 (epoch 55), train_loss = 10.412, time/batch = 0.033\n",
      "3093/2800 (epoch 55), train_loss = 8.574, time/batch = 0.005\n",
      "3094/2800 (epoch 55), train_loss = 10.904, time/batch = 0.031\n",
      "3095/2800 (epoch 55), train_loss = 8.615, time/batch = 0.016\n",
      "3096/2800 (epoch 55), train_loss = 10.433, time/batch = 0.016\n",
      "3097/2800 (epoch 55), train_loss = 9.109, time/batch = 0.036\n",
      "3098/2800 (epoch 55), train_loss = 10.896, time/batch = 0.017\n",
      "3099/2800 (epoch 55), train_loss = 8.805, time/batch = 0.016\n",
      "3100/2800 (epoch 55), train_loss = 10.474, time/batch = 0.031\n",
      "3101/2800 (epoch 55), train_loss = 9.239, time/batch = 0.016\n",
      "3102/2800 (epoch 55), train_loss = 10.250, time/batch = 0.023\n",
      "3103/2800 (epoch 55), train_loss = 9.333, time/batch = 0.016\n",
      "3104/2800 (epoch 55), train_loss = 9.433, time/batch = 0.016\n",
      "3105/2800 (epoch 55), train_loss = 9.476, time/batch = 0.031\n",
      "3106/2800 (epoch 55), train_loss = 10.041, time/batch = 0.016\n",
      "3107/2800 (epoch 55), train_loss = 9.272, time/batch = 0.022\n",
      "3108/2800 (epoch 55), train_loss = 9.654, time/batch = 0.016\n",
      "3109/2800 (epoch 55), train_loss = 9.464, time/batch = 0.016\n",
      "3110/2800 (epoch 55), train_loss = 9.815, time/batch = 0.016\n",
      "3111/2800 (epoch 55), train_loss = 9.348, time/batch = 0.031\n",
      "3112/2800 (epoch 55), train_loss = 9.621, time/batch = 0.021\n",
      "3113/2800 (epoch 55), train_loss = 8.748, time/batch = 0.016\n",
      "3114/2800 (epoch 55), train_loss = 9.059, time/batch = 0.016\n",
      "3115/2800 (epoch 55), train_loss = 9.679, time/batch = 0.016\n",
      "3116/2800 (epoch 55), train_loss = 12.043, time/batch = 0.016\n",
      "3117/2800 (epoch 55), train_loss = 10.755, time/batch = 0.032\n",
      "3118/2800 (epoch 55), train_loss = 10.866, time/batch = 0.022\n",
      "3119/2800 (epoch 55), train_loss = 10.794, time/batch = 0.031\n",
      "3120/2800 (epoch 55), train_loss = 10.672, time/batch = 0.016\n",
      "3121/2800 (epoch 55), train_loss = 10.570, time/batch = 0.016\n",
      "3122/2800 (epoch 55), train_loss = 10.643, time/batch = 0.022\n",
      "3123/2800 (epoch 55), train_loss = 10.583, time/batch = 0.016\n",
      "3124/2800 (epoch 55), train_loss = 10.286, time/batch = 0.016\n",
      "3125/2800 (epoch 55), train_loss = 10.684, time/batch = 0.031\n",
      "3126/2800 (epoch 55), train_loss = 10.644, time/batch = 0.016\n",
      "3127/2800 (epoch 55), train_loss = 10.320, time/batch = 0.022\n",
      "3128/2800 (epoch 55), train_loss = 10.779, time/batch = 0.016\n",
      "3129/2800 (epoch 55), train_loss = 10.769, time/batch = 0.016\n",
      "3130/2800 (epoch 55), train_loss = 10.845, time/batch = 0.016\n",
      "3131/2800 (epoch 55), train_loss = 10.245, time/batch = 0.031\n",
      "3132/2800 (epoch 55), train_loss = 10.927, time/batch = 0.020\n",
      "3133/2800 (epoch 55), train_loss = 9.951, time/batch = 0.002\n",
      "3134/2800 (epoch 55), train_loss = 10.706, time/batch = 0.016\n",
      "3135/2800 (epoch 55), train_loss = 10.238, time/batch = 0.016\n",
      "3136/2800 (epoch 56), train_loss = 9.803, time/batch = 0.016\n",
      "3137/2800 (epoch 56), train_loss = 9.964, time/batch = 0.016\n",
      "3138/2800 (epoch 56), train_loss = 9.579, time/batch = 0.016\n",
      "3139/2800 (epoch 56), train_loss = 9.667, time/batch = 0.018\n",
      "3140/2800 (epoch 56), train_loss = 9.761, time/batch = 0.004\n",
      "3141/2800 (epoch 56), train_loss = 9.321, time/batch = 0.016\n",
      "3142/2800 (epoch 56), train_loss = 9.665, time/batch = 0.016\n",
      "3143/2800 (epoch 56), train_loss = 9.426, time/batch = 0.016\n",
      "3144/2800 (epoch 56), train_loss = 9.741, time/batch = 0.000\n",
      "3145/2800 (epoch 56), train_loss = 9.397, time/batch = 0.016\n",
      "3146/2800 (epoch 56), train_loss = 9.780, time/batch = 0.016\n",
      "3147/2800 (epoch 56), train_loss = 9.003, time/batch = 0.022\n",
      "3148/2800 (epoch 56), train_loss = 8.865, time/batch = 0.000\n",
      "3149/2800 (epoch 56), train_loss = 9.205, time/batch = 0.016\n",
      "3150/2800 (epoch 56), train_loss = 9.686, time/batch = 0.016\n",
      "3151/2800 (epoch 56), train_loss = 9.419, time/batch = 0.016\n",
      "3152/2800 (epoch 56), train_loss = 9.374, time/batch = 0.016\n",
      "3153/2800 (epoch 56), train_loss = 9.148, time/batch = 0.000\n",
      "3154/2800 (epoch 56), train_loss = 9.207, time/batch = 0.016\n",
      "3155/2800 (epoch 56), train_loss = 9.106, time/batch = 0.022\n",
      "3156/2800 (epoch 56), train_loss = 9.432, time/batch = 0.016\n",
      "3157/2800 (epoch 56), train_loss = 9.803, time/batch = 0.016\n",
      "3158/2800 (epoch 56), train_loss = 10.216, time/batch = 0.016\n",
      "3159/2800 (epoch 56), train_loss = 9.546, time/batch = 0.000\n",
      "3160/2800 (epoch 56), train_loss = 10.289, time/batch = 0.016\n",
      "3161/2800 (epoch 56), train_loss = 9.237, time/batch = 0.016\n",
      "3162/2800 (epoch 56), train_loss = 9.997, time/batch = 0.020\n",
      "3163/2800 (epoch 56), train_loss = 9.385, time/batch = 0.002\n",
      "3164/2800 (epoch 56), train_loss = 10.091, time/batch = 0.016\n",
      "3165/2800 (epoch 56), train_loss = 9.600, time/batch = 0.016\n",
      "3166/2800 (epoch 56), train_loss = 9.704, time/batch = 0.016\n",
      "3167/2800 (epoch 56), train_loss = 9.476, time/batch = 0.016\n",
      "3168/2800 (epoch 56), train_loss = 9.424, time/batch = 0.000\n",
      "3169/2800 (epoch 56), train_loss = 9.830, time/batch = 0.016\n",
      "3170/2800 (epoch 56), train_loss = 10.616, time/batch = 0.022\n",
      "3171/2800 (epoch 56), train_loss = 11.123, time/batch = 0.000\n",
      "3172/2800 (epoch 56), train_loss = 10.866, time/batch = 0.016\n",
      "3173/2800 (epoch 56), train_loss = 10.698, time/batch = 0.016\n",
      "3174/2800 (epoch 56), train_loss = 10.611, time/batch = 0.016\n",
      "3175/2800 (epoch 56), train_loss = 10.401, time/batch = 0.016\n",
      "3176/2800 (epoch 56), train_loss = 10.678, time/batch = 0.016\n",
      "3177/2800 (epoch 56), train_loss = 10.347, time/batch = 0.016\n",
      "3178/2800 (epoch 56), train_loss = 10.809, time/batch = 0.006\n",
      "3179/2800 (epoch 56), train_loss = 10.332, time/batch = 0.016\n",
      "3180/2800 (epoch 56), train_loss = 10.861, time/batch = 0.016\n",
      "3181/2800 (epoch 56), train_loss = 10.285, time/batch = 0.016\n",
      "3182/2800 (epoch 56), train_loss = 10.386, time/batch = 0.000\n",
      "3183/2800 (epoch 56), train_loss = 11.084, time/batch = 0.016\n",
      "3184/2800 (epoch 56), train_loss = 10.555, time/batch = 0.016\n",
      "3185/2800 (epoch 56), train_loss = 10.170, time/batch = 0.022\n",
      "3186/2800 (epoch 56), train_loss = 10.255, time/batch = 0.000\n",
      "3187/2800 (epoch 56), train_loss = 9.985, time/batch = 0.016\n",
      "3188/2800 (epoch 56), train_loss = 10.093, time/batch = 0.016\n",
      "3189/2800 (epoch 56), train_loss = 10.008, time/batch = 0.016\n",
      "3190/2800 (epoch 56), train_loss = 10.673, time/batch = 0.016\n",
      "3191/2800 (epoch 56), train_loss = 9.403, time/batch = 0.000\n",
      "3192/2800 (epoch 57), train_loss = 10.216, time/batch = 0.016\n",
      "3193/2800 (epoch 57), train_loss = 9.213, time/batch = 0.022\n",
      "3194/2800 (epoch 57), train_loss = 9.201, time/batch = 0.016\n",
      "3195/2800 (epoch 57), train_loss = 9.476, time/batch = 0.000\n",
      "3196/2800 (epoch 57), train_loss = 9.950, time/batch = 0.016\n",
      "3197/2800 (epoch 57), train_loss = 9.291, time/batch = 0.016\n",
      "3198/2800 (epoch 57), train_loss = 9.027, time/batch = 0.016\n",
      "3199/2800 (epoch 57), train_loss = 8.895, time/batch = 0.016\n",
      "3200/2800 (epoch 57), train_loss = 12.396, time/batch = 0.019\n",
      "3201/2800 (epoch 57), train_loss = 8.867, time/batch = 0.003\n",
      "3202/2800 (epoch 57), train_loss = 9.405, time/batch = 0.016\n",
      "3203/2800 (epoch 57), train_loss = 10.724, time/batch = 0.016\n",
      "3204/2800 (epoch 57), train_loss = 9.883, time/batch = 0.016\n",
      "3205/2800 (epoch 57), train_loss = 10.468, time/batch = 0.000\n",
      "3206/2800 (epoch 57), train_loss = 9.051, time/batch = 0.016\n",
      "3207/2800 (epoch 57), train_loss = 10.072, time/batch = 0.016\n",
      "3208/2800 (epoch 57), train_loss = 9.091, time/batch = 0.022\n",
      "3209/2800 (epoch 57), train_loss = 9.527, time/batch = 0.000\n",
      "3210/2800 (epoch 57), train_loss = 9.053, time/batch = 0.000\n",
      "3211/2800 (epoch 57), train_loss = 9.454, time/batch = 0.016\n",
      "3212/2800 (epoch 57), train_loss = 9.044, time/batch = 0.016\n",
      "3213/2800 (epoch 57), train_loss = 9.149, time/batch = 0.016\n",
      "3214/2800 (epoch 57), train_loss = 8.739, time/batch = 0.000\n",
      "3215/2800 (epoch 57), train_loss = 9.771, time/batch = 0.016\n",
      "3216/2800 (epoch 57), train_loss = 9.449, time/batch = 0.022\n",
      "3217/2800 (epoch 57), train_loss = 9.748, time/batch = 0.016\n",
      "3218/2800 (epoch 57), train_loss = 9.698, time/batch = 0.000\n",
      "3219/2800 (epoch 57), train_loss = 9.447, time/batch = 0.016\n",
      "3220/2800 (epoch 57), train_loss = 10.072, time/batch = 0.016\n",
      "3221/2800 (epoch 57), train_loss = 9.240, time/batch = 0.016\n",
      "3222/2800 (epoch 57), train_loss = 10.379, time/batch = 0.016\n",
      "3223/2800 (epoch 57), train_loss = 9.435, time/batch = 0.018\n",
      "3224/2800 (epoch 57), train_loss = 9.889, time/batch = 0.004\n",
      "3225/2800 (epoch 57), train_loss = 9.290, time/batch = 0.016\n",
      "3226/2800 (epoch 57), train_loss = 9.737, time/batch = 0.016\n",
      "3227/2800 (epoch 57), train_loss = 9.573, time/batch = 0.016\n",
      "3228/2800 (epoch 57), train_loss = 12.056, time/batch = 0.016\n",
      "3229/2800 (epoch 57), train_loss = 10.901, time/batch = 0.000\n",
      "3230/2800 (epoch 57), train_loss = 10.810, time/batch = 0.016\n",
      "3231/2800 (epoch 57), train_loss = 10.788, time/batch = 0.022\n",
      "3232/2800 (epoch 57), train_loss = 10.503, time/batch = 0.000\n",
      "3233/2800 (epoch 57), train_loss = 10.514, time/batch = 0.016\n",
      "3234/2800 (epoch 57), train_loss = 10.547, time/batch = 0.016\n",
      "3235/2800 (epoch 57), train_loss = 10.513, time/batch = 0.016\n",
      "3236/2800 (epoch 57), train_loss = 10.527, time/batch = 0.016\n",
      "3237/2800 (epoch 57), train_loss = 10.575, time/batch = 0.016\n",
      "3238/2800 (epoch 57), train_loss = 10.190, time/batch = 0.021\n",
      "3239/2800 (epoch 57), train_loss = 10.855, time/batch = 0.001\n",
      "3240/2800 (epoch 57), train_loss = 10.468, time/batch = 0.016\n",
      "3241/2800 (epoch 57), train_loss = 10.047, time/batch = 0.016\n",
      "3242/2800 (epoch 57), train_loss = 12.288, time/batch = 0.000\n",
      "3243/2800 (epoch 57), train_loss = 11.063, time/batch = 0.016\n",
      "3244/2800 (epoch 57), train_loss = 9.990, time/batch = 0.016\n",
      "3245/2800 (epoch 57), train_loss = 10.438, time/batch = 0.016\n",
      "3246/2800 (epoch 57), train_loss = 9.830, time/batch = 0.021\n",
      "3247/2800 (epoch 57), train_loss = 10.720, time/batch = 0.000\n",
      "3248/2800 (epoch 58), train_loss = 9.552, time/batch = 0.016\n",
      "3249/2800 (epoch 58), train_loss = 9.268, time/batch = 0.016\n",
      "3250/2800 (epoch 58), train_loss = 9.295, time/batch = 0.016\n",
      "3251/2800 (epoch 58), train_loss = 9.774, time/batch = 0.000\n",
      "3252/2800 (epoch 58), train_loss = 8.875, time/batch = 0.016\n",
      "3253/2800 (epoch 58), train_loss = 10.576, time/batch = 0.016\n",
      "3254/2800 (epoch 58), train_loss = 9.067, time/batch = 0.022\n",
      "3255/2800 (epoch 58), train_loss = 11.529, time/batch = 0.000\n",
      "3256/2800 (epoch 58), train_loss = 8.742, time/batch = 0.016\n",
      "3257/2800 (epoch 58), train_loss = 10.513, time/batch = 0.016\n",
      "3258/2800 (epoch 58), train_loss = 9.020, time/batch = 0.016\n",
      "3259/2800 (epoch 58), train_loss = 9.786, time/batch = 0.016\n",
      "3260/2800 (epoch 58), train_loss = 9.126, time/batch = 0.000\n",
      "3261/2800 (epoch 58), train_loss = 9.268, time/batch = 0.016\n",
      "3262/2800 (epoch 58), train_loss = 9.074, time/batch = 0.020\n",
      "3263/2800 (epoch 58), train_loss = 9.358, time/batch = 0.002\n",
      "3264/2800 (epoch 58), train_loss = 8.961, time/batch = 0.016\n",
      "3265/2800 (epoch 58), train_loss = 9.207, time/batch = 0.016\n",
      "3266/2800 (epoch 58), train_loss = 8.945, time/batch = 0.016\n",
      "3267/2800 (epoch 58), train_loss = 9.520, time/batch = 0.000\n",
      "3268/2800 (epoch 58), train_loss = 9.053, time/batch = 0.016\n",
      "3269/2800 (epoch 58), train_loss = 9.117, time/batch = 0.016\n",
      "3270/2800 (epoch 58), train_loss = 10.216, time/batch = 0.022\n",
      "3271/2800 (epoch 58), train_loss = 9.530, time/batch = 0.000\n",
      "3272/2800 (epoch 58), train_loss = 9.723, time/batch = 0.016\n",
      "3273/2800 (epoch 58), train_loss = 9.824, time/batch = 0.016\n",
      "3274/2800 (epoch 58), train_loss = 9.202, time/batch = 0.016\n",
      "3275/2800 (epoch 58), train_loss = 9.574, time/batch = 0.016\n",
      "3276/2800 (epoch 58), train_loss = 9.198, time/batch = 0.000\n",
      "3277/2800 (epoch 58), train_loss = 10.439, time/batch = 0.016\n",
      "3278/2800 (epoch 58), train_loss = 9.526, time/batch = 0.020\n",
      "3279/2800 (epoch 58), train_loss = 9.559, time/batch = 0.002\n",
      "3280/2800 (epoch 58), train_loss = 9.279, time/batch = 0.016\n",
      "3281/2800 (epoch 58), train_loss = 10.033, time/batch = 0.016\n",
      "3282/2800 (epoch 58), train_loss = 9.212, time/batch = 0.016\n",
      "3283/2800 (epoch 58), train_loss = 10.377, time/batch = 0.000\n",
      "3284/2800 (epoch 58), train_loss = 11.797, time/batch = 0.016\n",
      "3285/2800 (epoch 58), train_loss = 10.925, time/batch = 0.016\n",
      "3286/2800 (epoch 58), train_loss = 11.162, time/batch = 0.022\n",
      "3287/2800 (epoch 58), train_loss = 10.589, time/batch = 0.000\n",
      "3288/2800 (epoch 58), train_loss = 10.500, time/batch = 0.016\n",
      "3289/2800 (epoch 58), train_loss = 10.328, time/batch = 0.016\n",
      "3290/2800 (epoch 58), train_loss = 10.530, time/batch = 0.016\n",
      "3291/2800 (epoch 58), train_loss = 10.503, time/batch = 0.016\n",
      "3292/2800 (epoch 58), train_loss = 10.893, time/batch = 0.000\n",
      "3293/2800 (epoch 58), train_loss = 10.329, time/batch = 0.016\n",
      "3294/2800 (epoch 58), train_loss = 10.282, time/batch = 0.020\n",
      "3295/2800 (epoch 58), train_loss = 10.410, time/batch = 0.002\n",
      "3296/2800 (epoch 58), train_loss = 11.224, time/batch = 0.016\n",
      "3297/2800 (epoch 58), train_loss = 10.271, time/batch = 0.016\n",
      "3298/2800 (epoch 58), train_loss = 10.722, time/batch = 0.016\n",
      "3299/2800 (epoch 58), train_loss = 10.343, time/batch = 0.000\n",
      "3300/2800 (epoch 58), train_loss = 10.574, time/batch = 0.016\n",
      "3301/2800 (epoch 58), train_loss = 9.979, time/batch = 0.016\n",
      "3302/2800 (epoch 58), train_loss = 10.094, time/batch = 0.022\n",
      "3303/2800 (epoch 58), train_loss = 10.578, time/batch = 0.000\n",
      "3304/2800 (epoch 59), train_loss = 9.739, time/batch = 0.016\n",
      "3305/2800 (epoch 59), train_loss = 9.436, time/batch = 0.016\n",
      "3306/2800 (epoch 59), train_loss = 9.877, time/batch = 0.016\n",
      "3307/2800 (epoch 59), train_loss = 9.901, time/batch = 0.016\n",
      "3308/2800 (epoch 59), train_loss = 10.046, time/batch = 0.000\n",
      "3309/2800 (epoch 59), train_loss = 9.075, time/batch = 0.016\n",
      "3310/2800 (epoch 59), train_loss = 9.433, time/batch = 0.020\n",
      "3311/2800 (epoch 59), train_loss = 9.174, time/batch = 0.002\n",
      "3312/2800 (epoch 59), train_loss = 9.921, time/batch = 0.016\n",
      "3313/2800 (epoch 59), train_loss = 8.990, time/batch = 0.016\n",
      "3314/2800 (epoch 59), train_loss = 10.688, time/batch = 0.016\n",
      "3315/2800 (epoch 59), train_loss = 8.992, time/batch = 0.000\n",
      "3316/2800 (epoch 59), train_loss = 8.690, time/batch = 0.016\n",
      "3317/2800 (epoch 59), train_loss = 9.017, time/batch = 0.016\n",
      "3318/2800 (epoch 59), train_loss = 10.183, time/batch = 0.022\n",
      "3319/2800 (epoch 59), train_loss = 9.033, time/batch = 0.000\n",
      "3320/2800 (epoch 59), train_loss = 9.383, time/batch = 0.016\n",
      "3321/2800 (epoch 59), train_loss = 9.139, time/batch = 0.016\n",
      "3322/2800 (epoch 59), train_loss = 9.246, time/batch = 0.016\n",
      "3323/2800 (epoch 59), train_loss = 8.944, time/batch = 0.016\n",
      "3324/2800 (epoch 59), train_loss = 9.762, time/batch = 0.000\n",
      "3325/2800 (epoch 59), train_loss = 8.488, time/batch = 0.000\n",
      "3326/2800 (epoch 59), train_loss = 9.901, time/batch = 0.021\n",
      "3327/2800 (epoch 59), train_loss = 9.600, time/batch = 0.001\n",
      "3328/2800 (epoch 59), train_loss = 9.411, time/batch = 0.016\n",
      "3329/2800 (epoch 59), train_loss = 10.210, time/batch = 0.016\n",
      "3330/2800 (epoch 59), train_loss = 9.317, time/batch = 0.016\n",
      "3331/2800 (epoch 59), train_loss = 9.841, time/batch = 0.000\n",
      "3332/2800 (epoch 59), train_loss = 9.369, time/batch = 0.016\n",
      "3333/2800 (epoch 59), train_loss = 10.218, time/batch = 0.016\n",
      "3334/2800 (epoch 59), train_loss = 9.483, time/batch = 0.022\n",
      "3335/2800 (epoch 59), train_loss = 9.429, time/batch = 0.000\n",
      "3336/2800 (epoch 59), train_loss = 9.298, time/batch = 0.016\n",
      "3337/2800 (epoch 59), train_loss = 10.346, time/batch = 0.016\n",
      "3338/2800 (epoch 59), train_loss = 9.008, time/batch = 0.016\n",
      "3339/2800 (epoch 59), train_loss = 10.596, time/batch = 0.016\n",
      "3340/2800 (epoch 59), train_loss = 10.838, time/batch = 0.000\n",
      "3341/2800 (epoch 59), train_loss = 10.576, time/batch = 0.016\n",
      "3342/2800 (epoch 59), train_loss = 10.694, time/batch = 0.019\n",
      "3343/2800 (epoch 59), train_loss = 10.590, time/batch = 0.003\n",
      "3344/2800 (epoch 59), train_loss = 10.548, time/batch = 0.016\n",
      "3345/2800 (epoch 59), train_loss = 10.360, time/batch = 0.016\n",
      "3346/2800 (epoch 59), train_loss = 10.427, time/batch = 0.016\n",
      "3347/2800 (epoch 59), train_loss = 10.391, time/batch = 0.016\n",
      "3348/2800 (epoch 59), train_loss = 10.567, time/batch = 0.016\n",
      "3349/2800 (epoch 59), train_loss = 10.294, time/batch = 0.000\n",
      "3350/2800 (epoch 59), train_loss = 10.396, time/batch = 0.022\n",
      "3351/2800 (epoch 59), train_loss = 10.471, time/batch = 0.016\n",
      "3352/2800 (epoch 59), train_loss = 11.163, time/batch = 0.016\n",
      "3353/2800 (epoch 59), train_loss = 10.158, time/batch = 0.000\n",
      "3354/2800 (epoch 59), train_loss = 10.996, time/batch = 0.016\n",
      "3355/2800 (epoch 59), train_loss = 10.172, time/batch = 0.016\n",
      "3356/2800 (epoch 59), train_loss = 10.390, time/batch = 0.016\n",
      "3357/2800 (epoch 59), train_loss = 10.627, time/batch = 0.000\n",
      "3358/2800 (epoch 59), train_loss = 9.993, time/batch = 0.022\n",
      "3359/2800 (epoch 59), train_loss = 10.207, time/batch = 0.000\n",
      "3360/2800 (epoch 60), train_loss = 9.568, time/batch = 0.016\n",
      "3361/2800 (epoch 60), train_loss = 9.502, time/batch = 0.016\n",
      "3362/2800 (epoch 60), train_loss = 9.971, time/batch = 0.016\n",
      "3363/2800 (epoch 60), train_loss = 8.942, time/batch = 0.016\n",
      "3364/2800 (epoch 60), train_loss = 9.987, time/batch = 0.000\n",
      "3365/2800 (epoch 60), train_loss = 8.819, time/batch = 0.016\n",
      "3366/2800 (epoch 60), train_loss = 10.064, time/batch = 0.022\n",
      "3367/2800 (epoch 60), train_loss = 9.098, time/batch = 0.016\n",
      "3368/2800 (epoch 60), train_loss = 9.717, time/batch = 0.000\n",
      "3369/2800 (epoch 60), train_loss = 8.841, time/batch = 0.016\n",
      "3370/2800 (epoch 60), train_loss = 10.819, time/batch = 0.016\n",
      "3371/2800 (epoch 60), train_loss = 9.028, time/batch = 0.016\n",
      "3372/2800 (epoch 60), train_loss = 9.284, time/batch = 0.016\n",
      "3373/2800 (epoch 60), train_loss = 8.886, time/batch = 0.016\n",
      "3374/2800 (epoch 60), train_loss = 10.000, time/batch = 0.005\n",
      "3375/2800 (epoch 60), train_loss = 8.951, time/batch = 0.016\n",
      "3376/2800 (epoch 60), train_loss = 10.184, time/batch = 0.000\n",
      "3377/2800 (epoch 60), train_loss = 8.911, time/batch = 0.016\n",
      "3378/2800 (epoch 60), train_loss = 9.149, time/batch = 0.016\n",
      "3379/2800 (epoch 60), train_loss = 8.982, time/batch = 0.016\n",
      "3380/2800 (epoch 60), train_loss = 9.299, time/batch = 0.016\n",
      "3381/2800 (epoch 60), train_loss = 9.516, time/batch = 0.017\n",
      "3382/2800 (epoch 60), train_loss = 9.614, time/batch = 0.005\n",
      "3383/2800 (epoch 60), train_loss = 9.783, time/batch = 0.016\n",
      "3384/2800 (epoch 60), train_loss = 9.464, time/batch = 0.016\n",
      "3385/2800 (epoch 60), train_loss = 10.246, time/batch = 0.016\n",
      "3386/2800 (epoch 60), train_loss = 9.440, time/batch = 0.000\n",
      "3387/2800 (epoch 60), train_loss = 9.465, time/batch = 0.016\n",
      "3388/2800 (epoch 60), train_loss = 9.395, time/batch = 0.016\n",
      "3389/2800 (epoch 60), train_loss = 9.935, time/batch = 0.019\n",
      "3390/2800 (epoch 60), train_loss = 9.061, time/batch = 0.003\n",
      "3391/2800 (epoch 60), train_loss = 9.964, time/batch = 0.016\n",
      "3392/2800 (epoch 60), train_loss = 9.123, time/batch = 0.016\n",
      "3393/2800 (epoch 60), train_loss = 9.566, time/batch = 0.000\n",
      "3394/2800 (epoch 60), train_loss = 11.697, time/batch = 0.016\n",
      "3395/2800 (epoch 60), train_loss = 10.984, time/batch = 0.016\n",
      "3396/2800 (epoch 60), train_loss = 10.654, time/batch = 0.016\n",
      "3397/2800 (epoch 60), train_loss = 10.981, time/batch = 0.019\n",
      "3398/2800 (epoch 60), train_loss = 10.518, time/batch = 0.003\n",
      "3399/2800 (epoch 60), train_loss = 10.525, time/batch = 0.016\n",
      "3400/2800 (epoch 60), train_loss = 10.329, time/batch = 0.016\n",
      "3401/2800 (epoch 60), train_loss = 10.625, time/batch = 0.016\n",
      "3402/2800 (epoch 60), train_loss = 10.287, time/batch = 0.016\n",
      "3403/2800 (epoch 60), train_loss = 10.969, time/batch = 0.000\n",
      "3404/2800 (epoch 60), train_loss = 10.211, time/batch = 0.016\n",
      "3405/2800 (epoch 60), train_loss = 11.196, time/batch = 0.020\n",
      "3406/2800 (epoch 60), train_loss = 10.485, time/batch = 0.002\n",
      "3407/2800 (epoch 60), train_loss = 10.261, time/batch = 0.016\n",
      "3408/2800 (epoch 60), train_loss = 10.613, time/batch = 0.000\n",
      "3409/2800 (epoch 60), train_loss = 11.049, time/batch = 0.016\n",
      "3410/2800 (epoch 60), train_loss = 10.086, time/batch = 0.016\n",
      "3411/2800 (epoch 60), train_loss = 10.742, time/batch = 0.016\n",
      "3412/2800 (epoch 60), train_loss = 9.921, time/batch = 0.016\n",
      "3413/2800 (epoch 60), train_loss = 10.265, time/batch = 0.018\n",
      "3414/2800 (epoch 60), train_loss = 10.158, time/batch = 0.004\n",
      "3415/2800 (epoch 60), train_loss = 9.710, time/batch = 0.016\n",
      "3416/2800 (epoch 61), train_loss = 9.452, time/batch = 0.016\n",
      "3417/2800 (epoch 61), train_loss = 9.350, time/batch = 0.016\n",
      "3418/2800 (epoch 61), train_loss = 9.261, time/batch = 0.016\n",
      "3419/2800 (epoch 61), train_loss = 9.037, time/batch = 0.000\n",
      "3420/2800 (epoch 61), train_loss = 9.734, time/batch = 0.016\n",
      "3421/2800 (epoch 61), train_loss = 9.301, time/batch = 0.022\n",
      "3422/2800 (epoch 61), train_loss = 9.356, time/batch = 0.000\n",
      "3423/2800 (epoch 61), train_loss = 9.835, time/batch = 0.016\n",
      "3424/2800 (epoch 61), train_loss = 10.319, time/batch = 0.016\n",
      "3425/2800 (epoch 61), train_loss = 8.885, time/batch = 0.000\n",
      "3426/2800 (epoch 61), train_loss = 9.326, time/batch = 0.016\n",
      "3427/2800 (epoch 61), train_loss = 8.702, time/batch = 0.016\n",
      "3428/2800 (epoch 61), train_loss = 10.301, time/batch = 0.016\n",
      "3429/2800 (epoch 61), train_loss = 8.844, time/batch = 0.021\n",
      "3430/2800 (epoch 61), train_loss = 9.134, time/batch = 0.000\n",
      "3431/2800 (epoch 61), train_loss = 9.091, time/batch = 0.016\n",
      "3432/2800 (epoch 61), train_loss = 9.762, time/batch = 0.016\n",
      "3433/2800 (epoch 61), train_loss = 8.915, time/batch = 0.016\n",
      "3434/2800 (epoch 61), train_loss = 10.340, time/batch = 0.016\n",
      "3435/2800 (epoch 61), train_loss = 9.026, time/batch = 0.016\n",
      "3436/2800 (epoch 61), train_loss = 8.960, time/batch = 0.000\n",
      "3437/2800 (epoch 61), train_loss = 9.344, time/batch = 0.022\n",
      "3438/2800 (epoch 61), train_loss = 10.024, time/batch = 0.000\n",
      "3439/2800 (epoch 61), train_loss = 9.424, time/batch = 0.016\n",
      "3440/2800 (epoch 61), train_loss = 9.554, time/batch = 0.016\n",
      "3441/2800 (epoch 61), train_loss = 9.369, time/batch = 0.000\n",
      "3442/2800 (epoch 61), train_loss = 9.797, time/batch = 0.016\n",
      "3443/2800 (epoch 61), train_loss = 9.619, time/batch = 0.016\n",
      "3444/2800 (epoch 61), train_loss = 9.857, time/batch = 0.016\n",
      "3445/2800 (epoch 61), train_loss = 9.612, time/batch = 0.021\n",
      "3446/2800 (epoch 61), train_loss = 10.017, time/batch = 0.001\n",
      "3447/2800 (epoch 61), train_loss = 9.624, time/batch = 0.016\n",
      "3448/2800 (epoch 61), train_loss = 9.689, time/batch = 0.016\n",
      "3449/2800 (epoch 61), train_loss = 9.596, time/batch = 0.016\n",
      "3450/2800 (epoch 61), train_loss = 9.319, time/batch = 0.016\n",
      "3451/2800 (epoch 61), train_loss = 9.632, time/batch = 0.016\n",
      "3452/2800 (epoch 61), train_loss = 10.309, time/batch = 0.000\n",
      "3453/2800 (epoch 61), train_loss = 11.616, time/batch = 0.022\n",
      "3454/2800 (epoch 61), train_loss = 10.750, time/batch = 0.000\n",
      "3455/2800 (epoch 61), train_loss = 10.782, time/batch = 0.016\n",
      "3456/2800 (epoch 61), train_loss = 10.683, time/batch = 0.016\n",
      "3457/2800 (epoch 61), train_loss = 10.398, time/batch = 0.016\n",
      "3458/2800 (epoch 61), train_loss = 10.618, time/batch = 0.016\n",
      "3459/2800 (epoch 61), train_loss = 10.413, time/batch = 0.016\n",
      "3460/2800 (epoch 61), train_loss = 10.860, time/batch = 0.017\n",
      "3461/2800 (epoch 61), train_loss = 10.449, time/batch = 0.005\n",
      "3462/2800 (epoch 61), train_loss = 10.190, time/batch = 0.016\n",
      "3463/2800 (epoch 61), train_loss = 11.078, time/batch = 0.016\n",
      "3464/2800 (epoch 61), train_loss = 10.435, time/batch = 0.016\n",
      "3465/2800 (epoch 61), train_loss = 10.120, time/batch = 0.000\n",
      "3466/2800 (epoch 61), train_loss = 10.938, time/batch = 0.016\n",
      "3467/2800 (epoch 61), train_loss = 10.578, time/batch = 0.016\n",
      "3468/2800 (epoch 61), train_loss = 10.094, time/batch = 0.022\n",
      "3469/2800 (epoch 61), train_loss = 10.456, time/batch = 0.000\n",
      "3470/2800 (epoch 61), train_loss = 10.096, time/batch = 0.016\n",
      "3471/2800 (epoch 61), train_loss = 10.217, time/batch = 0.016\n",
      "3472/2800 (epoch 62), train_loss = 9.615, time/batch = 0.000\n",
      "3473/2800 (epoch 62), train_loss = 9.439, time/batch = 0.016\n",
      "3474/2800 (epoch 62), train_loss = 9.373, time/batch = 0.016\n",
      "3475/2800 (epoch 62), train_loss = 9.433, time/batch = 0.016\n",
      "3476/2800 (epoch 62), train_loss = 9.232, time/batch = 0.019\n",
      "3477/2800 (epoch 62), train_loss = 9.317, time/batch = 0.003\n",
      "3478/2800 (epoch 62), train_loss = 9.358, time/batch = 0.016\n",
      "3479/2800 (epoch 62), train_loss = 9.463, time/batch = 0.016\n",
      "3480/2800 (epoch 62), train_loss = 9.449, time/batch = 0.016\n",
      "3481/2800 (epoch 62), train_loss = 9.442, time/batch = 0.016\n",
      "3482/2800 (epoch 62), train_loss = 8.938, time/batch = 0.016\n",
      "3483/2800 (epoch 62), train_loss = 9.007, time/batch = 0.000\n",
      "3484/2800 (epoch 62), train_loss = 9.044, time/batch = 0.022\n",
      "3485/2800 (epoch 62), train_loss = 9.391, time/batch = 0.000\n",
      "3486/2800 (epoch 62), train_loss = 9.234, time/batch = 0.016\n",
      "3487/2800 (epoch 62), train_loss = 9.234, time/batch = 0.016\n",
      "3488/2800 (epoch 62), train_loss = 9.176, time/batch = 0.000\n",
      "3489/2800 (epoch 62), train_loss = 9.302, time/batch = 0.016\n",
      "3490/2800 (epoch 62), train_loss = 9.581, time/batch = 0.016\n",
      "3491/2800 (epoch 62), train_loss = 9.113, time/batch = 0.016\n",
      "3492/2800 (epoch 62), train_loss = 8.914, time/batch = 0.021\n",
      "3493/2800 (epoch 62), train_loss = 9.515, time/batch = 0.001\n",
      "3494/2800 (epoch 62), train_loss = 9.716, time/batch = 0.016\n",
      "3495/2800 (epoch 62), train_loss = 9.278, time/batch = 0.016\n",
      "3496/2800 (epoch 62), train_loss = 9.392, time/batch = 0.016\n",
      "3497/2800 (epoch 62), train_loss = 9.471, time/batch = 0.016\n",
      "3498/2800 (epoch 62), train_loss = 9.375, time/batch = 0.016\n",
      "3499/2800 (epoch 62), train_loss = 9.469, time/batch = 0.000\n",
      "3500/2800 (epoch 62), train_loss = 9.353, time/batch = 0.023\n",
      "model saved to save\\model.ckpt\n",
      "3501/2800 (epoch 62), train_loss = 9.745, time/batch = 0.020\n",
      "3502/2800 (epoch 62), train_loss = 9.950, time/batch = 0.031\n",
      "3503/2800 (epoch 62), train_loss = 9.138, time/batch = 0.031\n",
      "3504/2800 (epoch 62), train_loss = 9.364, time/batch = 0.037\n",
      "3505/2800 (epoch 62), train_loss = 9.697, time/batch = 0.016\n",
      "3506/2800 (epoch 62), train_loss = 9.659, time/batch = 0.031\n",
      "3507/2800 (epoch 62), train_loss = 11.266, time/batch = 0.016\n",
      "3508/2800 (epoch 62), train_loss = 10.909, time/batch = 0.022\n",
      "3509/2800 (epoch 62), train_loss = 10.713, time/batch = 0.047\n",
      "3510/2800 (epoch 62), train_loss = 10.833, time/batch = 0.038\n",
      "3511/2800 (epoch 62), train_loss = 10.291, time/batch = 0.031\n",
      "3512/2800 (epoch 62), train_loss = 10.563, time/batch = 0.031\n",
      "3513/2800 (epoch 62), train_loss = 10.262, time/batch = 0.038\n",
      "3514/2800 (epoch 62), train_loss = 10.607, time/batch = 0.031\n",
      "3515/2800 (epoch 62), train_loss = 10.702, time/batch = 0.047\n",
      "3516/2800 (epoch 62), train_loss = 10.315, time/batch = 0.022\n",
      "3517/2800 (epoch 62), train_loss = 10.502, time/batch = 0.047\n",
      "3518/2800 (epoch 62), train_loss = 10.604, time/batch = 0.054\n",
      "3519/2800 (epoch 62), train_loss = 10.154, time/batch = 0.036\n",
      "3520/2800 (epoch 62), train_loss = 11.093, time/batch = 0.047\n",
      "3521/2800 (epoch 62), train_loss = 10.674, time/batch = 0.040\n",
      "3522/2800 (epoch 62), train_loss = 10.282, time/batch = 0.030\n",
      "3523/2800 (epoch 62), train_loss = 10.237, time/batch = 0.031\n",
      "3524/2800 (epoch 62), train_loss = 10.486, time/batch = 0.048\n",
      "3525/2800 (epoch 62), train_loss = 10.199, time/batch = 0.033\n",
      "3526/2800 (epoch 62), train_loss = 10.324, time/batch = 0.050\n",
      "3527/2800 (epoch 62), train_loss = 9.771, time/batch = 0.046\n",
      "3528/2800 (epoch 63), train_loss = 9.567, time/batch = 0.023\n",
      "3529/2800 (epoch 63), train_loss = 9.775, time/batch = 0.047\n",
      "3530/2800 (epoch 63), train_loss = 9.497, time/batch = 0.031\n",
      "3531/2800 (epoch 63), train_loss = 9.276, time/batch = 0.053\n",
      "3532/2800 (epoch 63), train_loss = 10.362, time/batch = 0.031\n",
      "3533/2800 (epoch 63), train_loss = 9.056, time/batch = 0.038\n",
      "3534/2800 (epoch 63), train_loss = 10.346, time/batch = 0.031\n",
      "3535/2800 (epoch 63), train_loss = 9.046, time/batch = 0.031\n",
      "3536/2800 (epoch 63), train_loss = 10.372, time/batch = 0.034\n",
      "3537/2800 (epoch 63), train_loss = 8.785, time/batch = 0.019\n",
      "3538/2800 (epoch 63), train_loss = 10.282, time/batch = 0.031\n",
      "3539/2800 (epoch 63), train_loss = 8.848, time/batch = 0.031\n",
      "3540/2800 (epoch 63), train_loss = 11.745, time/batch = 0.038\n",
      "3541/2800 (epoch 63), train_loss = 9.064, time/batch = 0.031\n",
      "3542/2800 (epoch 63), train_loss = 8.643, time/batch = 0.047\n",
      "3543/2800 (epoch 63), train_loss = 9.211, time/batch = 0.037\n",
      "3544/2800 (epoch 63), train_loss = 10.613, time/batch = 0.016\n",
      "3545/2800 (epoch 63), train_loss = 9.062, time/batch = 0.031\n",
      "3546/2800 (epoch 63), train_loss = 9.749, time/batch = 0.038\n",
      "3547/2800 (epoch 63), train_loss = 8.879, time/batch = 0.031\n",
      "3548/2800 (epoch 63), train_loss = 9.385, time/batch = 0.031\n",
      "3549/2800 (epoch 63), train_loss = 8.961, time/batch = 0.038\n",
      "3550/2800 (epoch 63), train_loss = 10.458, time/batch = 0.031\n",
      "3551/2800 (epoch 63), train_loss = 9.065, time/batch = 0.031\n",
      "3552/2800 (epoch 63), train_loss = 9.331, time/batch = 0.022\n",
      "3553/2800 (epoch 63), train_loss = 9.838, time/batch = 0.016\n",
      "3554/2800 (epoch 63), train_loss = 9.294, time/batch = 0.047\n",
      "3555/2800 (epoch 63), train_loss = 10.547, time/batch = 0.016\n",
      "3556/2800 (epoch 63), train_loss = 8.950, time/batch = 0.022\n",
      "3557/2800 (epoch 63), train_loss = 10.429, time/batch = 0.031\n",
      "3558/2800 (epoch 63), train_loss = 9.359, time/batch = 0.016\n",
      "3559/2800 (epoch 63), train_loss = 9.979, time/batch = 0.031\n",
      "3560/2800 (epoch 63), train_loss = 9.082, time/batch = 0.022\n",
      "3561/2800 (epoch 63), train_loss = 10.439, time/batch = 0.016\n",
      "3562/2800 (epoch 63), train_loss = 8.826, time/batch = 0.031\n",
      "3563/2800 (epoch 63), train_loss = 10.949, time/batch = 0.031\n",
      "3564/2800 (epoch 63), train_loss = 9.295, time/batch = 0.022\n",
      "3565/2800 (epoch 63), train_loss = 13.514, time/batch = 0.016\n",
      "3566/2800 (epoch 63), train_loss = 11.582, time/batch = 0.031\n",
      "3567/2800 (epoch 63), train_loss = 10.728, time/batch = 0.016\n",
      "3568/2800 (epoch 63), train_loss = 10.847, time/batch = 0.035\n",
      "3569/2800 (epoch 63), train_loss = 10.464, time/batch = 0.018\n",
      "3570/2800 (epoch 63), train_loss = 10.529, time/batch = 0.031\n",
      "3571/2800 (epoch 63), train_loss = 10.265, time/batch = 0.016\n",
      "3572/2800 (epoch 63), train_loss = 10.727, time/batch = 0.032\n",
      "3573/2800 (epoch 63), train_loss = 10.355, time/batch = 0.021\n",
      "3574/2800 (epoch 63), train_loss = 10.809, time/batch = 0.016\n",
      "3575/2800 (epoch 63), train_loss = 10.060, time/batch = 0.031\n",
      "3576/2800 (epoch 63), train_loss = 10.587, time/batch = 0.016\n",
      "3577/2800 (epoch 63), train_loss = 10.435, time/batch = 0.022\n",
      "3578/2800 (epoch 63), train_loss = 10.370, time/batch = 0.031\n",
      "3579/2800 (epoch 63), train_loss = 10.351, time/batch = 0.016\n",
      "3580/2800 (epoch 63), train_loss = 10.380, time/batch = 0.016\n",
      "3581/2800 (epoch 63), train_loss = 10.175, time/batch = 0.018\n",
      "3582/2800 (epoch 63), train_loss = 10.636, time/batch = 0.004\n",
      "3583/2800 (epoch 63), train_loss = 9.726, time/batch = 0.031\n",
      "3584/2800 (epoch 64), train_loss = 10.365, time/batch = 0.016\n",
      "3585/2800 (epoch 64), train_loss = 9.308, time/batch = 0.031\n",
      "3586/2800 (epoch 64), train_loss = 9.746, time/batch = 0.021\n",
      "3587/2800 (epoch 64), train_loss = 8.982, time/batch = 0.017\n",
      "3588/2800 (epoch 64), train_loss = 10.043, time/batch = 0.016\n",
      "3589/2800 (epoch 64), train_loss = 9.211, time/batch = 0.016\n",
      "3590/2800 (epoch 64), train_loss = 9.836, time/batch = 0.031\n",
      "3591/2800 (epoch 64), train_loss = 9.187, time/batch = 0.022\n",
      "3592/2800 (epoch 64), train_loss = 9.890, time/batch = 0.016\n",
      "3593/2800 (epoch 64), train_loss = 9.248, time/batch = 0.016\n",
      "3594/2800 (epoch 64), train_loss = 9.165, time/batch = 0.016\n",
      "3595/2800 (epoch 64), train_loss = 9.054, time/batch = 0.031\n",
      "3596/2800 (epoch 64), train_loss = 9.868, time/batch = 0.022\n",
      "3597/2800 (epoch 64), train_loss = 9.248, time/batch = 0.016\n",
      "3598/2800 (epoch 64), train_loss = 9.023, time/batch = 0.016\n",
      "3599/2800 (epoch 64), train_loss = 9.108, time/batch = 0.016\n",
      "3600/2800 (epoch 64), train_loss = 9.340, time/batch = 0.049\n",
      "3601/2800 (epoch 64), train_loss = 9.175, time/batch = 0.019\n",
      "3602/2800 (epoch 64), train_loss = 9.122, time/batch = 0.016\n",
      "3603/2800 (epoch 64), train_loss = 9.016, time/batch = 0.016\n",
      "3604/2800 (epoch 64), train_loss = 9.482, time/batch = 0.016\n",
      "3605/2800 (epoch 64), train_loss = 9.699, time/batch = 0.034\n",
      "3606/2800 (epoch 64), train_loss = 9.337, time/batch = 0.019\n",
      "3607/2800 (epoch 64), train_loss = 9.947, time/batch = 0.016\n",
      "3608/2800 (epoch 64), train_loss = 9.286, time/batch = 0.016\n",
      "3609/2800 (epoch 64), train_loss = 9.920, time/batch = 0.016\n",
      "3610/2800 (epoch 64), train_loss = 9.263, time/batch = 0.016\n",
      "3611/2800 (epoch 64), train_loss = 9.784, time/batch = 0.022\n",
      "3612/2800 (epoch 64), train_loss = 9.877, time/batch = 0.031\n",
      "3613/2800 (epoch 64), train_loss = 9.177, time/batch = 0.031\n",
      "3614/2800 (epoch 64), train_loss = 9.303, time/batch = 0.016\n",
      "3615/2800 (epoch 64), train_loss = 10.001, time/batch = 0.022\n",
      "3616/2800 (epoch 64), train_loss = 9.606, time/batch = 0.016\n",
      "3617/2800 (epoch 64), train_loss = 9.742, time/batch = 0.016\n",
      "3618/2800 (epoch 64), train_loss = 9.256, time/batch = 0.016\n",
      "3619/2800 (epoch 64), train_loss = 9.491, time/batch = 0.031\n",
      "3620/2800 (epoch 64), train_loss = 9.401, time/batch = 0.020\n",
      "3621/2800 (epoch 64), train_loss = 10.565, time/batch = 0.017\n",
      "3622/2800 (epoch 64), train_loss = 11.205, time/batch = 0.016\n",
      "3623/2800 (epoch 64), train_loss = 10.779, time/batch = 0.016\n",
      "3624/2800 (epoch 64), train_loss = 10.777, time/batch = 0.031\n",
      "3625/2800 (epoch 64), train_loss = 10.746, time/batch = 0.023\n",
      "3626/2800 (epoch 64), train_loss = 10.240, time/batch = 0.016\n",
      "3627/2800 (epoch 64), train_loss = 10.534, time/batch = 0.016\n",
      "3628/2800 (epoch 64), train_loss = 10.440, time/batch = 0.016\n",
      "3629/2800 (epoch 64), train_loss = 10.657, time/batch = 0.016\n",
      "3630/2800 (epoch 64), train_loss = 10.552, time/batch = 0.033\n",
      "3631/2800 (epoch 64), train_loss = 10.295, time/batch = 0.005\n",
      "3632/2800 (epoch 64), train_loss = 10.766, time/batch = 0.031\n",
      "3633/2800 (epoch 64), train_loss = 10.403, time/batch = 0.016\n",
      "3634/2800 (epoch 64), train_loss = 10.286, time/batch = 0.016\n",
      "3635/2800 (epoch 64), train_loss = 10.368, time/batch = 0.000\n",
      "3636/2800 (epoch 64), train_loss = 11.281, time/batch = 0.016\n",
      "3637/2800 (epoch 64), train_loss = 9.835, time/batch = 0.022\n",
      "3638/2800 (epoch 64), train_loss = 10.117, time/batch = 0.016\n",
      "3639/2800 (epoch 64), train_loss = 10.522, time/batch = 0.000\n",
      "3640/2800 (epoch 65), train_loss = 9.807, time/batch = 0.016\n",
      "3641/2800 (epoch 65), train_loss = 9.217, time/batch = 0.016\n",
      "3642/2800 (epoch 65), train_loss = 9.705, time/batch = 0.016\n",
      "3643/2800 (epoch 65), train_loss = 9.177, time/batch = 0.016\n",
      "3644/2800 (epoch 65), train_loss = 9.687, time/batch = 0.017\n",
      "3645/2800 (epoch 65), train_loss = 9.136, time/batch = 0.005\n",
      "3646/2800 (epoch 65), train_loss = 9.090, time/batch = 0.016\n",
      "3647/2800 (epoch 65), train_loss = 9.344, time/batch = 0.016\n",
      "3648/2800 (epoch 65), train_loss = 9.758, time/batch = 0.016\n",
      "3649/2800 (epoch 65), train_loss = 9.082, time/batch = 0.016\n",
      "3650/2800 (epoch 65), train_loss = 9.131, time/batch = 0.016\n",
      "3651/2800 (epoch 65), train_loss = 10.336, time/batch = 0.021\n",
      "3652/2800 (epoch 65), train_loss = 9.435, time/batch = 0.000\n",
      "3653/2800 (epoch 65), train_loss = 9.028, time/batch = 0.016\n",
      "3654/2800 (epoch 65), train_loss = 9.748, time/batch = 0.016\n",
      "3655/2800 (epoch 65), train_loss = 9.149, time/batch = 0.016\n",
      "3656/2800 (epoch 65), train_loss = 9.363, time/batch = 0.016\n",
      "3657/2800 (epoch 65), train_loss = 9.244, time/batch = 0.016\n",
      "3658/2800 (epoch 65), train_loss = 9.648, time/batch = 0.000\n",
      "3659/2800 (epoch 65), train_loss = 9.002, time/batch = 0.022\n",
      "3660/2800 (epoch 65), train_loss = 9.660, time/batch = 0.016\n",
      "3661/2800 (epoch 65), train_loss = 9.032, time/batch = 0.016\n",
      "3662/2800 (epoch 65), train_loss = 10.035, time/batch = 0.000\n",
      "3663/2800 (epoch 65), train_loss = 9.671, time/batch = 0.016\n",
      "3664/2800 (epoch 65), train_loss = 9.164, time/batch = 0.016\n",
      "3665/2800 (epoch 65), train_loss = 9.491, time/batch = 0.016\n",
      "3666/2800 (epoch 65), train_loss = 10.355, time/batch = 0.020\n",
      "3667/2800 (epoch 65), train_loss = 9.472, time/batch = 0.002\n",
      "3668/2800 (epoch 65), train_loss = 9.682, time/batch = 0.016\n",
      "3669/2800 (epoch 65), train_loss = 9.997, time/batch = 0.016\n",
      "3670/2800 (epoch 65), train_loss = 9.566, time/batch = 0.016\n",
      "3671/2800 (epoch 65), train_loss = 9.498, time/batch = 0.016\n",
      "3672/2800 (epoch 65), train_loss = 9.527, time/batch = 0.016\n",
      "3673/2800 (epoch 65), train_loss = 9.264, time/batch = 0.000\n",
      "3674/2800 (epoch 65), train_loss = 9.469, time/batch = 0.022\n",
      "3675/2800 (epoch 65), train_loss = 10.199, time/batch = 0.000\n",
      "3676/2800 (epoch 65), train_loss = 11.446, time/batch = 0.016\n",
      "3677/2800 (epoch 65), train_loss = 10.745, time/batch = 0.016\n",
      "3678/2800 (epoch 65), train_loss = 11.423, time/batch = 0.016\n",
      "3679/2800 (epoch 65), train_loss = 10.471, time/batch = 0.016\n",
      "3680/2800 (epoch 65), train_loss = 10.654, time/batch = 0.016\n",
      "3681/2800 (epoch 65), train_loss = 10.226, time/batch = 0.020\n",
      "3682/2800 (epoch 65), train_loss = 10.960, time/batch = 0.002\n",
      "3683/2800 (epoch 65), train_loss = 10.290, time/batch = 0.016\n",
      "3684/2800 (epoch 65), train_loss = 10.695, time/batch = 0.016\n",
      "3685/2800 (epoch 65), train_loss = 10.283, time/batch = 0.016\n",
      "3686/2800 (epoch 65), train_loss = 11.037, time/batch = 0.000\n",
      "3687/2800 (epoch 65), train_loss = 10.371, time/batch = 0.016\n",
      "3688/2800 (epoch 65), train_loss = 10.302, time/batch = 0.016\n",
      "3689/2800 (epoch 65), train_loss = 10.379, time/batch = 0.022\n",
      "3690/2800 (epoch 65), train_loss = 10.176, time/batch = 0.016\n",
      "3691/2800 (epoch 65), train_loss = 10.038, time/batch = 0.000\n",
      "3692/2800 (epoch 65), train_loss = 9.807, time/batch = 0.016\n",
      "3693/2800 (epoch 65), train_loss = 10.444, time/batch = 0.016\n",
      "3694/2800 (epoch 65), train_loss = 10.502, time/batch = 0.016\n",
      "3695/2800 (epoch 65), train_loss = 10.373, time/batch = 0.016\n",
      "3696/2800 (epoch 66), train_loss = 9.665, time/batch = 0.021\n",
      "3697/2800 (epoch 66), train_loss = 9.524, time/batch = 0.001\n",
      "3698/2800 (epoch 66), train_loss = 9.274, time/batch = 0.016\n",
      "3699/2800 (epoch 66), train_loss = 8.828, time/batch = 0.016\n",
      "3700/2800 (epoch 66), train_loss = 11.419, time/batch = 0.016\n",
      "3701/2800 (epoch 66), train_loss = 8.793, time/batch = 0.016\n",
      "3702/2800 (epoch 66), train_loss = 9.727, time/batch = 0.000\n",
      "3703/2800 (epoch 66), train_loss = 9.465, time/batch = 0.016\n",
      "3704/2800 (epoch 66), train_loss = 9.427, time/batch = 0.022\n",
      "3705/2800 (epoch 66), train_loss = 9.356, time/batch = 0.016\n",
      "3706/2800 (epoch 66), train_loss = 9.445, time/batch = 0.000\n",
      "3707/2800 (epoch 66), train_loss = 9.166, time/batch = 0.016\n",
      "3708/2800 (epoch 66), train_loss = 10.775, time/batch = 0.016\n",
      "3709/2800 (epoch 66), train_loss = 9.157, time/batch = 0.016\n",
      "3710/2800 (epoch 66), train_loss = 9.261, time/batch = 0.016\n",
      "3711/2800 (epoch 66), train_loss = 9.251, time/batch = 0.017\n",
      "3712/2800 (epoch 66), train_loss = 9.082, time/batch = 0.004\n",
      "3713/2800 (epoch 66), train_loss = 9.386, time/batch = 0.016\n",
      "3714/2800 (epoch 66), train_loss = 9.080, time/batch = 0.016\n",
      "3715/2800 (epoch 66), train_loss = 9.272, time/batch = 0.016\n",
      "3716/2800 (epoch 66), train_loss = 9.058, time/batch = 0.016\n",
      "3717/2800 (epoch 66), train_loss = 9.166, time/batch = 0.016\n",
      "3718/2800 (epoch 66), train_loss = 9.019, time/batch = 0.000\n",
      "3719/2800 (epoch 66), train_loss = 9.513, time/batch = 0.022\n",
      "3720/2800 (epoch 66), train_loss = 8.819, time/batch = 0.016\n",
      "3721/2800 (epoch 66), train_loss = 10.546, time/batch = 0.000\n",
      "3722/2800 (epoch 66), train_loss = 9.105, time/batch = 0.016\n",
      "3723/2800 (epoch 66), train_loss = 10.266, time/batch = 0.016\n",
      "3724/2800 (epoch 66), train_loss = 8.953, time/batch = 0.016\n",
      "3725/2800 (epoch 66), train_loss = 9.608, time/batch = 0.016\n",
      "3726/2800 (epoch 66), train_loss = 9.200, time/batch = 0.022\n",
      "3727/2800 (epoch 66), train_loss = 10.093, time/batch = 0.000\n",
      "3728/2800 (epoch 66), train_loss = 9.434, time/batch = 0.016\n",
      "3729/2800 (epoch 66), train_loss = 10.152, time/batch = 0.016\n",
      "3730/2800 (epoch 66), train_loss = 9.395, time/batch = 0.016\n",
      "3731/2800 (epoch 66), train_loss = 9.832, time/batch = 0.016\n",
      "3732/2800 (epoch 66), train_loss = 9.067, time/batch = 0.000\n",
      "3733/2800 (epoch 66), train_loss = 10.474, time/batch = 0.016\n",
      "3734/2800 (epoch 66), train_loss = 12.653, time/batch = 0.022\n",
      "3735/2800 (epoch 66), train_loss = 10.840, time/batch = 0.016\n",
      "3736/2800 (epoch 66), train_loss = 11.291, time/batch = 0.000\n",
      "3737/2800 (epoch 66), train_loss = 10.423, time/batch = 0.016\n",
      "3738/2800 (epoch 66), train_loss = 10.517, time/batch = 0.016\n",
      "3739/2800 (epoch 66), train_loss = 10.194, time/batch = 0.016\n",
      "3740/2800 (epoch 66), train_loss = 10.814, time/batch = 0.016\n",
      "3741/2800 (epoch 66), train_loss = 10.315, time/batch = 0.022\n",
      "3742/2800 (epoch 66), train_loss = 10.811, time/batch = 0.016\n",
      "3743/2800 (epoch 66), train_loss = 10.469, time/batch = 0.000\n",
      "3744/2800 (epoch 66), train_loss = 10.638, time/batch = 0.016\n",
      "3745/2800 (epoch 66), train_loss = 10.175, time/batch = 0.016\n",
      "3746/2800 (epoch 66), train_loss = 10.473, time/batch = 0.016\n",
      "3747/2800 (epoch 66), train_loss = 10.237, time/batch = 0.016\n",
      "3748/2800 (epoch 66), train_loss = 10.565, time/batch = 0.000\n",
      "3749/2800 (epoch 66), train_loss = 10.294, time/batch = 0.007\n",
      "3750/2800 (epoch 66), train_loss = 10.722, time/batch = 0.016\n",
      "3751/2800 (epoch 66), train_loss = 10.367, time/batch = 0.016\n",
      "3752/2800 (epoch 67), train_loss = 9.715, time/batch = 0.000\n",
      "3753/2800 (epoch 67), train_loss = 9.511, time/batch = 0.016\n",
      "3754/2800 (epoch 67), train_loss = 10.149, time/batch = 0.016\n",
      "3755/2800 (epoch 67), train_loss = 9.166, time/batch = 0.016\n",
      "3756/2800 (epoch 67), train_loss = 9.224, time/batch = 0.019\n",
      "3757/2800 (epoch 67), train_loss = 9.769, time/batch = 0.003\n",
      "3758/2800 (epoch 67), train_loss = 9.158, time/batch = 0.016\n",
      "3759/2800 (epoch 67), train_loss = 8.990, time/batch = 0.016\n",
      "3760/2800 (epoch 67), train_loss = 9.681, time/batch = 0.016\n",
      "3761/2800 (epoch 67), train_loss = 9.112, time/batch = 0.016\n",
      "3762/2800 (epoch 67), train_loss = 9.919, time/batch = 0.000\n",
      "3763/2800 (epoch 67), train_loss = 8.952, time/batch = 0.016\n",
      "3764/2800 (epoch 67), train_loss = 9.398, time/batch = 0.021\n",
      "3765/2800 (epoch 67), train_loss = 9.246, time/batch = 0.001\n",
      "3766/2800 (epoch 67), train_loss = 9.022, time/batch = 0.016\n",
      "3767/2800 (epoch 67), train_loss = 9.195, time/batch = 0.016\n",
      "3768/2800 (epoch 67), train_loss = 9.168, time/batch = 0.016\n",
      "3769/2800 (epoch 67), train_loss = 9.626, time/batch = 0.016\n",
      "3770/2800 (epoch 67), train_loss = 9.382, time/batch = 0.016\n",
      "3771/2800 (epoch 67), train_loss = 9.335, time/batch = 0.000\n",
      "3772/2800 (epoch 67), train_loss = 9.117, time/batch = 0.006\n",
      "3773/2800 (epoch 67), train_loss = 9.527, time/batch = 0.016\n",
      "3774/2800 (epoch 67), train_loss = 9.989, time/batch = 0.000\n",
      "3775/2800 (epoch 67), train_loss = 10.010, time/batch = 0.000\n",
      "3776/2800 (epoch 67), train_loss = 9.086, time/batch = 0.016\n",
      "3777/2800 (epoch 67), train_loss = 9.880, time/batch = 0.016\n",
      "3778/2800 (epoch 67), train_loss = 10.183, time/batch = 0.016\n",
      "3779/2800 (epoch 67), train_loss = 9.134, time/batch = 0.022\n",
      "3780/2800 (epoch 67), train_loss = 9.860, time/batch = 0.000\n",
      "3781/2800 (epoch 67), train_loss = 9.497, time/batch = 0.016\n",
      "3782/2800 (epoch 67), train_loss = 9.833, time/batch = 0.016\n",
      "3783/2800 (epoch 67), train_loss = 9.406, time/batch = 0.016\n",
      "3784/2800 (epoch 67), train_loss = 9.727, time/batch = 0.016\n",
      "3785/2800 (epoch 67), train_loss = 9.225, time/batch = 0.016\n",
      "3786/2800 (epoch 67), train_loss = 9.626, time/batch = 0.019\n",
      "3787/2800 (epoch 67), train_loss = 10.253, time/batch = 0.004\n",
      "3788/2800 (epoch 67), train_loss = 11.725, time/batch = 0.016\n",
      "3789/2800 (epoch 67), train_loss = 10.507, time/batch = 0.016\n",
      "3790/2800 (epoch 67), train_loss = 11.287, time/batch = 0.000\n",
      "3791/2800 (epoch 67), train_loss = 10.492, time/batch = 0.016\n",
      "3792/2800 (epoch 67), train_loss = 10.589, time/batch = 0.016\n",
      "3793/2800 (epoch 67), train_loss = 10.115, time/batch = 0.016\n",
      "3794/2800 (epoch 67), train_loss = 10.746, time/batch = 0.021\n",
      "3795/2800 (epoch 67), train_loss = 10.545, time/batch = 0.000\n",
      "3796/2800 (epoch 67), train_loss = 10.911, time/batch = 0.016\n",
      "3797/2800 (epoch 67), train_loss = 10.304, time/batch = 0.016\n",
      "3798/2800 (epoch 67), train_loss = 10.459, time/batch = 0.016\n",
      "3799/2800 (epoch 67), train_loss = 10.315, time/batch = 0.016\n",
      "3800/2800 (epoch 67), train_loss = 10.166, time/batch = 0.016\n",
      "3801/2800 (epoch 67), train_loss = 10.669, time/batch = 0.000\n",
      "3802/2800 (epoch 67), train_loss = 10.449, time/batch = 0.007\n",
      "3803/2800 (epoch 67), train_loss = 10.567, time/batch = 0.016\n",
      "3804/2800 (epoch 67), train_loss = 9.891, time/batch = 0.016\n",
      "3805/2800 (epoch 67), train_loss = 12.008, time/batch = 0.000\n",
      "3806/2800 (epoch 67), train_loss = 10.594, time/batch = 0.016\n",
      "3807/2800 (epoch 67), train_loss = 11.385, time/batch = 0.016\n",
      "3808/2800 (epoch 68), train_loss = 9.519, time/batch = 0.016\n",
      "3809/2800 (epoch 68), train_loss = 10.623, time/batch = 0.019\n",
      "3810/2800 (epoch 68), train_loss = 9.082, time/batch = 0.002\n",
      "3811/2800 (epoch 68), train_loss = 10.929, time/batch = 0.016\n",
      "3812/2800 (epoch 68), train_loss = 8.892, time/batch = 0.016\n",
      "3813/2800 (epoch 68), train_loss = 10.582, time/batch = 0.016\n",
      "3814/2800 (epoch 68), train_loss = 8.896, time/batch = 0.016\n",
      "3815/2800 (epoch 68), train_loss = 10.670, time/batch = 0.016\n",
      "3816/2800 (epoch 68), train_loss = 8.921, time/batch = 0.000\n",
      "3817/2800 (epoch 68), train_loss = 9.526, time/batch = 0.022\n",
      "3818/2800 (epoch 68), train_loss = 9.130, time/batch = 0.016\n",
      "3819/2800 (epoch 68), train_loss = 9.511, time/batch = 0.016\n",
      "3820/2800 (epoch 68), train_loss = 8.910, time/batch = 0.016\n",
      "3821/2800 (epoch 68), train_loss = 9.644, time/batch = 0.000\n",
      "3822/2800 (epoch 68), train_loss = 8.919, time/batch = 0.000\n",
      "3823/2800 (epoch 68), train_loss = 9.634, time/batch = 0.016\n",
      "3824/2800 (epoch 68), train_loss = 8.742, time/batch = 0.021\n",
      "3825/2800 (epoch 68), train_loss = 9.502, time/batch = 0.001\n",
      "3826/2800 (epoch 68), train_loss = 9.272, time/batch = 0.016\n",
      "3827/2800 (epoch 68), train_loss = 9.686, time/batch = 0.016\n",
      "3828/2800 (epoch 68), train_loss = 8.763, time/batch = 0.016\n",
      "3829/2800 (epoch 68), train_loss = 9.617, time/batch = 0.016\n",
      "3830/2800 (epoch 68), train_loss = 8.950, time/batch = 0.016\n",
      "3831/2800 (epoch 68), train_loss = 9.853, time/batch = 0.000\n",
      "3832/2800 (epoch 68), train_loss = 9.392, time/batch = 0.022\n",
      "3833/2800 (epoch 68), train_loss = 9.685, time/batch = 0.016\n",
      "3834/2800 (epoch 68), train_loss = 9.505, time/batch = 0.000\n",
      "3835/2800 (epoch 68), train_loss = 9.638, time/batch = 0.016\n",
      "3836/2800 (epoch 68), train_loss = 9.155, time/batch = 0.016\n",
      "3837/2800 (epoch 68), train_loss = 9.842, time/batch = 0.016\n",
      "3838/2800 (epoch 68), train_loss = 9.400, time/batch = 0.016\n",
      "3839/2800 (epoch 68), train_loss = 9.250, time/batch = 0.022\n",
      "3840/2800 (epoch 68), train_loss = 9.497, time/batch = 0.016\n",
      "3841/2800 (epoch 68), train_loss = 9.455, time/batch = 0.000\n",
      "3842/2800 (epoch 68), train_loss = 9.214, time/batch = 0.016\n",
      "3843/2800 (epoch 68), train_loss = 10.855, time/batch = 0.016\n",
      "3844/2800 (epoch 68), train_loss = 10.360, time/batch = 0.016\n",
      "3845/2800 (epoch 68), train_loss = 10.612, time/batch = 0.016\n",
      "3846/2800 (epoch 68), train_loss = 10.544, time/batch = 0.017\n",
      "3847/2800 (epoch 68), train_loss = 10.733, time/batch = 0.006\n",
      "3848/2800 (epoch 68), train_loss = 10.313, time/batch = 0.016\n",
      "3849/2800 (epoch 68), train_loss = 10.488, time/batch = 0.016\n",
      "3850/2800 (epoch 68), train_loss = 10.263, time/batch = 0.016\n",
      "3851/2800 (epoch 68), train_loss = 10.463, time/batch = 0.016\n",
      "3852/2800 (epoch 68), train_loss = 10.345, time/batch = 0.016\n",
      "3853/2800 (epoch 68), train_loss = 10.418, time/batch = 0.000\n",
      "3854/2800 (epoch 68), train_loss = 10.686, time/batch = 0.022\n",
      "3855/2800 (epoch 68), train_loss = 10.419, time/batch = 0.016\n",
      "3856/2800 (epoch 68), train_loss = 10.417, time/batch = 0.016\n",
      "3857/2800 (epoch 68), train_loss = 10.523, time/batch = 0.000\n",
      "3858/2800 (epoch 68), train_loss = 10.084, time/batch = 0.016\n",
      "3859/2800 (epoch 68), train_loss = 10.268, time/batch = 0.016\n",
      "3860/2800 (epoch 68), train_loss = 11.406, time/batch = 0.016\n",
      "3861/2800 (epoch 68), train_loss = 10.006, time/batch = 0.019\n",
      "3862/2800 (epoch 68), train_loss = 10.860, time/batch = 0.003\n",
      "3863/2800 (epoch 68), train_loss = 9.993, time/batch = 0.016\n",
      "3864/2800 (epoch 69), train_loss = 9.918, time/batch = 0.016\n",
      "3865/2800 (epoch 69), train_loss = 9.168, time/batch = 0.016\n",
      "3866/2800 (epoch 69), train_loss = 9.252, time/batch = 0.016\n",
      "3867/2800 (epoch 69), train_loss = 9.903, time/batch = 0.000\n",
      "3868/2800 (epoch 69), train_loss = 9.032, time/batch = 0.016\n",
      "3869/2800 (epoch 69), train_loss = 9.468, time/batch = 0.023\n",
      "3870/2800 (epoch 69), train_loss = 9.101, time/batch = 0.000\n",
      "3871/2800 (epoch 69), train_loss = 10.147, time/batch = 0.016\n",
      "3872/2800 (epoch 69), train_loss = 8.977, time/batch = 0.016\n",
      "3873/2800 (epoch 69), train_loss = 9.957, time/batch = 0.016\n",
      "3874/2800 (epoch 69), train_loss = 8.633, time/batch = 0.016\n",
      "3875/2800 (epoch 69), train_loss = 10.683, time/batch = 0.016\n",
      "3876/2800 (epoch 69), train_loss = 9.122, time/batch = 0.018\n",
      "3877/2800 (epoch 69), train_loss = 9.753, time/batch = 0.004\n",
      "3878/2800 (epoch 69), train_loss = 8.908, time/batch = 0.016\n",
      "3879/2800 (epoch 69), train_loss = 10.000, time/batch = 0.016\n",
      "3880/2800 (epoch 69), train_loss = 8.856, time/batch = 0.016\n",
      "3881/2800 (epoch 69), train_loss = 10.710, time/batch = 0.000\n",
      "3882/2800 (epoch 69), train_loss = 9.018, time/batch = 0.016\n",
      "3883/2800 (epoch 69), train_loss = 9.977, time/batch = 0.016\n",
      "3884/2800 (epoch 69), train_loss = 8.964, time/batch = 0.022\n",
      "3885/2800 (epoch 69), train_loss = 10.143, time/batch = 0.000\n",
      "3886/2800 (epoch 69), train_loss = 8.542, time/batch = 0.016\n",
      "3887/2800 (epoch 69), train_loss = 9.900, time/batch = 0.016\n",
      "3888/2800 (epoch 69), train_loss = 8.751, time/batch = 0.016\n",
      "3889/2800 (epoch 69), train_loss = 10.045, time/batch = 0.016\n",
      "3890/2800 (epoch 69), train_loss = 9.421, time/batch = 0.016\n",
      "3891/2800 (epoch 69), train_loss = 9.531, time/batch = 0.018\n",
      "3892/2800 (epoch 69), train_loss = 9.656, time/batch = 0.004\n",
      "3893/2800 (epoch 69), train_loss = 9.694, time/batch = 0.016\n",
      "3894/2800 (epoch 69), train_loss = 8.885, time/batch = 0.016\n",
      "3895/2800 (epoch 69), train_loss = 9.889, time/batch = 0.016\n",
      "3896/2800 (epoch 69), train_loss = 9.407, time/batch = 0.000\n",
      "3897/2800 (epoch 69), train_loss = 9.840, time/batch = 0.016\n",
      "3898/2800 (epoch 69), train_loss = 9.684, time/batch = 0.016\n",
      "3899/2800 (epoch 69), train_loss = 9.672, time/batch = 0.022\n",
      "3900/2800 (epoch 69), train_loss = 9.165, time/batch = 0.000\n",
      "3901/2800 (epoch 69), train_loss = 9.587, time/batch = 0.016\n",
      "3902/2800 (epoch 69), train_loss = 10.087, time/batch = 0.016\n",
      "3903/2800 (epoch 69), train_loss = 11.834, time/batch = 0.016\n",
      "3904/2800 (epoch 69), train_loss = 10.543, time/batch = 0.016\n",
      "3905/2800 (epoch 69), train_loss = 10.740, time/batch = 0.000\n",
      "3906/2800 (epoch 69), train_loss = 10.444, time/batch = 0.016\n",
      "3907/2800 (epoch 69), train_loss = 10.449, time/batch = 0.022\n",
      "3908/2800 (epoch 69), train_loss = 10.317, time/batch = 0.000\n",
      "3909/2800 (epoch 69), train_loss = 10.513, time/batch = 0.000\n",
      "3910/2800 (epoch 69), train_loss = 10.624, time/batch = 0.016\n",
      "3911/2800 (epoch 69), train_loss = 10.474, time/batch = 0.016\n",
      "3912/2800 (epoch 69), train_loss = 10.170, time/batch = 0.016\n",
      "3913/2800 (epoch 69), train_loss = 11.123, time/batch = 0.016\n",
      "3914/2800 (epoch 69), train_loss = 10.548, time/batch = 0.018\n",
      "3915/2800 (epoch 69), train_loss = 10.185, time/batch = 0.004\n",
      "3916/2800 (epoch 69), train_loss = 10.508, time/batch = 0.016\n",
      "3917/2800 (epoch 69), train_loss = 10.912, time/batch = 0.016\n",
      "3918/2800 (epoch 69), train_loss = 10.232, time/batch = 0.000\n",
      "3919/2800 (epoch 69), train_loss = 10.606, time/batch = 0.016\n",
      "3920/2800 (epoch 70), train_loss = 9.868, time/batch = 0.016\n",
      "3921/2800 (epoch 70), train_loss = 9.497, time/batch = 0.016\n",
      "3922/2800 (epoch 70), train_loss = 9.394, time/batch = 0.018\n",
      "3923/2800 (epoch 70), train_loss = 9.664, time/batch = 0.004\n",
      "3924/2800 (epoch 70), train_loss = 9.118, time/batch = 0.016\n",
      "3925/2800 (epoch 70), train_loss = 9.608, time/batch = 0.016\n",
      "3926/2800 (epoch 70), train_loss = 9.024, time/batch = 0.016\n",
      "3927/2800 (epoch 70), train_loss = 11.125, time/batch = 0.016\n",
      "3928/2800 (epoch 70), train_loss = 8.568, time/batch = 0.000\n",
      "3929/2800 (epoch 70), train_loss = 10.711, time/batch = 0.000\n",
      "3930/2800 (epoch 70), train_loss = 9.001, time/batch = 0.022\n",
      "3931/2800 (epoch 70), train_loss = 9.436, time/batch = 0.000\n",
      "3932/2800 (epoch 70), train_loss = 8.783, time/batch = 0.016\n",
      "3933/2800 (epoch 70), train_loss = 10.090, time/batch = 0.016\n",
      "3934/2800 (epoch 70), train_loss = 9.328, time/batch = 0.016\n",
      "3935/2800 (epoch 70), train_loss = 10.079, time/batch = 0.016\n",
      "3936/2800 (epoch 70), train_loss = 9.204, time/batch = 0.016\n",
      "3937/2800 (epoch 70), train_loss = 9.354, time/batch = 0.000\n",
      "3938/2800 (epoch 70), train_loss = 9.316, time/batch = 0.022\n",
      "3939/2800 (epoch 70), train_loss = 9.203, time/batch = 0.016\n",
      "3940/2800 (epoch 70), train_loss = 8.986, time/batch = 0.016\n",
      "3941/2800 (epoch 70), train_loss = 9.531, time/batch = 0.000\n",
      "3942/2800 (epoch 70), train_loss = 9.192, time/batch = 0.016\n",
      "3943/2800 (epoch 70), train_loss = 9.926, time/batch = 0.016\n",
      "3944/2800 (epoch 70), train_loss = 9.456, time/batch = 0.016\n",
      "3945/2800 (epoch 70), train_loss = 9.399, time/batch = 0.022\n",
      "3946/2800 (epoch 70), train_loss = 9.787, time/batch = 0.000\n",
      "3947/2800 (epoch 70), train_loss = 9.383, time/batch = 0.016\n",
      "3948/2800 (epoch 70), train_loss = 9.684, time/batch = 0.016\n",
      "3949/2800 (epoch 70), train_loss = 9.517, time/batch = 0.000\n",
      "3950/2800 (epoch 70), train_loss = 9.725, time/batch = 0.031\n",
      "3951/2800 (epoch 70), train_loss = 9.436, time/batch = 0.016\n",
      "3952/2800 (epoch 70), train_loss = 9.915, time/batch = 0.017\n",
      "3953/2800 (epoch 70), train_loss = 9.102, time/batch = 0.005\n",
      "3954/2800 (epoch 70), train_loss = 9.797, time/batch = 0.016\n",
      "3955/2800 (epoch 70), train_loss = 10.254, time/batch = 0.016\n",
      "3956/2800 (epoch 70), train_loss = 11.110, time/batch = 0.016\n",
      "3957/2800 (epoch 70), train_loss = 10.465, time/batch = 0.000\n",
      "3958/2800 (epoch 70), train_loss = 10.780, time/batch = 0.000\n",
      "3959/2800 (epoch 70), train_loss = 10.379, time/batch = 0.016\n",
      "3960/2800 (epoch 70), train_loss = 10.578, time/batch = 0.022\n",
      "3961/2800 (epoch 70), train_loss = 10.468, time/batch = 0.016\n",
      "3962/2800 (epoch 70), train_loss = 10.332, time/batch = 0.000\n",
      "3963/2800 (epoch 70), train_loss = 10.432, time/batch = 0.016\n",
      "3964/2800 (epoch 70), train_loss = 10.526, time/batch = 0.016\n",
      "3965/2800 (epoch 70), train_loss = 10.256, time/batch = 0.000\n",
      "3966/2800 (epoch 70), train_loss = 10.634, time/batch = 0.016\n",
      "3967/2800 (epoch 70), train_loss = 10.258, time/batch = 0.016\n",
      "3968/2800 (epoch 70), train_loss = 10.350, time/batch = 0.022\n",
      "3969/2800 (epoch 70), train_loss = 10.982, time/batch = 0.016\n",
      "3970/2800 (epoch 70), train_loss = 10.509, time/batch = 0.000\n",
      "3971/2800 (epoch 70), train_loss = 9.993, time/batch = 0.016\n",
      "3972/2800 (epoch 70), train_loss = 10.229, time/batch = 0.016\n",
      "3973/2800 (epoch 70), train_loss = 9.773, time/batch = 0.016\n",
      "3974/2800 (epoch 70), train_loss = 10.210, time/batch = 0.016\n",
      "3975/2800 (epoch 70), train_loss = 10.689, time/batch = 0.019\n",
      "3976/2800 (epoch 71), train_loss = 9.826, time/batch = 0.002\n",
      "3977/2800 (epoch 71), train_loss = 9.204, time/batch = 0.016\n",
      "3978/2800 (epoch 71), train_loss = 9.781, time/batch = 0.016\n",
      "3979/2800 (epoch 71), train_loss = 9.350, time/batch = 0.016\n",
      "3980/2800 (epoch 71), train_loss = 9.328, time/batch = 0.000\n",
      "3981/2800 (epoch 71), train_loss = 9.560, time/batch = 0.016\n",
      "3982/2800 (epoch 71), train_loss = 9.438, time/batch = 0.016\n",
      "3983/2800 (epoch 71), train_loss = 9.443, time/batch = 0.022\n",
      "3984/2800 (epoch 71), train_loss = 9.255, time/batch = 0.000\n",
      "3985/2800 (epoch 71), train_loss = 9.763, time/batch = 0.000\n",
      "3986/2800 (epoch 71), train_loss = 9.674, time/batch = 0.016\n",
      "3987/2800 (epoch 71), train_loss = 8.860, time/batch = 0.016\n",
      "3988/2800 (epoch 71), train_loss = 8.867, time/batch = 0.016\n",
      "3989/2800 (epoch 71), train_loss = 9.173, time/batch = 0.016\n",
      "3990/2800 (epoch 71), train_loss = 9.273, time/batch = 0.020\n",
      "3991/2800 (epoch 71), train_loss = 11.753, time/batch = 0.013\n",
      "3992/2800 (epoch 71), train_loss = 9.132, time/batch = 0.013\n",
      "3993/2800 (epoch 71), train_loss = 10.121, time/batch = 0.006\n",
      "3994/2800 (epoch 71), train_loss = 8.908, time/batch = 0.016\n",
      "3995/2800 (epoch 71), train_loss = 9.833, time/batch = 0.000\n",
      "3996/2800 (epoch 71), train_loss = 8.782, time/batch = 0.016\n",
      "3997/2800 (epoch 71), train_loss = 9.871, time/batch = 0.016\n",
      "3998/2800 (epoch 71), train_loss = 9.361, time/batch = 0.016\n",
      "3999/2800 (epoch 71), train_loss = 9.447, time/batch = 0.016\n",
      "4000/2800 (epoch 71), train_loss = 9.439, time/batch = 0.019\n",
      "model saved to save\\model.ckpt\n",
      "4001/2800 (epoch 71), train_loss = 9.651, time/batch = 0.031\n",
      "4002/2800 (epoch 71), train_loss = 9.072, time/batch = 0.031\n",
      "4003/2800 (epoch 71), train_loss = 9.447, time/batch = 0.022\n",
      "4004/2800 (epoch 71), train_loss = 9.778, time/batch = 0.031\n",
      "4005/2800 (epoch 71), train_loss = 9.210, time/batch = 0.031\n",
      "4006/2800 (epoch 71), train_loss = 10.575, time/batch = 0.035\n",
      "4007/2800 (epoch 71), train_loss = 9.282, time/batch = 0.033\n",
      "4008/2800 (epoch 71), train_loss = 9.491, time/batch = 0.031\n",
      "4009/2800 (epoch 71), train_loss = 9.265, time/batch = 0.038\n",
      "4010/2800 (epoch 71), train_loss = 9.883, time/batch = 0.031\n",
      "4011/2800 (epoch 71), train_loss = 9.575, time/batch = 0.031\n",
      "4012/2800 (epoch 71), train_loss = 12.920, time/batch = 0.022\n",
      "4013/2800 (epoch 71), train_loss = 10.733, time/batch = 0.047\n",
      "4014/2800 (epoch 71), train_loss = 10.902, time/batch = 0.031\n",
      "4015/2800 (epoch 71), train_loss = 10.323, time/batch = 0.038\n",
      "4016/2800 (epoch 71), train_loss = 10.512, time/batch = 0.031\n",
      "4017/2800 (epoch 71), train_loss = 10.562, time/batch = 0.031\n",
      "4018/2800 (epoch 71), train_loss = 10.451, time/batch = 0.053\n",
      "4019/2800 (epoch 71), train_loss = 10.639, time/batch = 0.047\n",
      "4020/2800 (epoch 71), train_loss = 10.317, time/batch = 0.038\n",
      "4021/2800 (epoch 71), train_loss = 10.031, time/batch = 0.031\n",
      "4022/2800 (epoch 71), train_loss = 11.420, time/batch = 0.047\n",
      "4023/2800 (epoch 71), train_loss = 10.563, time/batch = 0.037\n",
      "4024/2800 (epoch 71), train_loss = 9.922, time/batch = 0.031\n",
      "4025/2800 (epoch 71), train_loss = 11.441, time/batch = 0.038\n",
      "4026/2800 (epoch 71), train_loss = 10.418, time/batch = 0.047\n",
      "4027/2800 (epoch 71), train_loss = 10.329, time/batch = 0.052\n",
      "4028/2800 (epoch 71), train_loss = 10.743, time/batch = 0.051\n",
      "4029/2800 (epoch 71), train_loss = 10.103, time/batch = 0.039\n",
      "4030/2800 (epoch 71), train_loss = 9.814, time/batch = 0.034\n",
      "4031/2800 (epoch 71), train_loss = 10.073, time/batch = 0.032\n",
      "4032/2800 (epoch 72), train_loss = 9.568, time/batch = 0.031\n",
      "4033/2800 (epoch 72), train_loss = 9.418, time/batch = 0.057\n",
      "4034/2800 (epoch 72), train_loss = 9.150, time/batch = 0.040\n",
      "4035/2800 (epoch 72), train_loss = 10.414, time/batch = 0.033\n",
      "4036/2800 (epoch 72), train_loss = 8.884, time/batch = 0.023\n",
      "4037/2800 (epoch 72), train_loss = 10.160, time/batch = 0.031\n",
      "4038/2800 (epoch 72), train_loss = 9.034, time/batch = 0.031\n",
      "4039/2800 (epoch 72), train_loss = 9.985, time/batch = 0.038\n",
      "4040/2800 (epoch 72), train_loss = 8.874, time/batch = 0.031\n",
      "4041/2800 (epoch 72), train_loss = 11.225, time/batch = 0.031\n",
      "4042/2800 (epoch 72), train_loss = 8.971, time/batch = 0.033\n",
      "4043/2800 (epoch 72), train_loss = 9.704, time/batch = 0.020\n",
      "4044/2800 (epoch 72), train_loss = 9.159, time/batch = 0.031\n",
      "4045/2800 (epoch 72), train_loss = 9.464, time/batch = 0.031\n",
      "4046/2800 (epoch 72), train_loss = 9.059, time/batch = 0.038\n",
      "4047/2800 (epoch 72), train_loss = 9.466, time/batch = 0.047\n",
      "4048/2800 (epoch 72), train_loss = 9.469, time/batch = 0.035\n",
      "4049/2800 (epoch 72), train_loss = 9.133, time/batch = 0.018\n",
      "4050/2800 (epoch 72), train_loss = 9.393, time/batch = 0.031\n",
      "4051/2800 (epoch 72), train_loss = 9.158, time/batch = 0.031\n",
      "4052/2800 (epoch 72), train_loss = 9.521, time/batch = 0.038\n",
      "4053/2800 (epoch 72), train_loss = 8.862, time/batch = 0.031\n",
      "4054/2800 (epoch 72), train_loss = 9.448, time/batch = 0.031\n",
      "4055/2800 (epoch 72), train_loss = 9.630, time/batch = 0.021\n",
      "4056/2800 (epoch 72), train_loss = 9.604, time/batch = 0.017\n",
      "4057/2800 (epoch 72), train_loss = 9.750, time/batch = 0.016\n",
      "4058/2800 (epoch 72), train_loss = 9.352, time/batch = 0.031\n",
      "4059/2800 (epoch 72), train_loss = 9.441, time/batch = 0.038\n",
      "4060/2800 (epoch 72), train_loss = 9.738, time/batch = 0.031\n",
      "4061/2800 (epoch 72), train_loss = 9.572, time/batch = 0.031\n",
      "4062/2800 (epoch 72), train_loss = 9.857, time/batch = 0.016\n",
      "4063/2800 (epoch 72), train_loss = 9.779, time/batch = 0.022\n",
      "4064/2800 (epoch 72), train_loss = 9.196, time/batch = 0.031\n",
      "4065/2800 (epoch 72), train_loss = 10.018, time/batch = 0.016\n",
      "4066/2800 (epoch 72), train_loss = 9.270, time/batch = 0.031\n",
      "4067/2800 (epoch 72), train_loss = 10.501, time/batch = 0.022\n",
      "4068/2800 (epoch 72), train_loss = 10.341, time/batch = 0.031\n",
      "4069/2800 (epoch 72), train_loss = 10.817, time/batch = 0.016\n",
      "4070/2800 (epoch 72), train_loss = 10.806, time/batch = 0.031\n",
      "4071/2800 (epoch 72), train_loss = 11.259, time/batch = 0.022\n",
      "4072/2800 (epoch 72), train_loss = 10.458, time/batch = 0.016\n",
      "4073/2800 (epoch 72), train_loss = 10.464, time/batch = 0.031\n",
      "4074/2800 (epoch 72), train_loss = 10.251, time/batch = 0.016\n",
      "4075/2800 (epoch 72), train_loss = 10.667, time/batch = 0.016\n",
      "4076/2800 (epoch 72), train_loss = 10.228, time/batch = 0.021\n",
      "4077/2800 (epoch 72), train_loss = 10.785, time/batch = 0.016\n",
      "4078/2800 (epoch 72), train_loss = 10.215, time/batch = 0.031\n",
      "4079/2800 (epoch 72), train_loss = 10.544, time/batch = 0.016\n",
      "4080/2800 (epoch 72), train_loss = 10.643, time/batch = 0.022\n",
      "4081/2800 (epoch 72), train_loss = 10.156, time/batch = 0.016\n",
      "4082/2800 (epoch 72), train_loss = 10.473, time/batch = 0.016\n",
      "4083/2800 (epoch 72), train_loss = 10.290, time/batch = 0.031\n",
      "4084/2800 (epoch 72), train_loss = 10.467, time/batch = 0.016\n",
      "4085/2800 (epoch 72), train_loss = 10.234, time/batch = 0.022\n",
      "4086/2800 (epoch 72), train_loss = 10.031, time/batch = 0.016\n",
      "4087/2800 (epoch 72), train_loss = 10.533, time/batch = 0.016\n",
      "4088/2800 (epoch 73), train_loss = 9.609, time/batch = 0.031\n",
      "4089/2800 (epoch 73), train_loss = 10.018, time/batch = 0.021\n",
      "4090/2800 (epoch 73), train_loss = 9.425, time/batch = 0.017\n",
      "4091/2800 (epoch 73), train_loss = 9.245, time/batch = 0.016\n",
      "4092/2800 (epoch 73), train_loss = 9.794, time/batch = 0.016\n",
      "4093/2800 (epoch 73), train_loss = 8.929, time/batch = 0.031\n",
      "4094/2800 (epoch 73), train_loss = 9.614, time/batch = 0.021\n",
      "4095/2800 (epoch 73), train_loss = 9.239, time/batch = 0.017\n",
      "4096/2800 (epoch 73), train_loss = 10.152, time/batch = 0.016\n",
      "4097/2800 (epoch 73), train_loss = 9.014, time/batch = 0.016\n",
      "4098/2800 (epoch 73), train_loss = 10.116, time/batch = 0.031\n",
      "4099/2800 (epoch 73), train_loss = 9.678, time/batch = 0.022\n",
      "4100/2800 (epoch 73), train_loss = 9.091, time/batch = 0.016\n",
      "4101/2800 (epoch 73), train_loss = 8.579, time/batch = 0.016\n",
      "4102/2800 (epoch 73), train_loss = 11.233, time/batch = 0.016\n",
      "4103/2800 (epoch 73), train_loss = 8.952, time/batch = 0.031\n",
      "4104/2800 (epoch 73), train_loss = 10.024, time/batch = 0.022\n",
      "4105/2800 (epoch 73), train_loss = 8.784, time/batch = 0.016\n",
      "4106/2800 (epoch 73), train_loss = 9.757, time/batch = 0.016\n",
      "4107/2800 (epoch 73), train_loss = 8.901, time/batch = 0.031\n",
      "4108/2800 (epoch 73), train_loss = 10.299, time/batch = 0.016\n",
      "4109/2800 (epoch 73), train_loss = 8.610, time/batch = 0.022\n",
      "4110/2800 (epoch 73), train_loss = 10.057, time/batch = 0.016\n",
      "4111/2800 (epoch 73), train_loss = 9.360, time/batch = 0.031\n",
      "4112/2800 (epoch 73), train_loss = 9.580, time/batch = 0.016\n",
      "4113/2800 (epoch 73), train_loss = 9.934, time/batch = 0.016\n",
      "4114/2800 (epoch 73), train_loss = 9.299, time/batch = 0.022\n",
      "4115/2800 (epoch 73), train_loss = 10.018, time/batch = 0.016\n",
      "4116/2800 (epoch 73), train_loss = 8.964, time/batch = 0.031\n",
      "4117/2800 (epoch 73), train_loss = 9.629, time/batch = 0.016\n",
      "4118/2800 (epoch 73), train_loss = 9.408, time/batch = 0.016\n",
      "4119/2800 (epoch 73), train_loss = 9.632, time/batch = 0.022\n",
      "4120/2800 (epoch 73), train_loss = 9.675, time/batch = 0.016\n",
      "4121/2800 (epoch 73), train_loss = 9.589, time/batch = 0.016\n",
      "4122/2800 (epoch 73), train_loss = 9.218, time/batch = 0.031\n",
      "4123/2800 (epoch 73), train_loss = 9.853, time/batch = 0.016\n",
      "4124/2800 (epoch 73), train_loss = 9.545, time/batch = 0.022\n",
      "4125/2800 (epoch 73), train_loss = 12.305, time/batch = 0.031\n",
      "4126/2800 (epoch 73), train_loss = 10.599, time/batch = 0.016\n",
      "4127/2800 (epoch 73), train_loss = 11.530, time/batch = 0.016\n",
      "4128/2800 (epoch 73), train_loss = 10.223, time/batch = 0.016\n",
      "4129/2800 (epoch 73), train_loss = 10.642, time/batch = 0.022\n",
      "4130/2800 (epoch 73), train_loss = 10.136, time/batch = 0.016\n",
      "4131/2800 (epoch 73), train_loss = 10.991, time/batch = 0.016\n",
      "4132/2800 (epoch 73), train_loss = 10.183, time/batch = 0.031\n",
      "4133/2800 (epoch 73), train_loss = 10.976, time/batch = 0.016\n",
      "4134/2800 (epoch 73), train_loss = 10.718, time/batch = 0.022\n",
      "4135/2800 (epoch 73), train_loss = 11.155, time/batch = 0.016\n",
      "4136/2800 (epoch 73), train_loss = 10.395, time/batch = 0.016\n",
      "4137/2800 (epoch 73), train_loss = 10.417, time/batch = 0.031\n",
      "4138/2800 (epoch 73), train_loss = 10.523, time/batch = 0.016\n",
      "4139/2800 (epoch 73), train_loss = 10.668, time/batch = 0.022\n",
      "4140/2800 (epoch 73), train_loss = 9.859, time/batch = 0.016\n",
      "4141/2800 (epoch 73), train_loss = 11.234, time/batch = 0.016\n",
      "4142/2800 (epoch 73), train_loss = 10.046, time/batch = 0.016\n",
      "4143/2800 (epoch 73), train_loss = 10.143, time/batch = 0.016\n",
      "4144/2800 (epoch 74), train_loss = 9.671, time/batch = 0.035\n",
      "4145/2800 (epoch 74), train_loss = 10.790, time/batch = 0.018\n",
      "4146/2800 (epoch 74), train_loss = 8.888, time/batch = 0.016\n",
      "4147/2800 (epoch 74), train_loss = 11.257, time/batch = 0.016\n",
      "4148/2800 (epoch 74), train_loss = 9.045, time/batch = 0.000\n",
      "4149/2800 (epoch 74), train_loss = 10.880, time/batch = 0.016\n",
      "4150/2800 (epoch 74), train_loss = 8.783, time/batch = 0.016\n",
      "4151/2800 (epoch 74), train_loss = 11.096, time/batch = 0.022\n",
      "4152/2800 (epoch 74), train_loss = 8.899, time/batch = 0.000\n",
      "4153/2800 (epoch 74), train_loss = 10.498, time/batch = 0.016\n",
      "4154/2800 (epoch 74), train_loss = 9.127, time/batch = 0.016\n",
      "4155/2800 (epoch 74), train_loss = 11.085, time/batch = 0.016\n",
      "4156/2800 (epoch 74), train_loss = 8.743, time/batch = 0.016\n",
      "4157/2800 (epoch 74), train_loss = 9.633, time/batch = 0.000\n",
      "4158/2800 (epoch 74), train_loss = 9.031, time/batch = 0.016\n",
      "4159/2800 (epoch 74), train_loss = 9.508, time/batch = 0.022\n",
      "4160/2800 (epoch 74), train_loss = 8.970, time/batch = 0.016\n",
      "4161/2800 (epoch 74), train_loss = 9.441, time/batch = 0.016\n",
      "4162/2800 (epoch 74), train_loss = 9.013, time/batch = 0.016\n",
      "4163/2800 (epoch 74), train_loss = 10.515, time/batch = 0.016\n",
      "4164/2800 (epoch 74), train_loss = 8.568, time/batch = 0.000\n",
      "4165/2800 (epoch 74), train_loss = 10.110, time/batch = 0.016\n",
      "4166/2800 (epoch 74), train_loss = 9.644, time/batch = 0.022\n",
      "4167/2800 (epoch 74), train_loss = 10.106, time/batch = 0.000\n",
      "4168/2800 (epoch 74), train_loss = 9.101, time/batch = 0.016\n",
      "4169/2800 (epoch 74), train_loss = 10.480, time/batch = 0.016\n",
      "4170/2800 (epoch 74), train_loss = 9.590, time/batch = 0.016\n",
      "4171/2800 (epoch 74), train_loss = 9.384, time/batch = 0.016\n",
      "4172/2800 (epoch 74), train_loss = 9.103, time/batch = 0.016\n",
      "4173/2800 (epoch 74), train_loss = 10.245, time/batch = 0.000\n",
      "4174/2800 (epoch 74), train_loss = 9.372, time/batch = 0.022\n",
      "4175/2800 (epoch 74), train_loss = 10.326, time/batch = 0.016\n",
      "4176/2800 (epoch 74), train_loss = 9.249, time/batch = 0.000\n",
      "4177/2800 (epoch 74), train_loss = 9.572, time/batch = 0.016\n",
      "4178/2800 (epoch 74), train_loss = 9.299, time/batch = 0.016\n",
      "4179/2800 (epoch 74), train_loss = 9.745, time/batch = 0.016\n",
      "4180/2800 (epoch 74), train_loss = 11.464, time/batch = 0.016\n",
      "4181/2800 (epoch 74), train_loss = 10.706, time/batch = 0.020\n",
      "4182/2800 (epoch 74), train_loss = 11.263, time/batch = 0.002\n",
      "4183/2800 (epoch 74), train_loss = 10.335, time/batch = 0.016\n",
      "4184/2800 (epoch 74), train_loss = 10.655, time/batch = 0.016\n",
      "4185/2800 (epoch 74), train_loss = 10.353, time/batch = 0.000\n",
      "4186/2800 (epoch 74), train_loss = 10.647, time/batch = 0.016\n",
      "4187/2800 (epoch 74), train_loss = 10.242, time/batch = 0.016\n",
      "4188/2800 (epoch 74), train_loss = 10.906, time/batch = 0.016\n",
      "4189/2800 (epoch 74), train_loss = 10.133, time/batch = 0.021\n",
      "4190/2800 (epoch 74), train_loss = 10.685, time/batch = 0.000\n",
      "4191/2800 (epoch 74), train_loss = 10.667, time/batch = 0.016\n",
      "4192/2800 (epoch 74), train_loss = 9.998, time/batch = 0.016\n",
      "4193/2800 (epoch 74), train_loss = 10.656, time/batch = 0.016\n",
      "4194/2800 (epoch 74), train_loss = 11.846, time/batch = 0.000\n",
      "4195/2800 (epoch 74), train_loss = 9.979, time/batch = 0.016\n",
      "4196/2800 (epoch 74), train_loss = 10.310, time/batch = 0.016\n",
      "4197/2800 (epoch 74), train_loss = 9.872, time/batch = 0.022\n",
      "4198/2800 (epoch 74), train_loss = 10.544, time/batch = 0.000\n",
      "4199/2800 (epoch 74), train_loss = 10.351, time/batch = 0.016\n",
      "4200/2800 (epoch 75), train_loss = 9.822, time/batch = 0.016\n",
      "4201/2800 (epoch 75), train_loss = 10.269, time/batch = 0.016\n",
      "4202/2800 (epoch 75), train_loss = 9.307, time/batch = 0.016\n",
      "4203/2800 (epoch 75), train_loss = 9.140, time/batch = 0.000\n",
      "4204/2800 (epoch 75), train_loss = 9.858, time/batch = 0.016\n",
      "4205/2800 (epoch 75), train_loss = 9.127, time/batch = 0.022\n",
      "4206/2800 (epoch 75), train_loss = 9.728, time/batch = 0.016\n",
      "4207/2800 (epoch 75), train_loss = 9.027, time/batch = 0.016\n",
      "4208/2800 (epoch 75), train_loss = 9.493, time/batch = 0.000\n",
      "4209/2800 (epoch 75), train_loss = 9.221, time/batch = 0.016\n",
      "4210/2800 (epoch 75), train_loss = 10.299, time/batch = 0.016\n",
      "4211/2800 (epoch 75), train_loss = 9.706, time/batch = 0.016\n",
      "4212/2800 (epoch 75), train_loss = 9.400, time/batch = 0.018\n",
      "4213/2800 (epoch 75), train_loss = 8.896, time/batch = 0.004\n",
      "4214/2800 (epoch 75), train_loss = 9.434, time/batch = 0.016\n",
      "4215/2800 (epoch 75), train_loss = 9.486, time/batch = 0.016\n",
      "4216/2800 (epoch 75), train_loss = 9.264, time/batch = 0.016\n",
      "4217/2800 (epoch 75), train_loss = 8.947, time/batch = 0.016\n",
      "4218/2800 (epoch 75), train_loss = 9.343, time/batch = 0.016\n",
      "4219/2800 (epoch 75), train_loss = 9.220, time/batch = 0.019\n",
      "4220/2800 (epoch 75), train_loss = 9.455, time/batch = 0.002\n",
      "4221/2800 (epoch 75), train_loss = 8.809, time/batch = 0.016\n",
      "4222/2800 (epoch 75), train_loss = 10.208, time/batch = 0.016\n",
      "4223/2800 (epoch 75), train_loss = 9.136, time/batch = 0.016\n",
      "4224/2800 (epoch 75), train_loss = 9.809, time/batch = 0.016\n",
      "4225/2800 (epoch 75), train_loss = 9.469, time/batch = 0.016\n",
      "4226/2800 (epoch 75), train_loss = 9.535, time/batch = 0.000\n",
      "4227/2800 (epoch 75), train_loss = 9.250, time/batch = 0.022\n",
      "4228/2800 (epoch 75), train_loss = 9.537, time/batch = 0.016\n",
      "4229/2800 (epoch 75), train_loss = 9.465, time/batch = 0.016\n",
      "4230/2800 (epoch 75), train_loss = 9.893, time/batch = 0.016\n",
      "4231/2800 (epoch 75), train_loss = 9.621, time/batch = 0.016\n",
      "4232/2800 (epoch 75), train_loss = 9.322, time/batch = 0.016\n",
      "4233/2800 (epoch 75), train_loss = 9.561, time/batch = 0.020\n",
      "4234/2800 (epoch 75), train_loss = 9.328, time/batch = 0.002\n",
      "4235/2800 (epoch 75), train_loss = 10.247, time/batch = 0.016\n",
      "4236/2800 (epoch 75), train_loss = 11.053, time/batch = 0.016\n",
      "4237/2800 (epoch 75), train_loss = 10.675, time/batch = 0.016\n",
      "4238/2800 (epoch 75), train_loss = 11.165, time/batch = 0.016\n",
      "4239/2800 (epoch 75), train_loss = 10.272, time/batch = 0.016\n",
      "4240/2800 (epoch 75), train_loss = 10.753, time/batch = 0.017\n",
      "4241/2800 (epoch 75), train_loss = 10.109, time/batch = 0.005\n",
      "4242/2800 (epoch 75), train_loss = 10.763, time/batch = 0.016\n",
      "4243/2800 (epoch 75), train_loss = 10.399, time/batch = 0.016\n",
      "4244/2800 (epoch 75), train_loss = 10.553, time/batch = 0.016\n",
      "4245/2800 (epoch 75), train_loss = 10.371, time/batch = 0.000\n",
      "4246/2800 (epoch 75), train_loss = 10.436, time/batch = 0.016\n",
      "4247/2800 (epoch 75), train_loss = 10.654, time/batch = 0.016\n",
      "4248/2800 (epoch 75), train_loss = 10.093, time/batch = 0.022\n",
      "4249/2800 (epoch 75), train_loss = 10.591, time/batch = 0.016\n",
      "4250/2800 (epoch 75), train_loss = 11.095, time/batch = 0.000\n",
      "4251/2800 (epoch 75), train_loss = 10.008, time/batch = 0.016\n",
      "4252/2800 (epoch 75), train_loss = 10.466, time/batch = 0.016\n",
      "4253/2800 (epoch 75), train_loss = 9.729, time/batch = 0.016\n",
      "4254/2800 (epoch 75), train_loss = 10.924, time/batch = 0.016\n",
      "4255/2800 (epoch 75), train_loss = 10.213, time/batch = 0.021\n",
      "4256/2800 (epoch 76), train_loss = 9.632, time/batch = 0.001\n",
      "4257/2800 (epoch 76), train_loss = 9.839, time/batch = 0.016\n",
      "4258/2800 (epoch 76), train_loss = 9.963, time/batch = 0.016\n",
      "4259/2800 (epoch 76), train_loss = 9.059, time/batch = 0.016\n",
      "4260/2800 (epoch 76), train_loss = 10.168, time/batch = 0.016\n",
      "4261/2800 (epoch 76), train_loss = 9.316, time/batch = 0.016\n",
      "4262/2800 (epoch 76), train_loss = 9.780, time/batch = 0.000\n",
      "4263/2800 (epoch 76), train_loss = 9.300, time/batch = 0.023\n",
      "4264/2800 (epoch 76), train_loss = 9.720, time/batch = 0.016\n",
      "4265/2800 (epoch 76), train_loss = 8.547, time/batch = 0.016\n",
      "4266/2800 (epoch 76), train_loss = 9.376, time/batch = 0.016\n",
      "4267/2800 (epoch 76), train_loss = 10.057, time/batch = 0.016\n",
      "4268/2800 (epoch 76), train_loss = 9.230, time/batch = 0.016\n",
      "4269/2800 (epoch 76), train_loss = 9.746, time/batch = 0.000\n",
      "4270/2800 (epoch 76), train_loss = 9.123, time/batch = 0.022\n",
      "4271/2800 (epoch 76), train_loss = 9.056, time/batch = 0.016\n",
      "4272/2800 (epoch 76), train_loss = 10.162, time/batch = 0.016\n",
      "4273/2800 (epoch 76), train_loss = 9.064, time/batch = 0.016\n",
      "4274/2800 (epoch 76), train_loss = 9.876, time/batch = 0.016\n",
      "4275/2800 (epoch 76), train_loss = 9.090, time/batch = 0.016\n",
      "4276/2800 (epoch 76), train_loss = 9.181, time/batch = 0.017\n",
      "4277/2800 (epoch 76), train_loss = 9.435, time/batch = 0.005\n",
      "4278/2800 (epoch 76), train_loss = 9.293, time/batch = 0.016\n",
      "4279/2800 (epoch 76), train_loss = 9.576, time/batch = 0.016\n",
      "4280/2800 (epoch 76), train_loss = 9.620, time/batch = 0.016\n",
      "4281/2800 (epoch 76), train_loss = 9.218, time/batch = 0.016\n",
      "4282/2800 (epoch 76), train_loss = 10.776, time/batch = 0.016\n",
      "4283/2800 (epoch 76), train_loss = 9.317, time/batch = 0.000\n",
      "4284/2800 (epoch 76), train_loss = 9.909, time/batch = 0.022\n",
      "4285/2800 (epoch 76), train_loss = 8.747, time/batch = 0.000\n",
      "4286/2800 (epoch 76), train_loss = 9.234, time/batch = 0.016\n",
      "4287/2800 (epoch 76), train_loss = 9.461, time/batch = 0.016\n",
      "4288/2800 (epoch 76), train_loss = 9.168, time/batch = 0.016\n",
      "4289/2800 (epoch 76), train_loss = 9.878, time/batch = 0.016\n",
      "4290/2800 (epoch 76), train_loss = 9.449, time/batch = 0.000\n",
      "4291/2800 (epoch 76), train_loss = 9.757, time/batch = 0.016\n",
      "4292/2800 (epoch 76), train_loss = 9.080, time/batch = 0.022\n",
      "4293/2800 (epoch 76), train_loss = 9.767, time/batch = 0.016\n",
      "4294/2800 (epoch 76), train_loss = 11.306, time/batch = 0.000\n",
      "4295/2800 (epoch 76), train_loss = 10.803, time/batch = 0.016\n",
      "4296/2800 (epoch 76), train_loss = 10.675, time/batch = 0.016\n",
      "4297/2800 (epoch 76), train_loss = 10.465, time/batch = 0.016\n",
      "4298/2800 (epoch 76), train_loss = 10.758, time/batch = 0.016\n",
      "4299/2800 (epoch 76), train_loss = 10.102, time/batch = 0.019\n",
      "4300/2800 (epoch 76), train_loss = 10.832, time/batch = 0.002\n",
      "4301/2800 (epoch 76), train_loss = 10.405, time/batch = 0.016\n",
      "4302/2800 (epoch 76), train_loss = 11.149, time/batch = 0.016\n",
      "4303/2800 (epoch 76), train_loss = 10.015, time/batch = 0.016\n",
      "4304/2800 (epoch 76), train_loss = 10.982, time/batch = 0.000\n",
      "4305/2800 (epoch 76), train_loss = 10.480, time/batch = 0.016\n",
      "4306/2800 (epoch 76), train_loss = 9.878, time/batch = 0.016\n",
      "4307/2800 (epoch 76), train_loss = 10.815, time/batch = 0.021\n",
      "4308/2800 (epoch 76), train_loss = 10.534, time/batch = 0.001\n",
      "4309/2800 (epoch 76), train_loss = 10.416, time/batch = 0.016\n",
      "4310/2800 (epoch 76), train_loss = 10.629, time/batch = 0.016\n",
      "4311/2800 (epoch 76), train_loss = 10.114, time/batch = 0.016\n",
      "4312/2800 (epoch 77), train_loss = 10.177, time/batch = 0.016\n",
      "4313/2800 (epoch 77), train_loss = 9.430, time/batch = 0.016\n",
      "4314/2800 (epoch 77), train_loss = 9.214, time/batch = 0.000\n",
      "4315/2800 (epoch 77), train_loss = 9.731, time/batch = 0.022\n",
      "4316/2800 (epoch 77), train_loss = 9.180, time/batch = 0.016\n",
      "4317/2800 (epoch 77), train_loss = 9.768, time/batch = 0.016\n",
      "4318/2800 (epoch 77), train_loss = 9.081, time/batch = 0.016\n",
      "4319/2800 (epoch 77), train_loss = 10.140, time/batch = 0.000\n",
      "4320/2800 (epoch 77), train_loss = 9.024, time/batch = 0.016\n",
      "4321/2800 (epoch 77), train_loss = 10.172, time/batch = 0.016\n",
      "4322/2800 (epoch 77), train_loss = 8.866, time/batch = 0.019\n",
      "4323/2800 (epoch 77), train_loss = 10.085, time/batch = 0.003\n",
      "4324/2800 (epoch 77), train_loss = 8.840, time/batch = 0.016\n",
      "4325/2800 (epoch 77), train_loss = 9.594, time/batch = 0.016\n",
      "4326/2800 (epoch 77), train_loss = 9.362, time/batch = 0.016\n",
      "4327/2800 (epoch 77), train_loss = 9.115, time/batch = 0.016\n",
      "4328/2800 (epoch 77), train_loss = 9.044, time/batch = 0.016\n",
      "4329/2800 (epoch 77), train_loss = 9.618, time/batch = 0.020\n",
      "4330/2800 (epoch 77), train_loss = 8.989, time/batch = 0.003\n",
      "4331/2800 (epoch 77), train_loss = 9.410, time/batch = 0.016\n",
      "4332/2800 (epoch 77), train_loss = 8.930, time/batch = 0.016\n",
      "4333/2800 (epoch 77), train_loss = 9.359, time/batch = 0.016\n",
      "4334/2800 (epoch 77), train_loss = 8.779, time/batch = 0.016\n",
      "4335/2800 (epoch 77), train_loss = 9.478, time/batch = 0.000\n",
      "4336/2800 (epoch 77), train_loss = 8.989, time/batch = 0.016\n",
      "4337/2800 (epoch 77), train_loss = 10.515, time/batch = 0.022\n",
      "4338/2800 (epoch 77), train_loss = 9.470, time/batch = 0.000\n",
      "4339/2800 (epoch 77), train_loss = 10.119, time/batch = 0.016\n",
      "4340/2800 (epoch 77), train_loss = 9.260, time/batch = 0.016\n",
      "4341/2800 (epoch 77), train_loss = 10.447, time/batch = 0.016\n",
      "4342/2800 (epoch 77), train_loss = 9.010, time/batch = 0.016\n",
      "4343/2800 (epoch 77), train_loss = 10.012, time/batch = 0.016\n",
      "4344/2800 (epoch 77), train_loss = 9.472, time/batch = 0.016\n",
      "4345/2800 (epoch 77), train_loss = 10.252, time/batch = 0.006\n",
      "4346/2800 (epoch 77), train_loss = 9.253, time/batch = 0.016\n",
      "4347/2800 (epoch 77), train_loss = 9.897, time/batch = 0.016\n",
      "4348/2800 (epoch 77), train_loss = 9.143, time/batch = 0.000\n",
      "4349/2800 (epoch 77), train_loss = 9.761, time/batch = 0.016\n",
      "4350/2800 (epoch 77), train_loss = 10.057, time/batch = 0.016\n",
      "4351/2800 (epoch 77), train_loss = 11.336, time/batch = 0.016\n",
      "4352/2800 (epoch 77), train_loss = 10.431, time/batch = 0.019\n",
      "4353/2800 (epoch 77), train_loss = 11.622, time/batch = 0.003\n",
      "4354/2800 (epoch 77), train_loss = 10.282, time/batch = 0.016\n",
      "4355/2800 (epoch 77), train_loss = 10.805, time/batch = 0.000\n",
      "4356/2800 (epoch 77), train_loss = 10.087, time/batch = 0.016\n",
      "4357/2800 (epoch 77), train_loss = 10.927, time/batch = 0.016\n",
      "4358/2800 (epoch 77), train_loss = 10.188, time/batch = 0.016\n",
      "4359/2800 (epoch 77), train_loss = 11.142, time/batch = 0.018\n",
      "4360/2800 (epoch 77), train_loss = 10.080, time/batch = 0.005\n",
      "4361/2800 (epoch 77), train_loss = 11.050, time/batch = 0.016\n",
      "4362/2800 (epoch 77), train_loss = 10.298, time/batch = 0.016\n",
      "4363/2800 (epoch 77), train_loss = 10.066, time/batch = 0.016\n",
      "4364/2800 (epoch 77), train_loss = 10.516, time/batch = 0.016\n",
      "4365/2800 (epoch 77), train_loss = 10.955, time/batch = 0.016\n",
      "4366/2800 (epoch 77), train_loss = 10.099, time/batch = 0.000\n",
      "4367/2800 (epoch 77), train_loss = 10.967, time/batch = 0.022\n",
      "4368/2800 (epoch 78), train_loss = 9.674, time/batch = 0.016\n",
      "4369/2800 (epoch 78), train_loss = 9.253, time/batch = 0.016\n",
      "4370/2800 (epoch 78), train_loss = 9.138, time/batch = 0.000\n",
      "4371/2800 (epoch 78), train_loss = 10.124, time/batch = 0.016\n",
      "4372/2800 (epoch 78), train_loss = 8.880, time/batch = 0.016\n",
      "4373/2800 (epoch 78), train_loss = 9.136, time/batch = 0.016\n",
      "4374/2800 (epoch 78), train_loss = 8.886, time/batch = 0.017\n",
      "4375/2800 (epoch 78), train_loss = 13.146, time/batch = 0.005\n",
      "4376/2800 (epoch 78), train_loss = 8.765, time/batch = 0.016\n",
      "4377/2800 (epoch 78), train_loss = 10.066, time/batch = 0.016\n",
      "4378/2800 (epoch 78), train_loss = 9.172, time/batch = 0.016\n",
      "4379/2800 (epoch 78), train_loss = 10.023, time/batch = 0.000\n",
      "4380/2800 (epoch 78), train_loss = 9.470, time/batch = 0.016\n",
      "4381/2800 (epoch 78), train_loss = 9.776, time/batch = 0.000\n",
      "4382/2800 (epoch 78), train_loss = 8.973, time/batch = 0.007\n",
      "4383/2800 (epoch 78), train_loss = 9.384, time/batch = 0.016\n",
      "4384/2800 (epoch 78), train_loss = 9.181, time/batch = 0.000\n",
      "4385/2800 (epoch 78), train_loss = 9.506, time/batch = 0.016\n",
      "4386/2800 (epoch 78), train_loss = 8.921, time/batch = 0.016\n",
      "4387/2800 (epoch 78), train_loss = 9.403, time/batch = 0.016\n",
      "4388/2800 (epoch 78), train_loss = 9.471, time/batch = 0.016\n",
      "4389/2800 (epoch 78), train_loss = 9.051, time/batch = 0.020\n",
      "4390/2800 (epoch 78), train_loss = 9.068, time/batch = 0.001\n",
      "4391/2800 (epoch 78), train_loss = 10.189, time/batch = 0.016\n",
      "4392/2800 (epoch 78), train_loss = 9.017, time/batch = 0.016\n",
      "4393/2800 (epoch 78), train_loss = 9.537, time/batch = 0.000\n",
      "4394/2800 (epoch 78), train_loss = 9.864, time/batch = 0.000\n",
      "4395/2800 (epoch 78), train_loss = 9.257, time/batch = 0.016\n",
      "4396/2800 (epoch 78), train_loss = 10.082, time/batch = 0.016\n",
      "4397/2800 (epoch 78), train_loss = 9.581, time/batch = 0.022\n",
      "4398/2800 (epoch 78), train_loss = 9.446, time/batch = 0.000\n",
      "4399/2800 (epoch 78), train_loss = 9.653, time/batch = 0.016\n",
      "4400/2800 (epoch 78), train_loss = 9.399, time/batch = 0.016\n",
      "4401/2800 (epoch 78), train_loss = 9.565, time/batch = 0.016\n",
      "4402/2800 (epoch 78), train_loss = 9.252, time/batch = 0.016\n",
      "4403/2800 (epoch 78), train_loss = 9.462, time/batch = 0.016\n",
      "4404/2800 (epoch 78), train_loss = 9.228, time/batch = 0.000\n",
      "4405/2800 (epoch 78), train_loss = 11.548, time/batch = 0.022\n",
      "4406/2800 (epoch 78), train_loss = 10.972, time/batch = 0.016\n",
      "4407/2800 (epoch 78), train_loss = 10.761, time/batch = 0.016\n",
      "4408/2800 (epoch 78), train_loss = 10.685, time/batch = 0.000\n",
      "4409/2800 (epoch 78), train_loss = 10.405, time/batch = 0.016\n",
      "4410/2800 (epoch 78), train_loss = 10.382, time/batch = 0.016\n",
      "4411/2800 (epoch 78), train_loss = 10.293, time/batch = 0.016\n",
      "4412/2800 (epoch 78), train_loss = 10.597, time/batch = 0.017\n",
      "4413/2800 (epoch 78), train_loss = 10.478, time/batch = 0.005\n",
      "4414/2800 (epoch 78), train_loss = 10.258, time/batch = 0.016\n",
      "4415/2800 (epoch 78), train_loss = 11.195, time/batch = 0.016\n",
      "4416/2800 (epoch 78), train_loss = 10.483, time/batch = 0.016\n",
      "4417/2800 (epoch 78), train_loss = 10.105, time/batch = 0.000\n",
      "4418/2800 (epoch 78), train_loss = 10.597, time/batch = 0.016\n",
      "4419/2800 (epoch 78), train_loss = 10.227, time/batch = 0.016\n",
      "4420/2800 (epoch 78), train_loss = 10.126, time/batch = 0.022\n",
      "4421/2800 (epoch 78), train_loss = 10.490, time/batch = 0.016\n",
      "4422/2800 (epoch 78), train_loss = 10.100, time/batch = 0.016\n",
      "4423/2800 (epoch 78), train_loss = 10.286, time/batch = 0.000\n",
      "4424/2800 (epoch 79), train_loss = 9.789, time/batch = 0.016\n",
      "4425/2800 (epoch 79), train_loss = 9.270, time/batch = 0.016\n",
      "4426/2800 (epoch 79), train_loss = 9.907, time/batch = 0.016\n",
      "4427/2800 (epoch 79), train_loss = 9.986, time/batch = 0.000\n",
      "4428/2800 (epoch 79), train_loss = 9.117, time/batch = 0.006\n",
      "4429/2800 (epoch 79), train_loss = 10.147, time/batch = 0.016\n",
      "4430/2800 (epoch 79), train_loss = 9.062, time/batch = 0.000\n",
      "4431/2800 (epoch 79), train_loss = 9.818, time/batch = 0.016\n",
      "4432/2800 (epoch 79), train_loss = 9.345, time/batch = 0.016\n",
      "4433/2800 (epoch 79), train_loss = 9.831, time/batch = 0.016\n",
      "4434/2800 (epoch 79), train_loss = 8.834, time/batch = 0.016\n",
      "4435/2800 (epoch 79), train_loss = 9.721, time/batch = 0.020\n",
      "4436/2800 (epoch 79), train_loss = 9.711, time/batch = 0.002\n",
      "4437/2800 (epoch 79), train_loss = 8.915, time/batch = 0.016\n",
      "4438/2800 (epoch 79), train_loss = 8.910, time/batch = 0.016\n",
      "4439/2800 (epoch 79), train_loss = 9.684, time/batch = 0.016\n",
      "4440/2800 (epoch 79), train_loss = 9.820, time/batch = 0.016\n",
      "4441/2800 (epoch 79), train_loss = 10.168, time/batch = 0.016\n",
      "4442/2800 (epoch 79), train_loss = 9.174, time/batch = 0.000\n",
      "4443/2800 (epoch 79), train_loss = 9.535, time/batch = 0.022\n",
      "4444/2800 (epoch 79), train_loss = 9.048, time/batch = 0.016\n",
      "4445/2800 (epoch 79), train_loss = 9.623, time/batch = 0.000\n",
      "4446/2800 (epoch 79), train_loss = 9.011, time/batch = 0.000\n",
      "4447/2800 (epoch 79), train_loss = 9.669, time/batch = 0.016\n",
      "4448/2800 (epoch 79), train_loss = 9.551, time/batch = 0.016\n",
      "4449/2800 (epoch 79), train_loss = 9.284, time/batch = 0.016\n",
      "4450/2800 (epoch 79), train_loss = 9.423, time/batch = 0.021\n",
      "4451/2800 (epoch 79), train_loss = 9.879, time/batch = 0.000\n",
      "4452/2800 (epoch 79), train_loss = 9.542, time/batch = 0.016\n",
      "4453/2800 (epoch 79), train_loss = 9.320, time/batch = 0.016\n",
      "4454/2800 (epoch 79), train_loss = 9.113, time/batch = 0.016\n",
      "4455/2800 (epoch 79), train_loss = 9.658, time/batch = 0.000\n",
      "4456/2800 (epoch 79), train_loss = 9.473, time/batch = 0.016\n",
      "4457/2800 (epoch 79), train_loss = 9.612, time/batch = 0.016\n",
      "4458/2800 (epoch 79), train_loss = 9.359, time/batch = 0.022\n",
      "4459/2800 (epoch 79), train_loss = 9.613, time/batch = 0.000\n",
      "4460/2800 (epoch 79), train_loss = 9.256, time/batch = 0.016\n",
      "4461/2800 (epoch 79), train_loss = 9.543, time/batch = 0.016\n",
      "4462/2800 (epoch 79), train_loss = 9.887, time/batch = 0.016\n",
      "4463/2800 (epoch 79), train_loss = 11.945, time/batch = 0.016\n",
      "4464/2800 (epoch 79), train_loss = 10.292, time/batch = 0.000\n",
      "4465/2800 (epoch 79), train_loss = 10.321, time/batch = 0.016\n",
      "4466/2800 (epoch 79), train_loss = 11.034, time/batch = 0.022\n",
      "4467/2800 (epoch 79), train_loss = 10.358, time/batch = 0.016\n",
      "4468/2800 (epoch 79), train_loss = 10.558, time/batch = 0.016\n",
      "4469/2800 (epoch 79), train_loss = 10.136, time/batch = 0.016\n",
      "4470/2800 (epoch 79), train_loss = 10.864, time/batch = 0.000\n",
      "4471/2800 (epoch 79), train_loss = 10.159, time/batch = 0.016\n",
      "4472/2800 (epoch 79), train_loss = 10.496, time/batch = 0.016\n",
      "4473/2800 (epoch 79), train_loss = 10.346, time/batch = 0.021\n",
      "4474/2800 (epoch 79), train_loss = 10.733, time/batch = 0.001\n",
      "4475/2800 (epoch 79), train_loss = 10.119, time/batch = 0.016\n",
      "4476/2800 (epoch 79), train_loss = 11.031, time/batch = 0.016\n",
      "4477/2800 (epoch 79), train_loss = 10.320, time/batch = 0.016\n",
      "4478/2800 (epoch 79), train_loss = 10.045, time/batch = 0.016\n",
      "4479/2800 (epoch 79), train_loss = 10.050, time/batch = 0.016\n",
      "4480/2800 (epoch 80), train_loss = 9.841, time/batch = 0.022\n",
      "4481/2800 (epoch 80), train_loss = 9.235, time/batch = 0.000\n",
      "4482/2800 (epoch 80), train_loss = 9.340, time/batch = 0.031\n",
      "4483/2800 (epoch 80), train_loss = 9.429, time/batch = 0.016\n",
      "4484/2800 (epoch 80), train_loss = 8.734, time/batch = 0.016\n",
      "4485/2800 (epoch 80), train_loss = 9.807, time/batch = 0.016\n",
      "4486/2800 (epoch 80), train_loss = 9.608, time/batch = 0.022\n",
      "4487/2800 (epoch 80), train_loss = 10.000, time/batch = 0.016\n",
      "4488/2800 (epoch 80), train_loss = 9.489, time/batch = 0.016\n",
      "4489/2800 (epoch 80), train_loss = 9.023, time/batch = 0.047\n",
      "4490/2800 (epoch 80), train_loss = 10.451, time/batch = 0.032\n",
      "4491/2800 (epoch 80), train_loss = 9.240, time/batch = 0.028\n",
      "4492/2800 (epoch 80), train_loss = 9.675, time/batch = 0.013\n",
      "4493/2800 (epoch 80), train_loss = 9.370, time/batch = 0.014\n",
      "4494/2800 (epoch 80), train_loss = 8.921, time/batch = 0.014\n",
      "4495/2800 (epoch 80), train_loss = 9.197, time/batch = 0.017\n",
      "4496/2800 (epoch 80), train_loss = 9.369, time/batch = 0.016\n",
      "4497/2800 (epoch 80), train_loss = 9.086, time/batch = 0.017\n",
      "4498/2800 (epoch 80), train_loss = 9.018, time/batch = 0.015\n",
      "4499/2800 (epoch 80), train_loss = 9.112, time/batch = 0.013\n",
      "4500/2800 (epoch 80), train_loss = 9.026, time/batch = 0.015\n",
      "model saved to save\\model.ckpt\n",
      "4501/2800 (epoch 80), train_loss = 8.891, time/batch = 0.031\n",
      "4502/2800 (epoch 80), train_loss = 9.989, time/batch = 0.038\n",
      "4503/2800 (epoch 80), train_loss = 9.144, time/batch = 0.031\n",
      "4504/2800 (epoch 80), train_loss = 9.369, time/batch = 0.031\n",
      "4505/2800 (epoch 80), train_loss = 10.754, time/batch = 0.037\n",
      "4506/2800 (epoch 80), train_loss = 9.299, time/batch = 0.016\n",
      "4507/2800 (epoch 80), train_loss = 10.263, time/batch = 0.047\n",
      "4508/2800 (epoch 80), train_loss = 9.211, time/batch = 0.038\n",
      "4509/2800 (epoch 80), train_loss = 9.674, time/batch = 0.031\n",
      "4510/2800 (epoch 80), train_loss = 9.212, time/batch = 0.031\n",
      "4511/2800 (epoch 80), train_loss = 10.162, time/batch = 0.037\n",
      "4512/2800 (epoch 80), train_loss = 9.475, time/batch = 0.031\n",
      "4513/2800 (epoch 80), train_loss = 9.495, time/batch = 0.051\n",
      "4514/2800 (epoch 80), train_loss = 9.263, time/batch = 0.033\n",
      "4515/2800 (epoch 80), train_loss = 9.924, time/batch = 0.031\n",
      "4516/2800 (epoch 80), train_loss = 9.234, time/batch = 0.038\n",
      "4517/2800 (epoch 80), train_loss = 11.779, time/batch = 0.031\n",
      "4518/2800 (epoch 80), train_loss = 10.661, time/batch = 0.047\n",
      "4519/2800 (epoch 80), train_loss = 10.660, time/batch = 0.053\n",
      "4520/2800 (epoch 80), train_loss = 10.366, time/batch = 0.031\n",
      "4521/2800 (epoch 80), train_loss = 10.799, time/batch = 0.038\n",
      "4522/2800 (epoch 80), train_loss = 10.129, time/batch = 0.031\n",
      "4523/2800 (epoch 80), train_loss = 10.715, time/batch = 0.031\n",
      "4524/2800 (epoch 80), train_loss = 10.292, time/batch = 0.038\n",
      "4525/2800 (epoch 80), train_loss = 11.061, time/batch = 0.047\n",
      "4526/2800 (epoch 80), train_loss = 10.089, time/batch = 0.047\n",
      "4527/2800 (epoch 80), train_loss = 11.076, time/batch = 0.037\n",
      "4528/2800 (epoch 80), train_loss = 10.471, time/batch = 0.047\n",
      "4529/2800 (epoch 80), train_loss = 10.294, time/batch = 0.038\n",
      "4530/2800 (epoch 80), train_loss = 10.604, time/batch = 0.031\n",
      "4531/2800 (epoch 80), train_loss = 10.676, time/batch = 0.050\n",
      "4532/2800 (epoch 80), train_loss = 9.912, time/batch = 0.034\n",
      "4533/2800 (epoch 80), train_loss = 10.275, time/batch = 0.031\n",
      "4534/2800 (epoch 80), train_loss = 9.803, time/batch = 0.038\n",
      "4535/2800 (epoch 80), train_loss = 10.361, time/batch = 0.031\n",
      "4536/2800 (epoch 81), train_loss = 9.732, time/batch = 0.066\n",
      "4537/2800 (epoch 81), train_loss = 9.232, time/batch = 0.047\n",
      "4538/2800 (epoch 81), train_loss = 9.094, time/batch = 0.016\n",
      "4539/2800 (epoch 81), train_loss = 9.975, time/batch = 0.038\n",
      "4540/2800 (epoch 81), train_loss = 9.229, time/batch = 0.031\n",
      "4541/2800 (epoch 81), train_loss = 10.167, time/batch = 0.031\n",
      "4542/2800 (epoch 81), train_loss = 9.170, time/batch = 0.037\n",
      "4543/2800 (epoch 81), train_loss = 9.694, time/batch = 0.031\n",
      "4544/2800 (epoch 81), train_loss = 9.103, time/batch = 0.031\n",
      "4545/2800 (epoch 81), train_loss = 9.650, time/batch = 0.040\n",
      "4546/2800 (epoch 81), train_loss = 9.398, time/batch = 0.034\n",
      "4547/2800 (epoch 81), train_loss = 9.341, time/batch = 0.033\n",
      "4548/2800 (epoch 81), train_loss = 9.070, time/batch = 0.030\n",
      "4549/2800 (epoch 81), train_loss = 11.174, time/batch = 0.019\n",
      "4550/2800 (epoch 81), train_loss = 8.890, time/batch = 0.047\n",
      "4551/2800 (epoch 81), train_loss = 9.459, time/batch = 0.031\n",
      "4552/2800 (epoch 81), train_loss = 9.261, time/batch = 0.022\n",
      "4553/2800 (epoch 81), train_loss = 10.078, time/batch = 0.016\n",
      "4554/2800 (epoch 81), train_loss = 8.959, time/batch = 0.031\n",
      "4555/2800 (epoch 81), train_loss = 9.543, time/batch = 0.016\n",
      "4556/2800 (epoch 81), train_loss = 9.103, time/batch = 0.038\n",
      "4557/2800 (epoch 81), train_loss = 9.409, time/batch = 0.016\n",
      "4558/2800 (epoch 81), train_loss = 9.029, time/batch = 0.016\n",
      "4559/2800 (epoch 81), train_loss = 9.750, time/batch = 0.031\n",
      "4560/2800 (epoch 81), train_loss = 9.520, time/batch = 0.035\n",
      "4561/2800 (epoch 81), train_loss = 9.443, time/batch = 0.018\n",
      "4562/2800 (epoch 81), train_loss = 9.900, time/batch = 0.016\n",
      "4563/2800 (epoch 81), train_loss = 9.411, time/batch = 0.031\n",
      "4564/2800 (epoch 81), train_loss = 9.860, time/batch = 0.016\n",
      "4565/2800 (epoch 81), train_loss = 9.776, time/batch = 0.038\n",
      "4566/2800 (epoch 81), train_loss = 9.055, time/batch = 0.016\n",
      "4567/2800 (epoch 81), train_loss = 9.317, time/batch = 0.016\n",
      "4568/2800 (epoch 81), train_loss = 9.841, time/batch = 0.035\n",
      "4569/2800 (epoch 81), train_loss = 9.498, time/batch = 0.018\n",
      "4570/2800 (epoch 81), train_loss = 10.114, time/batch = 0.031\n",
      "4571/2800 (epoch 81), train_loss = 9.287, time/batch = 0.016\n",
      "4572/2800 (epoch 81), train_loss = 9.825, time/batch = 0.016\n",
      "4573/2800 (epoch 81), train_loss = 9.132, time/batch = 0.038\n",
      "4574/2800 (epoch 81), train_loss = 10.472, time/batch = 0.016\n",
      "4575/2800 (epoch 81), train_loss = 11.672, time/batch = 0.031\n",
      "4576/2800 (epoch 81), train_loss = 10.464, time/batch = 0.016\n",
      "4577/2800 (epoch 81), train_loss = 11.230, time/batch = 0.022\n",
      "4578/2800 (epoch 81), train_loss = 10.504, time/batch = 0.016\n",
      "4579/2800 (epoch 81), train_loss = 10.387, time/batch = 0.031\n",
      "4580/2800 (epoch 81), train_loss = 10.339, time/batch = 0.016\n",
      "4581/2800 (epoch 81), train_loss = 10.576, time/batch = 0.033\n",
      "4582/2800 (epoch 81), train_loss = 10.301, time/batch = 0.005\n",
      "4583/2800 (epoch 81), train_loss = 10.674, time/batch = 0.031\n",
      "4584/2800 (epoch 81), train_loss = 10.284, time/batch = 0.016\n",
      "4585/2800 (epoch 81), train_loss = 10.403, time/batch = 0.016\n",
      "4586/2800 (epoch 81), train_loss = 10.107, time/batch = 0.034\n",
      "4587/2800 (epoch 81), train_loss = 11.444, time/batch = 0.019\n",
      "4588/2800 (epoch 81), train_loss = 10.560, time/batch = 0.016\n",
      "4589/2800 (epoch 81), train_loss = 10.275, time/batch = 0.016\n",
      "4590/2800 (epoch 81), train_loss = 10.120, time/batch = 0.031\n",
      "4591/2800 (epoch 81), train_loss = 9.725, time/batch = 0.022\n",
      "4592/2800 (epoch 82), train_loss = 10.623, time/batch = 0.016\n",
      "4593/2800 (epoch 82), train_loss = 9.418, time/batch = 0.031\n",
      "4594/2800 (epoch 82), train_loss = 9.973, time/batch = 0.016\n",
      "4595/2800 (epoch 82), train_loss = 8.800, time/batch = 0.038\n",
      "4596/2800 (epoch 82), train_loss = 10.517, time/batch = 0.016\n",
      "4597/2800 (epoch 82), train_loss = 9.809, time/batch = 0.016\n",
      "4598/2800 (epoch 82), train_loss = 9.623, time/batch = 0.016\n",
      "4599/2800 (epoch 82), train_loss = 9.540, time/batch = 0.031\n",
      "4600/2800 (epoch 82), train_loss = 9.412, time/batch = 0.022\n",
      "4601/2800 (epoch 82), train_loss = 9.418, time/batch = 0.016\n",
      "4602/2800 (epoch 82), train_loss = 10.838, time/batch = 0.016\n",
      "4603/2800 (epoch 82), train_loss = 8.780, time/batch = 0.031\n",
      "4604/2800 (epoch 82), train_loss = 9.825, time/batch = 0.016\n",
      "4605/2800 (epoch 82), train_loss = 9.156, time/batch = 0.022\n",
      "4606/2800 (epoch 82), train_loss = 9.804, time/batch = 0.016\n",
      "4607/2800 (epoch 82), train_loss = 8.885, time/batch = 0.016\n",
      "4608/2800 (epoch 82), train_loss = 9.843, time/batch = 0.016\n",
      "4609/2800 (epoch 82), train_loss = 8.991, time/batch = 0.016\n",
      "4610/2800 (epoch 82), train_loss = 9.213, time/batch = 0.020\n",
      "4611/2800 (epoch 82), train_loss = 9.283, time/batch = 0.002\n",
      "4612/2800 (epoch 82), train_loss = 9.295, time/batch = 0.031\n",
      "4613/2800 (epoch 82), train_loss = 9.594, time/batch = 0.016\n",
      "4614/2800 (epoch 82), train_loss = 9.583, time/batch = 0.016\n",
      "4615/2800 (epoch 82), train_loss = 9.481, time/batch = 0.031\n",
      "4616/2800 (epoch 82), train_loss = 9.590, time/batch = 0.007\n",
      "4617/2800 (epoch 82), train_loss = 9.519, time/batch = 0.016\n",
      "4618/2800 (epoch 82), train_loss = 9.763, time/batch = 0.031\n",
      "4619/2800 (epoch 82), train_loss = 9.189, time/batch = 0.016\n",
      "4620/2800 (epoch 82), train_loss = 9.306, time/batch = 0.016\n",
      "4621/2800 (epoch 82), train_loss = 9.287, time/batch = 0.022\n",
      "4622/2800 (epoch 82), train_loss = 10.056, time/batch = 0.016\n",
      "4623/2800 (epoch 82), train_loss = 9.485, time/batch = 0.016\n",
      "4624/2800 (epoch 82), train_loss = 9.703, time/batch = 0.047\n",
      "4625/2800 (epoch 82), train_loss = 9.274, time/batch = 0.022\n",
      "4626/2800 (epoch 82), train_loss = 9.409, time/batch = 0.016\n",
      "4627/2800 (epoch 82), train_loss = 9.275, time/batch = 0.031\n",
      "4628/2800 (epoch 82), train_loss = 10.866, time/batch = 0.016\n",
      "4629/2800 (epoch 82), train_loss = 10.826, time/batch = 0.016\n",
      "4630/2800 (epoch 82), train_loss = 10.879, time/batch = 0.022\n",
      "4631/2800 (epoch 82), train_loss = 10.430, time/batch = 0.016\n",
      "4632/2800 (epoch 82), train_loss = 10.569, time/batch = 0.016\n",
      "4633/2800 (epoch 82), train_loss = 10.263, time/batch = 0.016\n",
      "4634/2800 (epoch 82), train_loss = 10.789, time/batch = 0.016\n",
      "4635/2800 (epoch 82), train_loss = 10.279, time/batch = 0.016\n",
      "4636/2800 (epoch 82), train_loss = 11.046, time/batch = 0.022\n",
      "4637/2800 (epoch 82), train_loss = 9.966, time/batch = 0.016\n",
      "4638/2800 (epoch 82), train_loss = 11.594, time/batch = 0.016\n",
      "4639/2800 (epoch 82), train_loss = 10.250, time/batch = 0.000\n",
      "4640/2800 (epoch 82), train_loss = 10.012, time/batch = 0.016\n",
      "4641/2800 (epoch 82), train_loss = 10.816, time/batch = 0.016\n",
      "4642/2800 (epoch 82), train_loss = 10.729, time/batch = 0.016\n",
      "4643/2800 (epoch 82), train_loss = 10.088, time/batch = 0.020\n",
      "4644/2800 (epoch 82), train_loss = 10.086, time/batch = 0.001\n",
      "4645/2800 (epoch 82), train_loss = 9.918, time/batch = 0.016\n",
      "4646/2800 (epoch 82), train_loss = 10.485, time/batch = 0.016\n",
      "4647/2800 (epoch 82), train_loss = 10.117, time/batch = 0.016\n",
      "4648/2800 (epoch 83), train_loss = 9.590, time/batch = 0.016\n",
      "4649/2800 (epoch 83), train_loss = 9.970, time/batch = 0.016\n",
      "4650/2800 (epoch 83), train_loss = 9.908, time/batch = 0.000\n",
      "4651/2800 (epoch 83), train_loss = 9.262, time/batch = 0.023\n",
      "4652/2800 (epoch 83), train_loss = 10.015, time/batch = 0.000\n",
      "4653/2800 (epoch 83), train_loss = 9.185, time/batch = 0.016\n",
      "4654/2800 (epoch 83), train_loss = 10.080, time/batch = 0.031\n",
      "4655/2800 (epoch 83), train_loss = 9.249, time/batch = 0.016\n",
      "4656/2800 (epoch 83), train_loss = 9.557, time/batch = 0.016\n",
      "4657/2800 (epoch 83), train_loss = 9.516, time/batch = 0.018\n",
      "4658/2800 (epoch 83), train_loss = 9.200, time/batch = 0.004\n",
      "4659/2800 (epoch 83), train_loss = 9.392, time/batch = 0.016\n",
      "4660/2800 (epoch 83), train_loss = 9.314, time/batch = 0.016\n",
      "4661/2800 (epoch 83), train_loss = 9.008, time/batch = 0.016\n",
      "4662/2800 (epoch 83), train_loss = 9.170, time/batch = 0.016\n",
      "4663/2800 (epoch 83), train_loss = 9.001, time/batch = 0.016\n",
      "4664/2800 (epoch 83), train_loss = 9.716, time/batch = 0.017\n",
      "4665/2800 (epoch 83), train_loss = 8.888, time/batch = 0.005\n",
      "4666/2800 (epoch 83), train_loss = 9.310, time/batch = 0.016\n",
      "4667/2800 (epoch 83), train_loss = 9.059, time/batch = 0.016\n",
      "4668/2800 (epoch 83), train_loss = 10.437, time/batch = 0.016\n",
      "4669/2800 (epoch 83), train_loss = 9.030, time/batch = 0.016\n",
      "4670/2800 (epoch 83), train_loss = 9.581, time/batch = 0.016\n",
      "4671/2800 (epoch 83), train_loss = 9.859, time/batch = 0.022\n",
      "4672/2800 (epoch 83), train_loss = 9.988, time/batch = 0.000\n",
      "4673/2800 (epoch 83), train_loss = 9.439, time/batch = 0.016\n",
      "4674/2800 (epoch 83), train_loss = 9.566, time/batch = 0.016\n",
      "4675/2800 (epoch 83), train_loss = 9.346, time/batch = 0.016\n",
      "4676/2800 (epoch 83), train_loss = 9.438, time/batch = 0.016\n",
      "4677/2800 (epoch 83), train_loss = 9.508, time/batch = 0.016\n",
      "4678/2800 (epoch 83), train_loss = 10.101, time/batch = 0.020\n",
      "4679/2800 (epoch 83), train_loss = 9.492, time/batch = 0.002\n",
      "4680/2800 (epoch 83), train_loss = 9.362, time/batch = 0.016\n",
      "4681/2800 (epoch 83), train_loss = 9.425, time/batch = 0.016\n",
      "4682/2800 (epoch 83), train_loss = 9.768, time/batch = 0.016\n",
      "4683/2800 (epoch 83), train_loss = 9.547, time/batch = 0.000\n",
      "4684/2800 (epoch 83), train_loss = 11.146, time/batch = 0.016\n",
      "4685/2800 (epoch 83), train_loss = 10.349, time/batch = 0.000\n",
      "4686/2800 (epoch 83), train_loss = 10.721, time/batch = 0.022\n",
      "4687/2800 (epoch 83), train_loss = 10.472, time/batch = 0.016\n",
      "4688/2800 (epoch 83), train_loss = 10.542, time/batch = 0.016\n",
      "4689/2800 (epoch 83), train_loss = 10.422, time/batch = 0.016\n",
      "4690/2800 (epoch 83), train_loss = 10.379, time/batch = 0.016\n",
      "4691/2800 (epoch 83), train_loss = 10.639, time/batch = 0.000\n",
      "4692/2800 (epoch 83), train_loss = 10.520, time/batch = 0.016\n",
      "4693/2800 (epoch 83), train_loss = 10.692, time/batch = 0.022\n",
      "4694/2800 (epoch 83), train_loss = 10.280, time/batch = 0.016\n",
      "4695/2800 (epoch 83), train_loss = 10.271, time/batch = 0.016\n",
      "4696/2800 (epoch 83), train_loss = 10.435, time/batch = 0.000\n",
      "4697/2800 (epoch 83), train_loss = 11.190, time/batch = 0.016\n",
      "4698/2800 (epoch 83), train_loss = 10.243, time/batch = 0.016\n",
      "4699/2800 (epoch 83), train_loss = 10.182, time/batch = 0.016\n",
      "4700/2800 (epoch 83), train_loss = 10.208, time/batch = 0.022\n",
      "4701/2800 (epoch 83), train_loss = 10.148, time/batch = 0.000\n",
      "4702/2800 (epoch 83), train_loss = 10.079, time/batch = 0.016\n",
      "4703/2800 (epoch 83), train_loss = 10.264, time/batch = 0.016\n",
      "4704/2800 (epoch 84), train_loss = 9.642, time/batch = 0.016\n",
      "4705/2800 (epoch 84), train_loss = 9.364, time/batch = 0.016\n",
      "4706/2800 (epoch 84), train_loss = 9.254, time/batch = 0.016\n",
      "4707/2800 (epoch 84), train_loss = 9.718, time/batch = 0.018\n",
      "4708/2800 (epoch 84), train_loss = 9.158, time/batch = 0.004\n",
      "4709/2800 (epoch 84), train_loss = 9.539, time/batch = 0.016\n",
      "4710/2800 (epoch 84), train_loss = 9.091, time/batch = 0.016\n",
      "4711/2800 (epoch 84), train_loss = 9.597, time/batch = 0.016\n",
      "4712/2800 (epoch 84), train_loss = 8.949, time/batch = 0.016\n",
      "4713/2800 (epoch 84), train_loss = 9.314, time/batch = 0.016\n",
      "4714/2800 (epoch 84), train_loss = 9.419, time/batch = 0.022\n",
      "4715/2800 (epoch 84), train_loss = 9.343, time/batch = 0.000\n",
      "4716/2800 (epoch 84), train_loss = 9.533, time/batch = 0.016\n",
      "4717/2800 (epoch 84), train_loss = 9.207, time/batch = 0.016\n",
      "4718/2800 (epoch 84), train_loss = 9.188, time/batch = 0.016\n",
      "4719/2800 (epoch 84), train_loss = 9.309, time/batch = 0.016\n",
      "4720/2800 (epoch 84), train_loss = 9.155, time/batch = 0.016\n",
      "4721/2800 (epoch 84), train_loss = 9.216, time/batch = 0.021\n",
      "4722/2800 (epoch 84), train_loss = 9.241, time/batch = 0.000\n",
      "4723/2800 (epoch 84), train_loss = 9.304, time/batch = 0.016\n",
      "4724/2800 (epoch 84), train_loss = 8.813, time/batch = 0.016\n",
      "4725/2800 (epoch 84), train_loss = 9.851, time/batch = 0.016\n",
      "4726/2800 (epoch 84), train_loss = 10.002, time/batch = 0.016\n",
      "4727/2800 (epoch 84), train_loss = 9.430, time/batch = 0.016\n",
      "4728/2800 (epoch 84), train_loss = 9.763, time/batch = 0.022\n",
      "4729/2800 (epoch 84), train_loss = 9.660, time/batch = 0.016\n",
      "4730/2800 (epoch 84), train_loss = 9.270, time/batch = 0.016\n",
      "4731/2800 (epoch 84), train_loss = 9.313, time/batch = 0.000\n",
      "4732/2800 (epoch 84), train_loss = 10.394, time/batch = 0.016\n",
      "4733/2800 (epoch 84), train_loss = 9.639, time/batch = 0.016\n",
      "4734/2800 (epoch 84), train_loss = 9.740, time/batch = 0.016\n",
      "4735/2800 (epoch 84), train_loss = 9.207, time/batch = 0.022\n",
      "4736/2800 (epoch 84), train_loss = 10.214, time/batch = 0.016\n",
      "4737/2800 (epoch 84), train_loss = 10.142, time/batch = 0.000\n",
      "4738/2800 (epoch 84), train_loss = 11.457, time/batch = 0.016\n",
      "4739/2800 (epoch 84), train_loss = 10.403, time/batch = 0.016\n",
      "4740/2800 (epoch 84), train_loss = 10.564, time/batch = 0.016\n",
      "4741/2800 (epoch 84), train_loss = 10.365, time/batch = 0.016\n",
      "4742/2800 (epoch 84), train_loss = 10.402, time/batch = 0.022\n",
      "4743/2800 (epoch 84), train_loss = 10.277, time/batch = 0.000\n",
      "4744/2800 (epoch 84), train_loss = 10.884, time/batch = 0.016\n",
      "4745/2800 (epoch 84), train_loss = 10.680, time/batch = 0.016\n",
      "4746/2800 (epoch 84), train_loss = 10.397, time/batch = 0.016\n",
      "4747/2800 (epoch 84), train_loss = 10.277, time/batch = 0.016\n",
      "4748/2800 (epoch 84), train_loss = 10.678, time/batch = 0.016\n",
      "4749/2800 (epoch 84), train_loss = 10.058, time/batch = 0.018\n",
      "4750/2800 (epoch 84), train_loss = 10.533, time/batch = 0.004\n",
      "4751/2800 (epoch 84), train_loss = 10.026, time/batch = 0.016\n",
      "4752/2800 (epoch 84), train_loss = 10.891, time/batch = 0.016\n",
      "4753/2800 (epoch 84), train_loss = 10.021, time/batch = 0.016\n",
      "4754/2800 (epoch 84), train_loss = 10.533, time/batch = 0.016\n",
      "4755/2800 (epoch 84), train_loss = 9.992, time/batch = 0.016\n",
      "4756/2800 (epoch 84), train_loss = 10.496, time/batch = 0.019\n",
      "4757/2800 (epoch 84), train_loss = 9.746, time/batch = 0.003\n",
      "4758/2800 (epoch 84), train_loss = 9.215, time/batch = 0.016\n",
      "4759/2800 (epoch 84), train_loss = 10.647, time/batch = 0.016\n",
      "4760/2800 (epoch 85), train_loss = 9.053, time/batch = 0.016\n",
      "4761/2800 (epoch 85), train_loss = 10.100, time/batch = 0.016\n",
      "4762/2800 (epoch 85), train_loss = 8.585, time/batch = 0.016\n",
      "4763/2800 (epoch 85), train_loss = 9.849, time/batch = 0.019\n",
      "4764/2800 (epoch 85), train_loss = 9.000, time/batch = 0.003\n",
      "4765/2800 (epoch 85), train_loss = 9.750, time/batch = 0.016\n",
      "4766/2800 (epoch 85), train_loss = 9.208, time/batch = 0.016\n",
      "4767/2800 (epoch 85), train_loss = 10.111, time/batch = 0.016\n",
      "4768/2800 (epoch 85), train_loss = 9.271, time/batch = 0.016\n",
      "4769/2800 (epoch 85), train_loss = 10.045, time/batch = 0.016\n",
      "4770/2800 (epoch 85), train_loss = 9.151, time/batch = 0.022\n",
      "4771/2800 (epoch 85), train_loss = 9.738, time/batch = 0.000\n",
      "4772/2800 (epoch 85), train_loss = 8.944, time/batch = 0.016\n",
      "4773/2800 (epoch 85), train_loss = 10.899, time/batch = 0.016\n",
      "4774/2800 (epoch 85), train_loss = 8.814, time/batch = 0.016\n",
      "4775/2800 (epoch 85), train_loss = 9.131, time/batch = 0.016\n",
      "4776/2800 (epoch 85), train_loss = 9.956, time/batch = 0.016\n",
      "4777/2800 (epoch 85), train_loss = 9.021, time/batch = 0.020\n",
      "4778/2800 (epoch 85), train_loss = 9.347, time/batch = 0.002\n",
      "4779/2800 (epoch 85), train_loss = 8.948, time/batch = 0.016\n",
      "4780/2800 (epoch 85), train_loss = 9.460, time/batch = 0.016\n",
      "4781/2800 (epoch 85), train_loss = 9.105, time/batch = 0.016\n",
      "4782/2800 (epoch 85), train_loss = 9.459, time/batch = 0.016\n",
      "4783/2800 (epoch 85), train_loss = 9.257, time/batch = 0.016\n",
      "4784/2800 (epoch 85), train_loss = 10.519, time/batch = 0.020\n",
      "4785/2800 (epoch 85), train_loss = 9.473, time/batch = 0.017\n",
      "4786/2800 (epoch 85), train_loss = 9.721, time/batch = 0.000\n",
      "4787/2800 (epoch 85), train_loss = 9.609, time/batch = 0.016\n",
      "4788/2800 (epoch 85), train_loss = 9.893, time/batch = 0.016\n",
      "4789/2800 (epoch 85), train_loss = 9.272, time/batch = 0.016\n",
      "4790/2800 (epoch 85), train_loss = 9.642, time/batch = 0.016\n",
      "4791/2800 (epoch 85), train_loss = 10.000, time/batch = 0.021\n",
      "4792/2800 (epoch 85), train_loss = 9.587, time/batch = 0.001\n",
      "4793/2800 (epoch 85), train_loss = 9.689, time/batch = 0.016\n",
      "4794/2800 (epoch 85), train_loss = 9.558, time/batch = 0.016\n",
      "4795/2800 (epoch 85), train_loss = 9.463, time/batch = 0.016\n",
      "4796/2800 (epoch 85), train_loss = 9.565, time/batch = 0.016\n",
      "4797/2800 (epoch 85), train_loss = 9.339, time/batch = 0.016\n",
      "4798/2800 (epoch 85), train_loss = 10.882, time/batch = 0.017\n",
      "4799/2800 (epoch 85), train_loss = 10.998, time/batch = 0.006\n",
      "4800/2800 (epoch 85), train_loss = 10.729, time/batch = 0.016\n",
      "4801/2800 (epoch 85), train_loss = 10.392, time/batch = 0.016\n",
      "4802/2800 (epoch 85), train_loss = 10.620, time/batch = 0.016\n",
      "4803/2800 (epoch 85), train_loss = 10.123, time/batch = 0.016\n",
      "4804/2800 (epoch 85), train_loss = 10.660, time/batch = 0.016\n",
      "4805/2800 (epoch 85), train_loss = 10.304, time/batch = 0.016\n",
      "4806/2800 (epoch 85), train_loss = 11.048, time/batch = 0.006\n",
      "4807/2800 (epoch 85), train_loss = 10.159, time/batch = 0.016\n",
      "4808/2800 (epoch 85), train_loss = 10.629, time/batch = 0.016\n",
      "4809/2800 (epoch 85), train_loss = 10.450, time/batch = 0.016\n",
      "4810/2800 (epoch 85), train_loss = 10.663, time/batch = 0.016\n",
      "4811/2800 (epoch 85), train_loss = 10.316, time/batch = 0.000\n",
      "4812/2800 (epoch 85), train_loss = 10.458, time/batch = 0.016\n",
      "4813/2800 (epoch 85), train_loss = 10.295, time/batch = 0.022\n",
      "4814/2800 (epoch 85), train_loss = 9.879, time/batch = 0.000\n",
      "4815/2800 (epoch 85), train_loss = 11.324, time/batch = 0.016\n",
      "4816/2800 (epoch 86), train_loss = 9.423, time/batch = 0.016\n",
      "4817/2800 (epoch 86), train_loss = 9.017, time/batch = 0.016\n",
      "4818/2800 (epoch 86), train_loss = 9.369, time/batch = 0.016\n",
      "4819/2800 (epoch 86), train_loss = 9.385, time/batch = 0.016\n",
      "4820/2800 (epoch 86), train_loss = 8.915, time/batch = 0.021\n",
      "4821/2800 (epoch 86), train_loss = 11.544, time/batch = 0.001\n",
      "4822/2800 (epoch 86), train_loss = 8.741, time/batch = 0.016\n",
      "4823/2800 (epoch 86), train_loss = 11.472, time/batch = 0.016\n",
      "4824/2800 (epoch 86), train_loss = 8.720, time/batch = 0.016\n",
      "4825/2800 (epoch 86), train_loss = 11.144, time/batch = 0.016\n",
      "4826/2800 (epoch 86), train_loss = 8.760, time/batch = 0.016\n",
      "4827/2800 (epoch 86), train_loss = 9.893, time/batch = 0.021\n",
      "4828/2800 (epoch 86), train_loss = 9.003, time/batch = 0.016\n",
      "4829/2800 (epoch 86), train_loss = 11.077, time/batch = 0.016\n",
      "4830/2800 (epoch 86), train_loss = 8.929, time/batch = 0.016\n",
      "4831/2800 (epoch 86), train_loss = 10.390, time/batch = 0.016\n",
      "4832/2800 (epoch 86), train_loss = 8.727, time/batch = 0.016\n",
      "4833/2800 (epoch 86), train_loss = 9.824, time/batch = 0.022\n",
      "4834/2800 (epoch 86), train_loss = 8.853, time/batch = 0.000\n",
      "4835/2800 (epoch 86), train_loss = 9.883, time/batch = 0.016\n",
      "4836/2800 (epoch 86), train_loss = 8.801, time/batch = 0.016\n",
      "4837/2800 (epoch 86), train_loss = 9.827, time/batch = 0.016\n",
      "4838/2800 (epoch 86), train_loss = 8.828, time/batch = 0.016\n",
      "4839/2800 (epoch 86), train_loss = 10.637, time/batch = 0.016\n",
      "4840/2800 (epoch 86), train_loss = 8.886, time/batch = 0.020\n",
      "4841/2800 (epoch 86), train_loss = 11.128, time/batch = 0.001\n",
      "4842/2800 (epoch 86), train_loss = 9.586, time/batch = 0.031\n",
      "4843/2800 (epoch 86), train_loss = 10.066, time/batch = 0.016\n",
      "4844/2800 (epoch 86), train_loss = 9.393, time/batch = 0.016\n",
      "4845/2800 (epoch 86), train_loss = 9.778, time/batch = 0.000\n",
      "4846/2800 (epoch 86), train_loss = 9.326, time/batch = 0.016\n",
      "4847/2800 (epoch 86), train_loss = 10.133, time/batch = 0.023\n",
      "4848/2800 (epoch 86), train_loss = 9.417, time/batch = 0.016\n",
      "4849/2800 (epoch 86), train_loss = 10.105, time/batch = 0.016\n",
      "4850/2800 (epoch 86), train_loss = 9.602, time/batch = 0.016\n",
      "4851/2800 (epoch 86), train_loss = 9.690, time/batch = 0.016\n",
      "4852/2800 (epoch 86), train_loss = 9.394, time/batch = 0.016\n",
      "4853/2800 (epoch 86), train_loss = 9.444, time/batch = 0.000\n",
      "4854/2800 (epoch 86), train_loss = 10.417, time/batch = 0.022\n",
      "4855/2800 (epoch 86), train_loss = 11.143, time/batch = 0.016\n",
      "4856/2800 (epoch 86), train_loss = 10.632, time/batch = 0.016\n",
      "4857/2800 (epoch 86), train_loss = 10.607, time/batch = 0.016\n",
      "4858/2800 (epoch 86), train_loss = 10.324, time/batch = 0.016\n",
      "4859/2800 (epoch 86), train_loss = 10.291, time/batch = 0.016\n",
      "4860/2800 (epoch 86), train_loss = 10.663, time/batch = 0.017\n",
      "4861/2800 (epoch 86), train_loss = 10.342, time/batch = 0.005\n",
      "4862/2800 (epoch 86), train_loss = 10.645, time/batch = 0.016\n",
      "4863/2800 (epoch 86), train_loss = 10.336, time/batch = 0.016\n",
      "4864/2800 (epoch 86), train_loss = 10.278, time/batch = 0.000\n",
      "4865/2800 (epoch 86), train_loss = 10.460, time/batch = 0.016\n",
      "4866/2800 (epoch 86), train_loss = 11.366, time/batch = 0.016\n",
      "4867/2800 (epoch 86), train_loss = 10.059, time/batch = 0.016\n",
      "4868/2800 (epoch 86), train_loss = 10.345, time/batch = 0.022\n",
      "4869/2800 (epoch 86), train_loss = 10.175, time/batch = 0.016\n",
      "4870/2800 (epoch 86), train_loss = 10.440, time/batch = 0.000\n",
      "4871/2800 (epoch 86), train_loss = 10.328, time/batch = 0.016\n",
      "4872/2800 (epoch 87), train_loss = 9.718, time/batch = 0.016\n",
      "4873/2800 (epoch 87), train_loss = 9.716, time/batch = 0.016\n",
      "4874/2800 (epoch 87), train_loss = 9.265, time/batch = 0.016\n",
      "4875/2800 (epoch 87), train_loss = 10.066, time/batch = 0.018\n",
      "4876/2800 (epoch 87), train_loss = 9.042, time/batch = 0.004\n",
      "4877/2800 (epoch 87), train_loss = 10.125, time/batch = 0.016\n",
      "4878/2800 (epoch 87), train_loss = 9.063, time/batch = 0.016\n",
      "4879/2800 (epoch 87), train_loss = 10.101, time/batch = 0.016\n",
      "4880/2800 (epoch 87), train_loss = 9.179, time/batch = 0.000\n",
      "4881/2800 (epoch 87), train_loss = 8.957, time/batch = 0.016\n",
      "4882/2800 (epoch 87), train_loss = 9.391, time/batch = 0.016\n",
      "4883/2800 (epoch 87), train_loss = 9.695, time/batch = 0.022\n",
      "4884/2800 (epoch 87), train_loss = 9.006, time/batch = 0.000\n",
      "4885/2800 (epoch 87), train_loss = 9.909, time/batch = 0.016\n",
      "4886/2800 (epoch 87), train_loss = 9.539, time/batch = 0.016\n",
      "4887/2800 (epoch 87), train_loss = 8.974, time/batch = 0.016\n",
      "4888/2800 (epoch 87), train_loss = 9.149, time/batch = 0.016\n",
      "4889/2800 (epoch 87), train_loss = 9.917, time/batch = 0.016\n",
      "4890/2800 (epoch 87), train_loss = 8.875, time/batch = 0.020\n",
      "4891/2800 (epoch 87), train_loss = 9.707, time/batch = 0.001\n",
      "4892/2800 (epoch 87), train_loss = 9.011, time/batch = 0.016\n",
      "4893/2800 (epoch 87), train_loss = 10.090, time/batch = 0.016\n",
      "4894/2800 (epoch 87), train_loss = 8.872, time/batch = 0.016\n",
      "4895/2800 (epoch 87), train_loss = 9.284, time/batch = 0.016\n",
      "4896/2800 (epoch 87), train_loss = 9.532, time/batch = 0.000\n",
      "4897/2800 (epoch 87), train_loss = 9.924, time/batch = 0.016\n",
      "4898/2800 (epoch 87), train_loss = 9.258, time/batch = 0.022\n",
      "4899/2800 (epoch 87), train_loss = 9.616, time/batch = 0.016\n",
      "4900/2800 (epoch 87), train_loss = 9.602, time/batch = 0.000\n",
      "4901/2800 (epoch 87), train_loss = 8.957, time/batch = 0.016\n",
      "4902/2800 (epoch 87), train_loss = 9.240, time/batch = 0.016\n",
      "4903/2800 (epoch 87), train_loss = 10.480, time/batch = 0.016\n",
      "4904/2800 (epoch 87), train_loss = 9.736, time/batch = 0.016\n",
      "4905/2800 (epoch 87), train_loss = 9.996, time/batch = 0.019\n",
      "4906/2800 (epoch 87), train_loss = 9.286, time/batch = 0.002\n",
      "4907/2800 (epoch 87), train_loss = 9.603, time/batch = 0.016\n",
      "4908/2800 (epoch 87), train_loss = 9.416, time/batch = 0.016\n",
      "4909/2800 (epoch 87), train_loss = 9.655, time/batch = 0.016\n",
      "4910/2800 (epoch 87), train_loss = 11.381, time/batch = 0.016\n",
      "4911/2800 (epoch 87), train_loss = 10.595, time/batch = 0.000\n",
      "4912/2800 (epoch 87), train_loss = 10.748, time/batch = 0.016\n",
      "4913/2800 (epoch 87), train_loss = 10.627, time/batch = 0.022\n",
      "4914/2800 (epoch 87), train_loss = 10.386, time/batch = 0.000\n",
      "4915/2800 (epoch 87), train_loss = 10.261, time/batch = 0.016\n",
      "4916/2800 (epoch 87), train_loss = 10.504, time/batch = 0.016\n",
      "4917/2800 (epoch 87), train_loss = 10.421, time/batch = 0.016\n",
      "4918/2800 (epoch 87), train_loss = 10.686, time/batch = 0.016\n",
      "4919/2800 (epoch 87), train_loss = 10.446, time/batch = 0.016\n",
      "4920/2800 (epoch 87), train_loss = 11.126, time/batch = 0.021\n",
      "4921/2800 (epoch 87), train_loss = 10.254, time/batch = 0.000\n",
      "4922/2800 (epoch 87), train_loss = 10.458, time/batch = 0.016\n",
      "4923/2800 (epoch 87), train_loss = 10.383, time/batch = 0.016\n",
      "4924/2800 (epoch 87), train_loss = 10.364, time/batch = 0.016\n",
      "4925/2800 (epoch 87), train_loss = 10.082, time/batch = 0.016\n",
      "4926/2800 (epoch 87), train_loss = 9.932, time/batch = 0.000\n",
      "4927/2800 (epoch 87), train_loss = 10.028, time/batch = 0.016\n",
      "4928/2800 (epoch 88), train_loss = 9.522, time/batch = 0.022\n",
      "4929/2800 (epoch 88), train_loss = 10.289, time/batch = 0.016\n",
      "4930/2800 (epoch 88), train_loss = 9.125, time/batch = 0.000\n",
      "4931/2800 (epoch 88), train_loss = 10.515, time/batch = 0.000\n",
      "4932/2800 (epoch 88), train_loss = 9.168, time/batch = 0.016\n",
      "4933/2800 (epoch 88), train_loss = 10.205, time/batch = 0.016\n",
      "4934/2800 (epoch 88), train_loss = 8.929, time/batch = 0.016\n",
      "4935/2800 (epoch 88), train_loss = 10.178, time/batch = 0.017\n",
      "4936/2800 (epoch 88), train_loss = 9.000, time/batch = 0.004\n",
      "4937/2800 (epoch 88), train_loss = 10.301, time/batch = 0.016\n",
      "4938/2800 (epoch 88), train_loss = 9.356, time/batch = 0.016\n",
      "4939/2800 (epoch 88), train_loss = 10.290, time/batch = 0.016\n",
      "4940/2800 (epoch 88), train_loss = 9.121, time/batch = 0.000\n",
      "4941/2800 (epoch 88), train_loss = 9.778, time/batch = 0.016\n",
      "4942/2800 (epoch 88), train_loss = 9.189, time/batch = 0.016\n",
      "4943/2800 (epoch 88), train_loss = 9.705, time/batch = 0.022\n",
      "4944/2800 (epoch 88), train_loss = 9.208, time/batch = 0.000\n",
      "4945/2800 (epoch 88), train_loss = 9.518, time/batch = 0.016\n",
      "4946/2800 (epoch 88), train_loss = 9.239, time/batch = 0.016\n",
      "4947/2800 (epoch 88), train_loss = 9.016, time/batch = 0.031\n",
      "4948/2800 (epoch 88), train_loss = 9.454, time/batch = 0.016\n",
      "4949/2800 (epoch 88), train_loss = 9.108, time/batch = 0.000\n",
      "4950/2800 (epoch 88), train_loss = 9.118, time/batch = 0.022\n",
      "4951/2800 (epoch 88), train_loss = 9.165, time/batch = 0.016\n",
      "4952/2800 (epoch 88), train_loss = 9.725, time/batch = 0.016\n",
      "4953/2800 (epoch 88), train_loss = 9.798, time/batch = 0.000\n",
      "4954/2800 (epoch 88), train_loss = 9.638, time/batch = 0.016\n",
      "4955/2800 (epoch 88), train_loss = 9.813, time/batch = 0.016\n",
      "4956/2800 (epoch 88), train_loss = 9.424, time/batch = 0.016\n",
      "4957/2800 (epoch 88), train_loss = 9.652, time/batch = 0.018\n",
      "4958/2800 (epoch 88), train_loss = 9.394, time/batch = 0.004\n",
      "4959/2800 (epoch 88), train_loss = 9.759, time/batch = 0.016\n",
      "4960/2800 (epoch 88), train_loss = 9.483, time/batch = 0.016\n",
      "4961/2800 (epoch 88), train_loss = 9.684, time/batch = 0.000\n",
      "4962/2800 (epoch 88), train_loss = 9.319, time/batch = 0.016\n",
      "4963/2800 (epoch 88), train_loss = 9.480, time/batch = 0.016\n",
      "4964/2800 (epoch 88), train_loss = 10.730, time/batch = 0.016\n",
      "4965/2800 (epoch 88), train_loss = 11.236, time/batch = 0.022\n",
      "4966/2800 (epoch 88), train_loss = 10.213, time/batch = 0.000\n",
      "4967/2800 (epoch 88), train_loss = 11.582, time/batch = 0.016\n",
      "4968/2800 (epoch 88), train_loss = 10.364, time/batch = 0.016\n",
      "4969/2800 (epoch 88), train_loss = 10.773, time/batch = 0.016\n",
      "4970/2800 (epoch 88), train_loss = 10.286, time/batch = 0.016\n",
      "4971/2800 (epoch 88), train_loss = 10.938, time/batch = 0.016\n",
      "4972/2800 (epoch 88), train_loss = 10.200, time/batch = 0.000\n",
      "4973/2800 (epoch 88), train_loss = 11.060, time/batch = 0.022\n",
      "4974/2800 (epoch 88), train_loss = 9.980, time/batch = 0.016\n",
      "4975/2800 (epoch 88), train_loss = 10.841, time/batch = 0.016\n",
      "4976/2800 (epoch 88), train_loss = 10.308, time/batch = 0.016\n",
      "4977/2800 (epoch 88), train_loss = 10.087, time/batch = 0.016\n",
      "4978/2800 (epoch 88), train_loss = 10.678, time/batch = 0.016\n",
      "4979/2800 (epoch 88), train_loss = 10.533, time/batch = 0.019\n",
      "4980/2800 (epoch 88), train_loss = 10.037, time/batch = 0.003\n",
      "4981/2800 (epoch 88), train_loss = 10.676, time/batch = 0.016\n",
      "4982/2800 (epoch 88), train_loss = 9.779, time/batch = 0.016\n",
      "4983/2800 (epoch 88), train_loss = 10.196, time/batch = 0.016\n",
      "4984/2800 (epoch 89), train_loss = 9.456, time/batch = 0.000\n",
      "4985/2800 (epoch 89), train_loss = 9.663, time/batch = 0.016\n",
      "4986/2800 (epoch 89), train_loss = 9.047, time/batch = 0.016\n",
      "4987/2800 (epoch 89), train_loss = 11.703, time/batch = 0.022\n",
      "4988/2800 (epoch 89), train_loss = 9.022, time/batch = 0.000\n",
      "4989/2800 (epoch 89), train_loss = 10.924, time/batch = 0.016\n",
      "4990/2800 (epoch 89), train_loss = 8.908, time/batch = 0.016\n",
      "4991/2800 (epoch 89), train_loss = 10.759, time/batch = 0.016\n",
      "4992/2800 (epoch 89), train_loss = 8.834, time/batch = 0.016\n",
      "4993/2800 (epoch 89), train_loss = 10.682, time/batch = 0.000\n",
      "4994/2800 (epoch 89), train_loss = 9.005, time/batch = 0.000\n",
      "4995/2800 (epoch 89), train_loss = 10.240, time/batch = 0.022\n",
      "4996/2800 (epoch 89), train_loss = 9.135, time/batch = 0.016\n",
      "4997/2800 (epoch 89), train_loss = 9.904, time/batch = 0.016\n",
      "4998/2800 (epoch 89), train_loss = 9.238, time/batch = 0.000\n",
      "4999/2800 (epoch 89), train_loss = 9.648, time/batch = 0.016\n",
      "5000/2800 (epoch 89), train_loss = 9.085, time/batch = 0.016\n",
      "model saved to save\\model.ckpt\n",
      "5001/2800 (epoch 89), train_loss = 9.832, time/batch = 0.031\n",
      "5002/2800 (epoch 89), train_loss = 8.762, time/batch = 0.032\n",
      "5003/2800 (epoch 89), train_loss = 9.791, time/batch = 0.021\n",
      "5004/2800 (epoch 89), train_loss = 9.443, time/batch = 0.031\n",
      "5005/2800 (epoch 89), train_loss = 10.005, time/batch = 0.031\n",
      "5006/2800 (epoch 89), train_loss = 9.558, time/batch = 0.022\n",
      "5007/2800 (epoch 89), train_loss = 9.531, time/batch = 0.047\n",
      "5008/2800 (epoch 89), train_loss = 9.379, time/batch = 0.031\n",
      "5009/2800 (epoch 89), train_loss = 10.726, time/batch = 0.037\n",
      "5010/2800 (epoch 89), train_loss = 9.411, time/batch = 0.031\n",
      "5011/2800 (epoch 89), train_loss = 9.683, time/batch = 0.031\n",
      "5012/2800 (epoch 89), train_loss = 9.774, time/batch = 0.037\n",
      "5013/2800 (epoch 89), train_loss = 9.784, time/batch = 0.031\n",
      "5014/2800 (epoch 89), train_loss = 9.287, time/batch = 0.038\n",
      "5015/2800 (epoch 89), train_loss = 9.836, time/batch = 0.031\n",
      "5016/2800 (epoch 89), train_loss = 9.172, time/batch = 0.031\n",
      "5017/2800 (epoch 89), train_loss = 9.760, time/batch = 0.053\n",
      "5018/2800 (epoch 89), train_loss = 9.475, time/batch = 0.031\n",
      "5019/2800 (epoch 89), train_loss = 10.951, time/batch = 0.055\n",
      "5020/2800 (epoch 89), train_loss = 10.531, time/batch = 0.043\n",
      "5021/2800 (epoch 89), train_loss = 10.727, time/batch = 0.043\n",
      "5022/2800 (epoch 89), train_loss = 10.329, time/batch = 0.034\n",
      "5023/2800 (epoch 89), train_loss = 10.635, time/batch = 0.038\n",
      "5024/2800 (epoch 89), train_loss = 10.231, time/batch = 0.037\n",
      "5025/2800 (epoch 89), train_loss = 10.529, time/batch = 0.043\n",
      "5026/2800 (epoch 89), train_loss = 10.141, time/batch = 0.044\n",
      "5027/2800 (epoch 89), train_loss = 11.100, time/batch = 0.052\n",
      "5028/2800 (epoch 89), train_loss = 10.482, time/batch = 0.035\n",
      "5029/2800 (epoch 89), train_loss = 10.505, time/batch = 0.036\n",
      "5030/2800 (epoch 89), train_loss = 10.693, time/batch = 0.035\n",
      "5031/2800 (epoch 89), train_loss = 11.088, time/batch = 0.030\n",
      "5032/2800 (epoch 89), train_loss = 10.304, time/batch = 0.031\n",
      "5033/2800 (epoch 89), train_loss = 10.598, time/batch = 0.031\n",
      "5034/2800 (epoch 89), train_loss = 9.934, time/batch = 0.038\n",
      "5035/2800 (epoch 89), train_loss = 10.186, time/batch = 0.031\n",
      "5036/2800 (epoch 89), train_loss = 9.808, time/batch = 0.031\n",
      "5037/2800 (epoch 89), train_loss = 12.767, time/batch = 0.038\n",
      "5038/2800 (epoch 89), train_loss = 10.429, time/batch = 0.031\n",
      "5039/2800 (epoch 89), train_loss = 10.037, time/batch = 0.031\n",
      "5040/2800 (epoch 90), train_loss = 10.161, time/batch = 0.037\n",
      "5041/2800 (epoch 90), train_loss = 9.315, time/batch = 0.031\n",
      "5042/2800 (epoch 90), train_loss = 9.171, time/batch = 0.016\n",
      "5043/2800 (epoch 90), train_loss = 10.272, time/batch = 0.038\n",
      "5044/2800 (epoch 90), train_loss = 9.142, time/batch = 0.031\n",
      "5045/2800 (epoch 90), train_loss = 9.764, time/batch = 0.031\n",
      "5046/2800 (epoch 90), train_loss = 9.001, time/batch = 0.038\n",
      "5047/2800 (epoch 90), train_loss = 9.972, time/batch = 0.031\n",
      "5048/2800 (epoch 90), train_loss = 8.830, time/batch = 0.031\n",
      "5049/2800 (epoch 90), train_loss = 9.592, time/batch = 0.037\n",
      "5050/2800 (epoch 90), train_loss = 9.527, time/batch = 0.016\n",
      "5051/2800 (epoch 90), train_loss = 10.780, time/batch = 0.031\n",
      "5052/2800 (epoch 90), train_loss = 8.836, time/batch = 0.031\n",
      "5053/2800 (epoch 90), train_loss = 10.279, time/batch = 0.022\n",
      "5054/2800 (epoch 90), train_loss = 9.317, time/batch = 0.016\n",
      "5055/2800 (epoch 90), train_loss = 9.677, time/batch = 0.031\n",
      "5056/2800 (epoch 90), train_loss = 8.983, time/batch = 0.031\n",
      "5057/2800 (epoch 90), train_loss = 9.860, time/batch = 0.038\n",
      "5058/2800 (epoch 90), train_loss = 8.945, time/batch = 0.016\n",
      "5059/2800 (epoch 90), train_loss = 9.015, time/batch = 0.032\n",
      "5060/2800 (epoch 90), train_loss = 9.182, time/batch = 0.026\n",
      "5061/2800 (epoch 90), train_loss = 10.368, time/batch = 0.011\n",
      "5062/2800 (epoch 90), train_loss = 9.437, time/batch = 0.031\n",
      "5063/2800 (epoch 90), train_loss = 9.371, time/batch = 0.016\n",
      "5064/2800 (epoch 90), train_loss = 9.227, time/batch = 0.031\n",
      "5065/2800 (epoch 90), train_loss = 9.360, time/batch = 0.022\n",
      "5066/2800 (epoch 90), train_loss = 9.478, time/batch = 0.031\n",
      "5067/2800 (epoch 90), train_loss = 9.427, time/batch = 0.016\n",
      "5068/2800 (epoch 90), train_loss = 9.592, time/batch = 0.016\n",
      "5069/2800 (epoch 90), train_loss = 9.992, time/batch = 0.038\n",
      "5070/2800 (epoch 90), train_loss = 9.034, time/batch = 0.016\n",
      "5071/2800 (epoch 90), train_loss = 9.384, time/batch = 0.047\n",
      "5072/2800 (epoch 90), train_loss = 9.524, time/batch = 0.016\n",
      "5073/2800 (epoch 90), train_loss = 9.581, time/batch = 0.039\n",
      "5074/2800 (epoch 90), train_loss = 10.000, time/batch = 0.024\n",
      "5075/2800 (epoch 90), train_loss = 11.152, time/batch = 0.023\n",
      "5076/2800 (epoch 90), train_loss = 10.696, time/batch = 0.023\n",
      "5077/2800 (epoch 90), train_loss = 10.661, time/batch = 0.024\n",
      "5078/2800 (epoch 90), train_loss = 10.601, time/batch = 0.021\n",
      "5079/2800 (epoch 90), train_loss = 10.454, time/batch = 0.022\n",
      "5080/2800 (epoch 90), train_loss = 10.077, time/batch = 0.023\n",
      "5081/2800 (epoch 90), train_loss = 10.625, time/batch = 0.022\n",
      "5082/2800 (epoch 90), train_loss = 10.377, time/batch = 0.021\n",
      "5083/2800 (epoch 90), train_loss = 10.918, time/batch = 0.020\n",
      "5084/2800 (epoch 90), train_loss = 10.108, time/batch = 0.021\n",
      "5085/2800 (epoch 90), train_loss = 11.236, time/batch = 0.022\n",
      "5086/2800 (epoch 90), train_loss = 10.228, time/batch = 0.023\n",
      "5087/2800 (epoch 90), train_loss = 10.027, time/batch = 0.026\n",
      "5088/2800 (epoch 90), train_loss = 10.376, time/batch = 0.019\n",
      "5089/2800 (epoch 90), train_loss = 10.186, time/batch = 0.029\n",
      "5090/2800 (epoch 90), train_loss = 10.438, time/batch = 0.023\n",
      "5091/2800 (epoch 90), train_loss = 10.213, time/batch = 0.023\n",
      "5092/2800 (epoch 90), train_loss = 10.529, time/batch = 0.023\n",
      "5093/2800 (epoch 90), train_loss = 9.857, time/batch = 0.019\n",
      "5094/2800 (epoch 90), train_loss = 11.653, time/batch = 0.022\n",
      "5095/2800 (epoch 90), train_loss = 9.670, time/batch = 0.024\n",
      "5096/2800 (epoch 91), train_loss = 9.504, time/batch = 0.022\n",
      "5097/2800 (epoch 91), train_loss = 8.728, time/batch = 0.025\n",
      "5098/2800 (epoch 91), train_loss = 9.817, time/batch = 0.020\n",
      "5099/2800 (epoch 91), train_loss = 9.474, time/batch = 0.022\n",
      "5100/2800 (epoch 91), train_loss = 9.596, time/batch = 0.023\n",
      "5101/2800 (epoch 91), train_loss = 9.718, time/batch = 0.022\n",
      "5102/2800 (epoch 91), train_loss = 9.307, time/batch = 0.023\n",
      "5103/2800 (epoch 91), train_loss = 9.532, time/batch = 0.022\n",
      "5104/2800 (epoch 91), train_loss = 9.627, time/batch = 0.018\n",
      "5105/2800 (epoch 91), train_loss = 8.918, time/batch = 0.016\n",
      "5106/2800 (epoch 91), train_loss = 9.948, time/batch = 0.016\n",
      "5107/2800 (epoch 91), train_loss = 9.520, time/batch = 0.016\n",
      "5108/2800 (epoch 91), train_loss = 9.714, time/batch = 0.016\n",
      "5109/2800 (epoch 91), train_loss = 8.708, time/batch = 0.038\n",
      "5110/2800 (epoch 91), train_loss = 9.147, time/batch = 0.016\n",
      "5111/2800 (epoch 91), train_loss = 9.691, time/batch = 0.016\n",
      "5112/2800 (epoch 91), train_loss = 11.576, time/batch = 0.016\n",
      "5113/2800 (epoch 91), train_loss = 8.797, time/batch = 0.031\n",
      "5114/2800 (epoch 91), train_loss = 10.298, time/batch = 0.022\n",
      "5115/2800 (epoch 91), train_loss = 9.212, time/batch = 0.016\n",
      "5116/2800 (epoch 91), train_loss = 10.335, time/batch = 0.016\n",
      "5117/2800 (epoch 91), train_loss = 9.177, time/batch = 0.016\n",
      "5118/2800 (epoch 91), train_loss = 9.338, time/batch = 0.031\n",
      "5119/2800 (epoch 91), train_loss = 10.025, time/batch = 0.022\n",
      "5120/2800 (epoch 91), train_loss = 9.314, time/batch = 0.016\n",
      "5121/2800 (epoch 91), train_loss = 9.709, time/batch = 0.016\n",
      "5122/2800 (epoch 91), train_loss = 9.581, time/batch = 0.016\n",
      "5123/2800 (epoch 91), train_loss = 9.954, time/batch = 0.031\n",
      "5124/2800 (epoch 91), train_loss = 9.128, time/batch = 0.022\n",
      "5125/2800 (epoch 91), train_loss = 10.069, time/batch = 0.016\n",
      "5126/2800 (epoch 91), train_loss = 9.248, time/batch = 0.016\n",
      "5127/2800 (epoch 91), train_loss = 10.121, time/batch = 0.016\n",
      "5128/2800 (epoch 91), train_loss = 9.386, time/batch = 0.031\n",
      "5129/2800 (epoch 91), train_loss = 9.789, time/batch = 0.022\n",
      "5130/2800 (epoch 91), train_loss = 9.095, time/batch = 0.016\n",
      "5131/2800 (epoch 91), train_loss = 10.607, time/batch = 0.016\n",
      "5132/2800 (epoch 91), train_loss = 11.407, time/batch = 0.016\n",
      "5133/2800 (epoch 91), train_loss = 10.795, time/batch = 0.016\n",
      "5134/2800 (epoch 91), train_loss = 11.191, time/batch = 0.016\n",
      "5135/2800 (epoch 91), train_loss = 10.318, time/batch = 0.000\n",
      "5136/2800 (epoch 91), train_loss = 10.541, time/batch = 0.022\n",
      "5137/2800 (epoch 91), train_loss = 10.131, time/batch = 0.016\n",
      "5138/2800 (epoch 91), train_loss = 10.725, time/batch = 0.016\n",
      "5139/2800 (epoch 91), train_loss = 10.284, time/batch = 0.016\n",
      "5140/2800 (epoch 91), train_loss = 10.827, time/batch = 0.016\n",
      "5141/2800 (epoch 91), train_loss = 10.115, time/batch = 0.000\n",
      "5142/2800 (epoch 91), train_loss = 11.237, time/batch = 0.016\n",
      "5143/2800 (epoch 91), train_loss = 10.164, time/batch = 0.022\n",
      "5144/2800 (epoch 91), train_loss = 10.392, time/batch = 0.000\n",
      "5145/2800 (epoch 91), train_loss = 10.249, time/batch = 0.016\n",
      "5146/2800 (epoch 91), train_loss = 10.286, time/batch = 0.016\n",
      "5147/2800 (epoch 91), train_loss = 10.399, time/batch = 0.016\n",
      "5148/2800 (epoch 91), train_loss = 9.992, time/batch = 0.016\n",
      "5149/2800 (epoch 91), train_loss = 11.176, time/batch = 0.016\n",
      "5150/2800 (epoch 91), train_loss = 9.913, time/batch = 0.016\n",
      "5151/2800 (epoch 91), train_loss = 11.133, time/batch = 0.006\n",
      "5152/2800 (epoch 92), train_loss = 9.516, time/batch = 0.016\n",
      "5153/2800 (epoch 92), train_loss = 9.810, time/batch = 0.000\n",
      "5154/2800 (epoch 92), train_loss = 9.323, time/batch = 0.016\n",
      "5155/2800 (epoch 92), train_loss = 9.591, time/batch = 0.016\n",
      "5156/2800 (epoch 92), train_loss = 9.656, time/batch = 0.016\n",
      "5157/2800 (epoch 92), train_loss = 9.602, time/batch = 0.016\n",
      "5158/2800 (epoch 92), train_loss = 9.870, time/batch = 0.023\n",
      "5159/2800 (epoch 92), train_loss = 9.612, time/batch = 0.016\n",
      "5160/2800 (epoch 92), train_loss = 9.022, time/batch = 0.016\n",
      "5161/2800 (epoch 92), train_loss = 9.636, time/batch = 0.000\n",
      "5162/2800 (epoch 92), train_loss = 9.568, time/batch = 0.016\n",
      "5163/2800 (epoch 92), train_loss = 9.267, time/batch = 0.016\n",
      "5164/2800 (epoch 92), train_loss = 9.868, time/batch = 0.016\n",
      "5165/2800 (epoch 92), train_loss = 9.562, time/batch = 0.021\n",
      "5166/2800 (epoch 92), train_loss = 9.546, time/batch = 0.000\n",
      "5167/2800 (epoch 92), train_loss = 9.134, time/batch = 0.016\n",
      "5168/2800 (epoch 92), train_loss = 9.447, time/batch = 0.016\n",
      "5169/2800 (epoch 92), train_loss = 9.539, time/batch = 0.016\n",
      "5170/2800 (epoch 92), train_loss = 9.159, time/batch = 0.000\n",
      "5171/2800 (epoch 92), train_loss = 9.116, time/batch = 0.016\n",
      "5172/2800 (epoch 92), train_loss = 9.873, time/batch = 0.016\n",
      "5173/2800 (epoch 92), train_loss = 9.888, time/batch = 0.022\n",
      "5174/2800 (epoch 92), train_loss = 9.812, time/batch = 0.016\n",
      "5175/2800 (epoch 92), train_loss = 9.451, time/batch = 0.000\n",
      "5176/2800 (epoch 92), train_loss = 10.001, time/batch = 0.016\n",
      "5177/2800 (epoch 92), train_loss = 9.661, time/batch = 0.016\n",
      "5178/2800 (epoch 92), train_loss = 9.313, time/batch = 0.016\n",
      "5179/2800 (epoch 92), train_loss = 9.331, time/batch = 0.016\n",
      "5180/2800 (epoch 92), train_loss = 9.902, time/batch = 0.018\n",
      "5181/2800 (epoch 92), train_loss = 9.525, time/batch = 0.004\n",
      "5182/2800 (epoch 92), train_loss = 10.282, time/batch = 0.016\n",
      "5183/2800 (epoch 92), train_loss = 9.220, time/batch = 0.016\n",
      "5184/2800 (epoch 92), train_loss = 9.801, time/batch = 0.016\n",
      "5185/2800 (epoch 92), train_loss = 10.127, time/batch = 0.016\n",
      "5186/2800 (epoch 92), train_loss = 11.148, time/batch = 0.000\n",
      "5187/2800 (epoch 92), train_loss = 10.560, time/batch = 0.016\n",
      "5188/2800 (epoch 92), train_loss = 11.195, time/batch = 0.022\n",
      "5189/2800 (epoch 92), train_loss = 10.311, time/batch = 0.016\n",
      "5190/2800 (epoch 92), train_loss = 10.679, time/batch = 0.000\n",
      "5191/2800 (epoch 92), train_loss = 10.143, time/batch = 0.016\n",
      "5192/2800 (epoch 92), train_loss = 10.695, time/batch = 0.016\n",
      "5193/2800 (epoch 92), train_loss = 10.218, time/batch = 0.016\n",
      "5194/2800 (epoch 92), train_loss = 11.303, time/batch = 0.016\n",
      "5195/2800 (epoch 92), train_loss = 10.305, time/batch = 0.018\n",
      "5196/2800 (epoch 92), train_loss = 10.735, time/batch = 0.004\n",
      "5197/2800 (epoch 92), train_loss = 10.351, time/batch = 0.016\n",
      "5198/2800 (epoch 92), train_loss = 10.529, time/batch = 0.016\n",
      "5199/2800 (epoch 92), train_loss = 10.275, time/batch = 0.016\n",
      "5200/2800 (epoch 92), train_loss = 11.974, time/batch = 0.016\n",
      "5201/2800 (epoch 92), train_loss = 9.891, time/batch = 0.016\n",
      "5202/2800 (epoch 92), train_loss = 11.216, time/batch = 0.016\n",
      "5203/2800 (epoch 92), train_loss = 9.807, time/batch = 0.006\n",
      "5204/2800 (epoch 92), train_loss = 11.480, time/batch = 0.016\n",
      "5205/2800 (epoch 92), train_loss = 10.082, time/batch = 0.000\n",
      "5206/2800 (epoch 92), train_loss = 9.787, time/batch = 0.016\n",
      "5207/2800 (epoch 92), train_loss = 9.615, time/batch = 0.016\n",
      "5208/2800 (epoch 93), train_loss = 9.275, time/batch = 0.016\n",
      "5209/2800 (epoch 93), train_loss = 9.767, time/batch = 0.016\n",
      "5210/2800 (epoch 93), train_loss = 9.612, time/batch = 0.018\n",
      "5211/2800 (epoch 93), train_loss = 9.647, time/batch = 0.004\n",
      "5212/2800 (epoch 93), train_loss = 9.454, time/batch = 0.016\n",
      "5213/2800 (epoch 93), train_loss = 9.499, time/batch = 0.016\n",
      "5214/2800 (epoch 93), train_loss = 9.457, time/batch = 0.000\n",
      "5215/2800 (epoch 93), train_loss = 9.563, time/batch = 0.016\n",
      "5216/2800 (epoch 93), train_loss = 9.425, time/batch = 0.016\n",
      "5217/2800 (epoch 93), train_loss = 9.118, time/batch = 0.016\n",
      "5218/2800 (epoch 93), train_loss = 9.725, time/batch = 0.022\n",
      "5219/2800 (epoch 93), train_loss = 10.179, time/batch = 0.016\n",
      "5220/2800 (epoch 93), train_loss = 9.244, time/batch = 0.000\n",
      "5221/2800 (epoch 93), train_loss = 9.511, time/batch = 0.016\n",
      "5222/2800 (epoch 93), train_loss = 9.551, time/batch = 0.016\n",
      "5223/2800 (epoch 93), train_loss = 9.436, time/batch = 0.016\n",
      "5224/2800 (epoch 93), train_loss = 9.343, time/batch = 0.016\n",
      "5225/2800 (epoch 93), train_loss = 9.446, time/batch = 0.017\n",
      "5226/2800 (epoch 93), train_loss = 9.503, time/batch = 0.005\n",
      "5227/2800 (epoch 93), train_loss = 9.031, time/batch = 0.016\n",
      "5228/2800 (epoch 93), train_loss = 9.014, time/batch = 0.016\n",
      "5229/2800 (epoch 93), train_loss = 9.752, time/batch = 0.016\n",
      "5230/2800 (epoch 93), train_loss = 9.678, time/batch = 0.000\n",
      "5231/2800 (epoch 93), train_loss = 9.672, time/batch = 0.016\n",
      "5232/2800 (epoch 93), train_loss = 9.497, time/batch = 0.016\n",
      "5233/2800 (epoch 93), train_loss = 9.900, time/batch = 0.022\n",
      "5234/2800 (epoch 93), train_loss = 9.191, time/batch = 0.000\n",
      "5235/2800 (epoch 93), train_loss = 9.386, time/batch = 0.016\n",
      "5236/2800 (epoch 93), train_loss = 9.633, time/batch = 0.016\n",
      "5237/2800 (epoch 93), train_loss = 9.674, time/batch = 0.016\n",
      "5238/2800 (epoch 93), train_loss = 9.283, time/batch = 0.016\n",
      "5239/2800 (epoch 93), train_loss = 9.479, time/batch = 0.016\n",
      "5240/2800 (epoch 93), train_loss = 9.442, time/batch = 0.000\n",
      "5241/2800 (epoch 93), train_loss = 9.619, time/batch = 0.022\n",
      "5242/2800 (epoch 93), train_loss = 10.381, time/batch = 0.016\n",
      "5243/2800 (epoch 93), train_loss = 9.647, time/batch = 0.000\n",
      "5244/2800 (epoch 93), train_loss = 10.584, time/batch = 0.016\n",
      "5245/2800 (epoch 93), train_loss = 11.094, time/batch = 0.016\n",
      "5246/2800 (epoch 93), train_loss = 10.646, time/batch = 0.016\n",
      "5247/2800 (epoch 93), train_loss = 10.695, time/batch = 0.016\n",
      "5248/2800 (epoch 93), train_loss = 10.241, time/batch = 0.020\n",
      "5249/2800 (epoch 93), train_loss = 10.482, time/batch = 0.001\n",
      "5250/2800 (epoch 93), train_loss = 10.074, time/batch = 0.016\n",
      "5251/2800 (epoch 93), train_loss = 11.006, time/batch = 0.016\n",
      "5252/2800 (epoch 93), train_loss = 10.268, time/batch = 0.016\n",
      "5253/2800 (epoch 93), train_loss = 10.407, time/batch = 0.016\n",
      "5254/2800 (epoch 93), train_loss = 10.485, time/batch = 0.000\n",
      "5255/2800 (epoch 93), train_loss = 10.974, time/batch = 0.016\n",
      "5256/2800 (epoch 93), train_loss = 9.988, time/batch = 0.023\n",
      "5257/2800 (epoch 93), train_loss = 11.170, time/batch = 0.000\n",
      "5258/2800 (epoch 93), train_loss = 11.055, time/batch = 0.016\n",
      "5259/2800 (epoch 93), train_loss = 10.224, time/batch = 0.016\n",
      "5260/2800 (epoch 93), train_loss = 10.017, time/batch = 0.016\n",
      "5261/2800 (epoch 93), train_loss = 9.807, time/batch = 0.016\n",
      "5262/2800 (epoch 93), train_loss = 11.338, time/batch = 0.016\n",
      "5263/2800 (epoch 93), train_loss = 10.310, time/batch = 0.000\n",
      "5264/2800 (epoch 94), train_loss = 9.842, time/batch = 0.022\n",
      "5265/2800 (epoch 94), train_loss = 10.048, time/batch = 0.016\n",
      "5266/2800 (epoch 94), train_loss = 9.795, time/batch = 0.016\n",
      "5267/2800 (epoch 94), train_loss = 9.583, time/batch = 0.000\n",
      "5268/2800 (epoch 94), train_loss = 9.977, time/batch = 0.016\n",
      "5269/2800 (epoch 94), train_loss = 9.394, time/batch = 0.016\n",
      "5270/2800 (epoch 94), train_loss = 9.973, time/batch = 0.016\n",
      "5271/2800 (epoch 94), train_loss = 9.589, time/batch = 0.018\n",
      "5272/2800 (epoch 94), train_loss = 9.516, time/batch = 0.005\n",
      "5273/2800 (epoch 94), train_loss = 9.603, time/batch = 0.016\n",
      "5274/2800 (epoch 94), train_loss = 9.853, time/batch = 0.016\n",
      "5275/2800 (epoch 94), train_loss = 9.224, time/batch = 0.000\n",
      "5276/2800 (epoch 94), train_loss = 9.659, time/batch = 0.000\n",
      "5277/2800 (epoch 94), train_loss = 9.144, time/batch = 0.016\n",
      "5278/2800 (epoch 94), train_loss = 10.051, time/batch = 0.016\n",
      "5279/2800 (epoch 94), train_loss = 9.221, time/batch = 0.022\n",
      "5280/2800 (epoch 94), train_loss = 9.758, time/batch = 0.000\n",
      "5281/2800 (epoch 94), train_loss = 9.176, time/batch = 0.016\n",
      "5282/2800 (epoch 94), train_loss = 9.200, time/batch = 0.016\n",
      "5283/2800 (epoch 94), train_loss = 9.186, time/batch = 0.016\n",
      "5284/2800 (epoch 94), train_loss = 9.520, time/batch = 0.016\n",
      "5285/2800 (epoch 94), train_loss = 9.337, time/batch = 0.016\n",
      "5286/2800 (epoch 94), train_loss = 9.661, time/batch = 0.000\n",
      "5287/2800 (epoch 94), train_loss = 9.326, time/batch = 0.022\n",
      "5288/2800 (epoch 94), train_loss = 9.672, time/batch = 0.016\n",
      "5289/2800 (epoch 94), train_loss = 10.452, time/batch = 0.016\n",
      "5290/2800 (epoch 94), train_loss = 9.659, time/batch = 0.016\n",
      "5291/2800 (epoch 94), train_loss = 9.447, time/batch = 0.016\n",
      "5292/2800 (epoch 94), train_loss = 9.740, time/batch = 0.016\n",
      "5293/2800 (epoch 94), train_loss = 9.748, time/batch = 0.000\n",
      "5294/2800 (epoch 94), train_loss = 9.321, time/batch = 0.022\n",
      "5295/2800 (epoch 94), train_loss = 9.765, time/batch = 0.016\n",
      "5296/2800 (epoch 94), train_loss = 9.486, time/batch = 0.016\n",
      "5297/2800 (epoch 94), train_loss = 9.825, time/batch = 0.016\n",
      "5298/2800 (epoch 94), train_loss = 9.481, time/batch = 0.000\n",
      "5299/2800 (epoch 94), train_loss = 9.249, time/batch = 0.016\n",
      "5300/2800 (epoch 94), train_loss = 9.680, time/batch = 0.016\n",
      "5301/2800 (epoch 94), train_loss = 11.463, time/batch = 0.022\n",
      "5302/2800 (epoch 94), train_loss = 10.628, time/batch = 0.000\n",
      "5303/2800 (epoch 94), train_loss = 10.736, time/batch = 0.016\n",
      "5304/2800 (epoch 94), train_loss = 10.499, time/batch = 0.016\n",
      "5305/2800 (epoch 94), train_loss = 10.627, time/batch = 0.016\n",
      "5306/2800 (epoch 94), train_loss = 10.201, time/batch = 0.016\n",
      "5307/2800 (epoch 94), train_loss = 10.674, time/batch = 0.016\n",
      "5308/2800 (epoch 94), train_loss = 10.485, time/batch = 0.000\n",
      "5309/2800 (epoch 94), train_loss = 10.671, time/batch = 0.006\n",
      "5310/2800 (epoch 94), train_loss = 10.127, time/batch = 0.016\n",
      "5311/2800 (epoch 94), train_loss = 10.798, time/batch = 0.000\n",
      "5312/2800 (epoch 94), train_loss = 10.138, time/batch = 0.016\n",
      "5313/2800 (epoch 94), train_loss = 11.243, time/batch = 0.016\n",
      "5314/2800 (epoch 94), train_loss = 10.237, time/batch = 0.016\n",
      "5315/2800 (epoch 94), train_loss = 10.541, time/batch = 0.016\n",
      "5316/2800 (epoch 94), train_loss = 10.590, time/batch = 0.018\n",
      "5317/2800 (epoch 94), train_loss = 10.216, time/batch = 0.004\n",
      "5318/2800 (epoch 94), train_loss = 10.500, time/batch = 0.016\n",
      "5319/2800 (epoch 94), train_loss = 10.051, time/batch = 0.016\n",
      "5320/2800 (epoch 95), train_loss = 10.434, time/batch = 0.000\n",
      "5321/2800 (epoch 95), train_loss = 9.497, time/batch = 0.016\n",
      "5322/2800 (epoch 95), train_loss = 9.121, time/batch = 0.016\n",
      "5323/2800 (epoch 95), train_loss = 9.849, time/batch = 0.016\n",
      "5324/2800 (epoch 95), train_loss = 8.875, time/batch = 0.022\n",
      "5325/2800 (epoch 95), train_loss = 9.854, time/batch = 0.016\n",
      "5326/2800 (epoch 95), train_loss = 9.687, time/batch = 0.016\n",
      "5327/2800 (epoch 95), train_loss = 10.262, time/batch = 0.000\n",
      "5328/2800 (epoch 95), train_loss = 9.471, time/batch = 0.016\n",
      "5329/2800 (epoch 95), train_loss = 10.010, time/batch = 0.016\n",
      "5330/2800 (epoch 95), train_loss = 9.362, time/batch = 0.016\n",
      "5331/2800 (epoch 95), train_loss = 9.705, time/batch = 0.022\n",
      "5332/2800 (epoch 95), train_loss = 9.165, time/batch = 0.016\n",
      "5333/2800 (epoch 95), train_loss = 10.315, time/batch = 0.000\n",
      "5334/2800 (epoch 95), train_loss = 8.912, time/batch = 0.016\n",
      "5335/2800 (epoch 95), train_loss = 10.740, time/batch = 0.016\n",
      "5336/2800 (epoch 95), train_loss = 9.131, time/batch = 0.016\n",
      "5337/2800 (epoch 95), train_loss = 9.742, time/batch = 0.016\n",
      "5338/2800 (epoch 95), train_loss = 9.260, time/batch = 0.019\n",
      "5339/2800 (epoch 95), train_loss = 9.730, time/batch = 0.003\n",
      "5340/2800 (epoch 95), train_loss = 8.970, time/batch = 0.016\n",
      "5341/2800 (epoch 95), train_loss = 9.665, time/batch = 0.016\n",
      "5342/2800 (epoch 95), train_loss = 9.437, time/batch = 0.016\n",
      "5343/2800 (epoch 95), train_loss = 9.826, time/batch = 0.016\n",
      "5344/2800 (epoch 95), train_loss = 9.569, time/batch = 0.000\n",
      "5345/2800 (epoch 95), train_loss = 10.017, time/batch = 0.016\n",
      "5346/2800 (epoch 95), train_loss = 9.384, time/batch = 0.023\n",
      "5347/2800 (epoch 95), train_loss = 9.792, time/batch = 0.000\n",
      "5348/2800 (epoch 95), train_loss = 9.254, time/batch = 0.016\n",
      "5349/2800 (epoch 95), train_loss = 9.691, time/batch = 0.016\n",
      "5350/2800 (epoch 95), train_loss = 9.708, time/batch = 0.016\n",
      "5351/2800 (epoch 95), train_loss = 10.290, time/batch = 0.016\n",
      "5352/2800 (epoch 95), train_loss = 9.403, time/batch = 0.016\n",
      "5353/2800 (epoch 95), train_loss = 9.977, time/batch = 0.017\n",
      "5354/2800 (epoch 95), train_loss = 9.252, time/batch = 0.005\n",
      "5355/2800 (epoch 95), train_loss = 9.541, time/batch = 0.016\n",
      "5356/2800 (epoch 95), train_loss = 9.087, time/batch = 0.016\n",
      "5357/2800 (epoch 95), train_loss = 10.084, time/batch = 0.016\n",
      "5358/2800 (epoch 95), train_loss = 11.559, time/batch = 0.000\n",
      "5359/2800 (epoch 95), train_loss = 10.916, time/batch = 0.016\n",
      "5360/2800 (epoch 95), train_loss = 10.709, time/batch = 0.016\n",
      "5361/2800 (epoch 95), train_loss = 11.230, time/batch = 0.022\n",
      "5362/2800 (epoch 95), train_loss = 10.091, time/batch = 0.000\n",
      "5363/2800 (epoch 95), train_loss = 10.709, time/batch = 0.016\n",
      "5364/2800 (epoch 95), train_loss = 10.270, time/batch = 0.016\n",
      "5365/2800 (epoch 95), train_loss = 10.824, time/batch = 0.016\n",
      "5366/2800 (epoch 95), train_loss = 10.353, time/batch = 0.016\n",
      "5367/2800 (epoch 95), train_loss = 10.690, time/batch = 0.016\n",
      "5368/2800 (epoch 95), train_loss = 10.359, time/batch = 0.016\n",
      "5369/2800 (epoch 95), train_loss = 10.515, time/batch = 0.006\n",
      "5370/2800 (epoch 95), train_loss = 10.024, time/batch = 0.016\n",
      "5371/2800 (epoch 95), train_loss = 10.891, time/batch = 0.016\n",
      "5372/2800 (epoch 95), train_loss = 10.257, time/batch = 0.016\n",
      "5373/2800 (epoch 95), train_loss = 10.005, time/batch = 0.000\n",
      "5374/2800 (epoch 95), train_loss = 10.729, time/batch = 0.016\n",
      "5375/2800 (epoch 95), train_loss = 10.049, time/batch = 0.016\n",
      "5376/2800 (epoch 96), train_loss = 10.189, time/batch = 0.022\n",
      "5377/2800 (epoch 96), train_loss = 9.432, time/batch = 0.016\n",
      "5378/2800 (epoch 96), train_loss = 9.541, time/batch = 0.016\n",
      "5379/2800 (epoch 96), train_loss = 9.809, time/batch = 0.000\n",
      "5380/2800 (epoch 96), train_loss = 9.416, time/batch = 0.016\n",
      "5381/2800 (epoch 96), train_loss = 9.859, time/batch = 0.016\n",
      "5382/2800 (epoch 96), train_loss = 9.370, time/batch = 0.016\n",
      "5383/2800 (epoch 96), train_loss = 9.938, time/batch = 0.020\n",
      "5384/2800 (epoch 96), train_loss = 9.351, time/batch = 0.002\n",
      "5385/2800 (epoch 96), train_loss = 9.681, time/batch = 0.016\n",
      "5386/2800 (epoch 96), train_loss = 9.115, time/batch = 0.016\n",
      "5387/2800 (epoch 96), train_loss = 10.051, time/batch = 0.016\n",
      "5388/2800 (epoch 96), train_loss = 9.328, time/batch = 0.016\n",
      "5389/2800 (epoch 96), train_loss = 10.050, time/batch = 0.016\n",
      "5390/2800 (epoch 96), train_loss = 10.135, time/batch = 0.000\n",
      "5391/2800 (epoch 96), train_loss = 9.161, time/batch = 0.023\n",
      "5392/2800 (epoch 96), train_loss = 9.693, time/batch = 0.016\n",
      "5393/2800 (epoch 96), train_loss = 9.066, time/batch = 0.000\n",
      "5394/2800 (epoch 96), train_loss = 9.751, time/batch = 0.000\n",
      "5395/2800 (epoch 96), train_loss = 9.376, time/batch = 0.016\n",
      "5396/2800 (epoch 96), train_loss = 9.999, time/batch = 0.016\n",
      "5397/2800 (epoch 96), train_loss = 9.488, time/batch = 0.016\n",
      "5398/2800 (epoch 96), train_loss = 8.942, time/batch = 0.019\n",
      "5399/2800 (epoch 96), train_loss = 10.093, time/batch = 0.002\n",
      "5400/2800 (epoch 96), train_loss = 9.647, time/batch = 0.016\n",
      "5401/2800 (epoch 96), train_loss = 9.316, time/batch = 0.016\n",
      "5402/2800 (epoch 96), train_loss = 10.362, time/batch = 0.016\n",
      "5403/2800 (epoch 96), train_loss = 9.893, time/batch = 0.016\n",
      "5404/2800 (epoch 96), train_loss = 9.224, time/batch = 0.016\n",
      "5405/2800 (epoch 96), train_loss = 9.433, time/batch = 0.000\n",
      "5406/2800 (epoch 96), train_loss = 9.491, time/batch = 0.006\n",
      "5407/2800 (epoch 96), train_loss = 9.793, time/batch = 0.016\n",
      "5408/2800 (epoch 96), train_loss = 9.782, time/batch = 0.000\n",
      "5409/2800 (epoch 96), train_loss = 9.551, time/batch = 0.016\n",
      "5410/2800 (epoch 96), train_loss = 9.325, time/batch = 0.016\n",
      "5411/2800 (epoch 96), train_loss = 9.440, time/batch = 0.016\n",
      "5412/2800 (epoch 96), train_loss = 9.574, time/batch = 0.016\n",
      "5413/2800 (epoch 96), train_loss = 11.541, time/batch = 0.019\n",
      "5414/2800 (epoch 96), train_loss = 10.799, time/batch = 0.003\n",
      "5415/2800 (epoch 96), train_loss = 10.980, time/batch = 0.016\n",
      "5416/2800 (epoch 96), train_loss = 10.510, time/batch = 0.016\n",
      "5417/2800 (epoch 96), train_loss = 10.453, time/batch = 0.016\n",
      "5418/2800 (epoch 96), train_loss = 10.186, time/batch = 0.016\n",
      "5419/2800 (epoch 96), train_loss = 10.625, time/batch = 0.016\n",
      "5420/2800 (epoch 96), train_loss = 10.162, time/batch = 0.022\n",
      "5421/2800 (epoch 96), train_loss = 10.837, time/batch = 0.016\n",
      "5422/2800 (epoch 96), train_loss = 10.147, time/batch = 0.000\n",
      "5423/2800 (epoch 96), train_loss = 10.520, time/batch = 0.016\n",
      "5424/2800 (epoch 96), train_loss = 10.427, time/batch = 0.016\n",
      "5425/2800 (epoch 96), train_loss = 11.775, time/batch = 0.016\n",
      "5426/2800 (epoch 96), train_loss = 10.150, time/batch = 0.016\n",
      "5427/2800 (epoch 96), train_loss = 10.504, time/batch = 0.000\n",
      "5428/2800 (epoch 96), train_loss = 10.504, time/batch = 0.022\n",
      "5429/2800 (epoch 96), train_loss = 10.323, time/batch = 0.016\n",
      "5430/2800 (epoch 96), train_loss = 10.126, time/batch = 0.016\n",
      "5431/2800 (epoch 96), train_loss = 9.805, time/batch = 0.016\n",
      "5432/2800 (epoch 97), train_loss = 9.840, time/batch = 0.000\n",
      "5433/2800 (epoch 97), train_loss = 9.401, time/batch = 0.016\n",
      "5434/2800 (epoch 97), train_loss = 9.361, time/batch = 0.016\n",
      "5435/2800 (epoch 97), train_loss = 10.433, time/batch = 0.021\n",
      "5436/2800 (epoch 97), train_loss = 9.176, time/batch = 0.000\n",
      "5437/2800 (epoch 97), train_loss = 10.835, time/batch = 0.016\n",
      "5438/2800 (epoch 97), train_loss = 9.049, time/batch = 0.016\n",
      "5439/2800 (epoch 97), train_loss = 11.473, time/batch = 0.016\n",
      "5440/2800 (epoch 97), train_loss = 8.953, time/batch = 0.016\n",
      "5441/2800 (epoch 97), train_loss = 12.684, time/batch = 0.000\n",
      "5442/2800 (epoch 97), train_loss = 9.427, time/batch = 0.016\n",
      "5443/2800 (epoch 97), train_loss = 10.039, time/batch = 0.022\n",
      "5444/2800 (epoch 97), train_loss = 9.024, time/batch = 0.016\n",
      "5445/2800 (epoch 97), train_loss = 10.305, time/batch = 0.016\n",
      "5446/2800 (epoch 97), train_loss = 9.102, time/batch = 0.016\n",
      "5447/2800 (epoch 97), train_loss = 9.922, time/batch = 0.016\n",
      "5448/2800 (epoch 97), train_loss = 9.273, time/batch = 0.000\n",
      "5449/2800 (epoch 97), train_loss = 9.659, time/batch = 0.000\n",
      "5450/2800 (epoch 97), train_loss = 9.004, time/batch = 0.022\n",
      "5451/2800 (epoch 97), train_loss = 9.208, time/batch = 0.000\n",
      "5452/2800 (epoch 97), train_loss = 9.134, time/batch = 0.016\n",
      "5453/2800 (epoch 97), train_loss = 9.264, time/batch = 0.016\n",
      "5454/2800 (epoch 97), train_loss = 9.672, time/batch = 0.016\n",
      "5455/2800 (epoch 97), train_loss = 9.350, time/batch = 0.016\n",
      "5456/2800 (epoch 97), train_loss = 9.779, time/batch = 0.016\n",
      "5457/2800 (epoch 97), train_loss = 9.736, time/batch = 0.000\n",
      "5458/2800 (epoch 97), train_loss = 9.735, time/batch = 0.022\n",
      "5459/2800 (epoch 97), train_loss = 9.628, time/batch = 0.016\n",
      "5460/2800 (epoch 97), train_loss = 9.335, time/batch = 0.000\n",
      "5461/2800 (epoch 97), train_loss = 9.945, time/batch = 0.016\n",
      "5462/2800 (epoch 97), train_loss = 9.652, time/batch = 0.016\n",
      "5463/2800 (epoch 97), train_loss = 10.079, time/batch = 0.016\n",
      "5464/2800 (epoch 97), train_loss = 9.057, time/batch = 0.016\n",
      "5465/2800 (epoch 97), train_loss = 9.395, time/batch = 0.022\n",
      "5466/2800 (epoch 97), train_loss = 9.967, time/batch = 0.000\n",
      "5467/2800 (epoch 97), train_loss = 9.451, time/batch = 0.016\n",
      "5468/2800 (epoch 97), train_loss = 11.071, time/batch = 0.016\n",
      "5469/2800 (epoch 97), train_loss = 10.930, time/batch = 0.016\n",
      "5470/2800 (epoch 97), train_loss = 10.700, time/batch = 0.016\n",
      "5471/2800 (epoch 97), train_loss = 10.990, time/batch = 0.000\n",
      "5472/2800 (epoch 97), train_loss = 10.380, time/batch = 0.016\n",
      "5473/2800 (epoch 97), train_loss = 10.400, time/batch = 0.022\n",
      "5474/2800 (epoch 97), train_loss = 10.412, time/batch = 0.016\n",
      "5475/2800 (epoch 97), train_loss = 10.612, time/batch = 0.000\n",
      "5476/2800 (epoch 97), train_loss = 10.220, time/batch = 0.016\n",
      "5477/2800 (epoch 97), train_loss = 10.481, time/batch = 0.016\n",
      "5478/2800 (epoch 97), train_loss = 10.590, time/batch = 0.016\n",
      "5479/2800 (epoch 97), train_loss = 10.244, time/batch = 0.016\n",
      "5480/2800 (epoch 97), train_loss = 10.229, time/batch = 0.000\n",
      "5481/2800 (epoch 97), train_loss = 10.834, time/batch = 0.022\n",
      "5482/2800 (epoch 97), train_loss = 10.480, time/batch = 0.016\n",
      "5483/2800 (epoch 97), train_loss = 10.071, time/batch = 0.016\n",
      "5484/2800 (epoch 97), train_loss = 10.847, time/batch = 0.000\n",
      "5485/2800 (epoch 97), train_loss = 9.911, time/batch = 0.016\n",
      "5486/2800 (epoch 97), train_loss = 9.957, time/batch = 0.016\n",
      "5487/2800 (epoch 97), train_loss = 10.268, time/batch = 0.016\n",
      "5488/2800 (epoch 98), train_loss = 9.977, time/batch = 0.018\n",
      "5489/2800 (epoch 98), train_loss = 9.251, time/batch = 0.004\n",
      "5490/2800 (epoch 98), train_loss = 9.695, time/batch = 0.016\n",
      "5491/2800 (epoch 98), train_loss = 9.710, time/batch = 0.016\n",
      "5492/2800 (epoch 98), train_loss = 8.985, time/batch = 0.016\n",
      "5493/2800 (epoch 98), train_loss = 9.665, time/batch = 0.016\n",
      "5494/2800 (epoch 98), train_loss = 9.508, time/batch = 0.016\n",
      "5495/2800 (epoch 98), train_loss = 9.620, time/batch = 0.000\n",
      "5496/2800 (epoch 98), train_loss = 8.961, time/batch = 0.022\n",
      "5497/2800 (epoch 98), train_loss = 9.765, time/batch = 0.016\n",
      "5498/2800 (epoch 98), train_loss = 9.644, time/batch = 0.016\n",
      "5499/2800 (epoch 98), train_loss = 9.559, time/batch = 0.000\n",
      "5500/2800 (epoch 98), train_loss = 8.726, time/batch = 0.016\n",
      "model saved to save\\model.ckpt\n",
      "5501/2800 (epoch 98), train_loss = 9.271, time/batch = 0.022\n",
      "5502/2800 (epoch 98), train_loss = 9.647, time/batch = 0.031\n",
      "5503/2800 (epoch 98), train_loss = 9.904, time/batch = 0.031\n",
      "5504/2800 (epoch 98), train_loss = 9.170, time/batch = 0.037\n",
      "5505/2800 (epoch 98), train_loss = 9.500, time/batch = 0.016\n",
      "5506/2800 (epoch 98), train_loss = 9.110, time/batch = 0.016\n",
      "5507/2800 (epoch 98), train_loss = 9.279, time/batch = 0.049\n",
      "5508/2800 (epoch 98), train_loss = 9.350, time/batch = 0.034\n",
      "5509/2800 (epoch 98), train_loss = 9.313, time/batch = 0.031\n",
      "5510/2800 (epoch 98), train_loss = 9.316, time/batch = 0.038\n",
      "5511/2800 (epoch 98), train_loss = 10.087, time/batch = 0.031\n",
      "5512/2800 (epoch 98), train_loss = 9.371, time/batch = 0.031\n",
      "5513/2800 (epoch 98), train_loss = 9.904, time/batch = 0.038\n",
      "5514/2800 (epoch 98), train_loss = 9.345, time/batch = 0.047\n",
      "5515/2800 (epoch 98), train_loss = 9.908, time/batch = 0.031\n",
      "5516/2800 (epoch 98), train_loss = 9.225, time/batch = 0.038\n",
      "5517/2800 (epoch 98), train_loss = 10.118, time/batch = 0.031\n",
      "5518/2800 (epoch 98), train_loss = 9.139, time/batch = 0.053\n",
      "5519/2800 (epoch 98), train_loss = 9.931, time/batch = 0.047\n",
      "5520/2800 (epoch 98), train_loss = 9.151, time/batch = 0.031\n",
      "5521/2800 (epoch 98), train_loss = 10.463, time/batch = 0.054\n",
      "5522/2800 (epoch 98), train_loss = 11.538, time/batch = 0.040\n",
      "5523/2800 (epoch 98), train_loss = 10.776, time/batch = 0.036\n",
      "5524/2800 (epoch 98), train_loss = 11.105, time/batch = 0.039\n",
      "5525/2800 (epoch 98), train_loss = 10.428, time/batch = 0.042\n",
      "5526/2800 (epoch 98), train_loss = 10.248, time/batch = 0.039\n",
      "5527/2800 (epoch 98), train_loss = 10.171, time/batch = 0.042\n",
      "5528/2800 (epoch 98), train_loss = 10.593, time/batch = 0.049\n",
      "5529/2800 (epoch 98), train_loss = 10.191, time/batch = 0.037\n",
      "5530/2800 (epoch 98), train_loss = 10.790, time/batch = 0.022\n",
      "5531/2800 (epoch 98), train_loss = 10.340, time/batch = 0.047\n",
      "5532/2800 (epoch 98), train_loss = 10.433, time/batch = 0.031\n",
      "5533/2800 (epoch 98), train_loss = 9.982, time/batch = 0.038\n",
      "5534/2800 (epoch 98), train_loss = 11.100, time/batch = 0.031\n",
      "5535/2800 (epoch 98), train_loss = 10.165, time/batch = 0.031\n",
      "5536/2800 (epoch 98), train_loss = 10.047, time/batch = 0.038\n",
      "5537/2800 (epoch 98), train_loss = 9.930, time/batch = 0.016\n",
      "5538/2800 (epoch 98), train_loss = 9.975, time/batch = 0.047\n",
      "5539/2800 (epoch 98), train_loss = 11.683, time/batch = 0.022\n",
      "5540/2800 (epoch 98), train_loss = 9.860, time/batch = 0.031\n",
      "5541/2800 (epoch 98), train_loss = 10.063, time/batch = 0.031\n",
      "5542/2800 (epoch 98), train_loss = 9.615, time/batch = 0.038\n",
      "5543/2800 (epoch 98), train_loss = 9.234, time/batch = 0.063\n",
      "5544/2800 (epoch 99), train_loss = 9.422, time/batch = 0.049\n",
      "5545/2800 (epoch 99), train_loss = 8.978, time/batch = 0.031\n",
      "5546/2800 (epoch 99), train_loss = 9.417, time/batch = 0.029\n",
      "5547/2800 (epoch 99), train_loss = 11.124, time/batch = 0.019\n",
      "5548/2800 (epoch 99), train_loss = 9.062, time/batch = 0.031\n",
      "5549/2800 (epoch 99), train_loss = 10.267, time/batch = 0.047\n",
      "5550/2800 (epoch 99), train_loss = 8.818, time/batch = 0.022\n",
      "5551/2800 (epoch 99), train_loss = 9.487, time/batch = 0.016\n",
      "5552/2800 (epoch 99), train_loss = 8.665, time/batch = 0.031\n",
      "5553/2800 (epoch 99), train_loss = 12.619, time/batch = 0.031\n",
      "5554/2800 (epoch 99), train_loss = 8.800, time/batch = 0.022\n",
      "5555/2800 (epoch 99), train_loss = 10.663, time/batch = 0.016\n",
      "5556/2800 (epoch 99), train_loss = 8.668, time/batch = 0.031\n",
      "5557/2800 (epoch 99), train_loss = 10.645, time/batch = 0.016\n",
      "5558/2800 (epoch 99), train_loss = 8.816, time/batch = 0.037\n",
      "5559/2800 (epoch 99), train_loss = 10.507, time/batch = 0.017\n",
      "5560/2800 (epoch 99), train_loss = 8.860, time/batch = 0.031\n",
      "5561/2800 (epoch 99), train_loss = 10.463, time/batch = 0.016\n",
      "5562/2800 (epoch 99), train_loss = 9.190, time/batch = 0.036\n",
      "5563/2800 (epoch 99), train_loss = 10.366, time/batch = 0.018\n",
      "5564/2800 (epoch 99), train_loss = 9.008, time/batch = 0.016\n",
      "5565/2800 (epoch 99), train_loss = 9.656, time/batch = 0.031\n",
      "5566/2800 (epoch 99), train_loss = 9.487, time/batch = 0.016\n",
      "5567/2800 (epoch 99), train_loss = 10.148, time/batch = 0.038\n",
      "5568/2800 (epoch 99), train_loss = 9.195, time/batch = 0.016\n",
      "5569/2800 (epoch 99), train_loss = 10.232, time/batch = 0.031\n",
      "5570/2800 (epoch 99), train_loss = 9.174, time/batch = 0.016\n",
      "5571/2800 (epoch 99), train_loss = 9.865, time/batch = 0.022\n",
      "5572/2800 (epoch 99), train_loss = 9.209, time/batch = 0.031\n",
      "5573/2800 (epoch 99), train_loss = 11.689, time/batch = 0.016\n",
      "5574/2800 (epoch 99), train_loss = 9.558, time/batch = 0.031\n",
      "5575/2800 (epoch 99), train_loss = 9.942, time/batch = 0.022\n",
      "5576/2800 (epoch 99), train_loss = 9.059, time/batch = 0.016\n",
      "5577/2800 (epoch 99), train_loss = 9.972, time/batch = 0.031\n",
      "5578/2800 (epoch 99), train_loss = 9.603, time/batch = 0.031\n",
      "5579/2800 (epoch 99), train_loss = 9.651, time/batch = 0.022\n",
      "5580/2800 (epoch 99), train_loss = 9.947, time/batch = 0.016\n",
      "5581/2800 (epoch 99), train_loss = 11.126, time/batch = 0.031\n",
      "5582/2800 (epoch 99), train_loss = 10.878, time/batch = 0.016\n",
      "5583/2800 (epoch 99), train_loss = 11.144, time/batch = 0.036\n",
      "5584/2800 (epoch 99), train_loss = 10.432, time/batch = 0.017\n",
      "5585/2800 (epoch 99), train_loss = 10.360, time/batch = 0.016\n",
      "5586/2800 (epoch 99), train_loss = 10.176, time/batch = 0.031\n",
      "5587/2800 (epoch 99), train_loss = 10.554, time/batch = 0.032\n",
      "5588/2800 (epoch 99), train_loss = 10.369, time/batch = 0.021\n",
      "5589/2800 (epoch 99), train_loss = 10.452, time/batch = 0.016\n",
      "5590/2800 (epoch 99), train_loss = 10.141, time/batch = 0.031\n",
      "5591/2800 (epoch 99), train_loss = 10.593, time/batch = 0.016\n",
      "5592/2800 (epoch 99), train_loss = 11.285, time/batch = 0.022\n",
      "5593/2800 (epoch 99), train_loss = 10.182, time/batch = 0.031\n",
      "5594/2800 (epoch 99), train_loss = 10.565, time/batch = 0.016\n",
      "5595/2800 (epoch 99), train_loss = 10.661, time/batch = 0.016\n",
      "5596/2800 (epoch 99), train_loss = 10.056, time/batch = 0.032\n",
      "5597/2800 (epoch 99), train_loss = 10.402, time/batch = 0.021\n",
      "5598/2800 (epoch 99), train_loss = 9.746, time/batch = 0.016\n",
      "5599/2800 (epoch 99), train_loss = 11.376, time/batch = 0.031\n"
     ]
    }
   ],
   "source": [
    "#model=1\n",
    "#model=Model()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "epochs=100\n",
    "for e in range(epochs):\n",
    "            data_loader.reset_batch_pointer()\n",
    "            # Get the initial cell state of the LSTM\n",
    "            #state=sess.run(model.initial_state)\n",
    "            #saver = tf.train.Saver(tf.all_variables())\n",
    "            # For each batch in this epoch\n",
    "            for b in range(data_loader.num_batches):\n",
    "                start = time.time()\n",
    "                x, y = data_loader.next_batch()\n",
    "                # Feed the source, target data and the initial LSTM state to the model\n",
    "                feed = {model.input_data: x, model.target_data: y,model.initial_state: state}\n",
    "                # Fetch the loss of the model on this batch, the final LSTM state from the session\n",
    "                train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "                end = time.time()\n",
    "                print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\n",
    "                    .format(\n",
    "                        e * data_loader.num_batches + b,\n",
    "                        50 * data_loader.num_batches,\n",
    "                        e,\n",
    "                        train_loss, end - start))\n",
    "            \n",
    "                if (e * data_loader.num_batches + b) % 500 == 0 and ((e * data_loader.num_batches + b) > 0):\n",
    "                    checkpoint_path = os.path.join('save', 'model.ckpt')\n",
    "                    saver.save(sess, checkpoint_path, global_step=e * data_loader.num_batches + b)\n",
    "                    print(\"model saved to {}\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(mux).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "??tf.contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
