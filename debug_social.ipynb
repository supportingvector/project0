{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3aa7331-c8aa-4ebe-a5d5-1a291b156873"
    }
   },
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d056355b-40e8-4a0b-bff1-b6bbc1d151b1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448\n",
      "1168\n",
      "774\n",
      "785\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "from social_utils import SocialDataLoader\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from grid import getSequenceGridMask\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "batch_size=50\n",
    "seq_length=8\n",
    "maxNumPeds=40\n",
    "datasets=[0, 1, 2, 3, 4]\n",
    "grid_size = 8\n",
    "neighborhood_size=32\n",
    "num_epochs=1\n",
    "data_loader = SocialDataLoader()\n",
    "x,y,d=data_loader.next_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5a245462-7f4b-45a6-87fd-b8dc13d70498"
    }
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "de9f0235-d26f-4e36-a260-7f2766d967d9"
    }
   },
   "outputs": [],
   "source": [
    "class SocialModel():\n",
    "\n",
    "    def __init__(self, infer=False):\n",
    "        '''\n",
    "        args \n",
    "        '''\n",
    "        # If sampling new trajectories, then infer mode\n",
    "        if infer:\n",
    "            # Sample one position at a time\n",
    "            batch_size = 1\n",
    "            aseq_length = 1\n",
    "        # Store the arguments\n",
    "        self.infer = infer\n",
    "        # Store rnn size and grid_size\n",
    "        self.rnn_size = 128\n",
    "        self.grid_size = 8\n",
    "        # Maximum number of peds\n",
    "        self.maxNumPeds =30\n",
    "        self.seq_length=5\n",
    "        self.maxNumPeds=40\n",
    "        self.embedding_size=64\n",
    "        self.output_size = 5\n",
    "        self.learning_rate=0.003\n",
    "        self.grad_clip=0.5\n",
    "        '''\n",
    "        model\n",
    "        '''\n",
    "        with tf.name_scope(\"LSTM_cell\"):\n",
    "        #with tf.name_scope(\"LSTM_cell\",reuse=True):\n",
    "            cell = rnn_cell.BasicLSTMCell(self.rnn_size, state_is_tuple=False)\n",
    "        self.input_data = tf.placeholder(tf.float32, \n",
    "                                         [self.seq_length, self.maxNumPeds, 3], name=\"input_data\")\n",
    "        #self.input_data维度为(seq_length,maxNumPeds，3)\n",
    "        \n",
    "        self.target_data = tf.placeholder(tf.float32, \n",
    "                                          [self.seq_length, self.maxNumPeds, 3], name=\"target_data\")\n",
    "        #self.target_data维度为(seq_length,maxNumPeds，3)\n",
    "        \n",
    "        # Grid data would be a binary matrix which encodes whether a pedestrian is present in\n",
    "        # a grid cell of other pedestrian\n",
    "        self.grid_data = tf.placeholder(tf.float32,\n",
    "                                        [self.seq_length, self.maxNumPeds,\n",
    "                                         self.maxNumPeds, self.grid_size*self.grid_size], name=\"grid_data\")\n",
    "        self.lr = tf.Variable(self.learning_rate, trainable=False, name=\"learning_rate\")\n",
    "        \n",
    "        \n",
    "        # Define LSTM states for each pedestrian\n",
    "        # maxNumPeds每一帧最大行人数目\n",
    "        with tf.variable_scope(\"LSTM_states\"):\n",
    "        #with tf.variable_scope(\"LSTM_states\",reuse=True):\n",
    "            self.LSTM_states = tf.zeros([self.maxNumPeds, cell.state_size], name=\"LSTM_states\")\n",
    "            self.initial_states = tf.split(axis=0,\n",
    "                                           num_or_size_splits=self.maxNumPeds, value=self.LSTM_states)\n",
    "            #将LSTM_state变成一个list，有MaxNumPeds个元素，每个为256维（一个lstm有128*2个维度hidden units）\n",
    "        \n",
    "        # Define hidden output states for each pedestrian\n",
    "        with tf.variable_scope(\"Hidden_states\"):\n",
    "        #with tf.variable_scope(\"Hidden_states\",reuse=True):\n",
    "            # self.output_states = tf.zeros([args.maxNumPeds, cell.output_size], name=\"hidden_states\")\n",
    "            self.output_states = tf.split(axis=0, num_or_size_splits=self.maxNumPeds, value=tf.zeros([self.maxNumPeds, cell.output_size]))\n",
    "            #将LSTM_state变成一个list，有MaxNumPeds个元素，每个为output_size维度）\n",
    "    \n",
    "    \n",
    "        # List of tensors each of shape args.maxNumPedsx3 corresponding to each frame in the sequence\n",
    "        with tf.name_scope(\"frame_data_tensors\"):\n",
    "        #with tf.name_scope(\"frame_data_tensors\",reuse=True):\n",
    "            # frame_data = tf.split(0, args.seq_length, self.input_data, name=\"frame_data\")\n",
    "            frame_data = [tf.squeeze(input_, [0]) \n",
    "                          for input_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.input_data)]\n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（maxNumPeds，3）\n",
    "       \n",
    "    \n",
    "        with tf.name_scope(\"frame_target_data_tensors\"):\n",
    "        #with tf.name_scope(\"frame_target_data_tensors\",reuse=True):\n",
    "            # frame_target_data = tf.split(0, args.seq_length, self.target_data, name=\"frame_target_data\")\n",
    "            self.frame_target_data = [tf.squeeze(target_, [0]) \n",
    "                                      for target_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.target_data)]\n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（maxNumPeds，3）            \n",
    "            \n",
    "          \n",
    "        with tf.name_scope(\"grid_frame_data_tensors\"):\n",
    "        #with tf.name_scope(\"grid_frame_data_tensors\",reuse=True):\n",
    "            # This would contain a list of tensors each of shape MNP x MNP x (GS**2) encoding the mask\n",
    "            # grid_frame_data = tf.split(0, args.seq_length, self.grid_data, name=\"grid_frame_data\")\n",
    "            grid_frame_data = [tf.squeeze(input_, [0]) for input_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.grid_data)]    \n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（self.maxNumPeds, self.maxNumPeds, self.grid_size*self.grid_size）\n",
    "  \n",
    "\n",
    "        # Cost的一些参数\n",
    "        with tf.name_scope(\"Cost_related_stuff\"):\n",
    "        #with tf.name_scope(\"Cost_related_stuff\",reuse=True):\n",
    "            self.cost = tf.constant(0.0, name=\"cost\")\n",
    "            self.counter = tf.constant(0.0, name=\"counter\")\n",
    "            self.increment = tf.constant(1.0, name=\"increment\")\n",
    "            \n",
    "            \n",
    "        # Containers to store output distribution parameters\n",
    "        with tf.name_scope(\"Distribution_parameters_stuff\"):\n",
    "            # self.initial_output = tf.zeros([args.maxNumPeds, self.output_size], name=\"distribution_parameters\")\n",
    "            self.initial_output = tf.split(axis=0, num_or_size_splits=self.maxNumPeds, value=tf.zeros([self.maxNumPeds, self.output_size]))            \n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（self.output_size）\n",
    "            \n",
    "        self.define_embedding_and_output_layers()\n",
    "        #定义embedding的各种参数\n",
    "        \n",
    "        \n",
    "        # Tensor to represent non-existent ped\n",
    "        with tf.name_scope(\"Non_existent_ped_stuff\"):\n",
    "            nonexistent_ped = tf.constant(0.0, name=\"zero_ped\")\n",
    "        \n",
    "        \n",
    "        for seq, frame in enumerate(frame_data):\n",
    "            print(\"Frame number\", seq)\n",
    "            current_frame_data = frame  \n",
    "            # MNP x 3 tensor\n",
    "            current_grid_frame_data = grid_frame_data[seq] \n",
    "            # MNP x MNP x (GS**2) tensor\n",
    "            social_tensor = tf.zeros([\n",
    "                    self.maxNumPeds, self.grid_size*self.grid_size*self.rnn_size])\n",
    "            for ped in range(self.maxNumPeds):\n",
    "                #print(\"Pedestrian Number\", ped)\n",
    "                pedID = current_frame_data[ped, 0]\n",
    "                with tf.name_scope(\"extract_input_ped\"):\n",
    "                    self.spatial_input = tf.slice(current_frame_data, [ped, 1], [1, 2])\n",
    "                    # Tensor of shape (1,2)\n",
    "                    # Extract x and y positions of the current ped\n",
    "                    self.tensor_input = tf.slice(social_tensor, \n",
    "                                                 [ped, 0],[1, self.grid_size*self.grid_size*self.rnn_size])\n",
    "                    # current ped对应的social\n",
    "                with tf.name_scope(\"embeddings_operations\"):\n",
    "                    embedded_spatial_input = tf.nn.relu(\n",
    "                        tf.nn.xw_plus_b(self.spatial_input, self.embedding_w, self.embedding_b))\n",
    "                    embedded_tensor_input = tf.nn.relu(\n",
    "                        tf.nn.xw_plus_b(self.tensor_input, self.embedding_t_w, self.embedding_t_b))\n",
    "                \n",
    "                \n",
    "                with tf.name_scope(\"concatenate_embeddings\"): \n",
    "                    # Concatenate the embeddings\n",
    "                    complete_input = tf.concat(axis=1, values=[embedded_spatial_input, embedded_tensor_input])\n",
    "                \n",
    "\n",
    "                with tf.variable_scope(\"LSTM\") as scope:\n",
    "                    if seq > 0 or ped > 0:\n",
    "                        scope.reuse_variables()\n",
    "                    self.output_states[ped], self.initial_states[ped] = cell(complete_input, self.initial_states[ped])\n",
    "                    #第一个是cell的output_hidden，第二个是两个hidden_state拼起来\n",
    "                    \n",
    "                with tf.name_scope(\"output_linear_layer\"):\n",
    "                    self.initial_output[ped] = tf.nn.xw_plus_b(\n",
    "                        self.output_states[ped], self.output_w, self.output_b)\n",
    "                \n",
    "                \n",
    "                with tf.name_scope(\"extract_target_ped\"):\n",
    "                    # Extract x and y coordinates of the target data\n",
    "                    # x_data and y_data would be tensors of shape 1 x 1\n",
    "                    [x_data, y_data] = tf.split(axis=1, num_or_size_splits=2,value=tf.slice(self.frame_target_data[seq], [ped, 1], [1, 2]))\n",
    "                                    \n",
    "                \n",
    "                \n",
    "                with tf.name_scope(\"get_coef\"):\n",
    "                    [o_mux, o_muy, o_sx, o_sy, o_corr] = self.get_coef(self.initial_output[ped])\n",
    "                \n",
    "                with tf.name_scope(\"calculate_loss\"):\n",
    "                    lossfunc = self.get_lossfunc(o_mux, o_muy, o_sx, o_sy, o_corr, x_data, y_data)\n",
    " \n",
    "                with tf.name_scope(\"increment_cost\"):\n",
    "                # If it is a non-existent ped, it should not contribute to cost\n",
    "                    self.cost = tf.where(tf.equal(pedID, nonexistent_ped), \n",
    "                                  self.cost, tf.add(self.cost, lossfunc))\n",
    "                    self.counter = tf.where(tf.not_equal(pedID, nonexistent_ped), \n",
    "                                     tf.add(self.counter, self.increment), self.counter) \n",
    "                    \n",
    "        with tf.name_scope(\"mean_cost\"):\n",
    "            # Mean of the cost\n",
    "            self.cost = tf.div(self.cost, self.counter)\n",
    "            \n",
    "        tvars = tf.trainable_variables()\n",
    "        #把每个ped的state拼接起来\n",
    "        self.final_states = tf.concat(axis=0, values=self.initial_states)\n",
    "        \n",
    "        # Get the final distribution parameters\n",
    "        self.final_output = self.initial_output\n",
    "        \n",
    "        # Compute gradients\n",
    "        self.gradients = tf.gradients(self.cost, tvars)\n",
    "        \n",
    "        # Clip the gradients\n",
    "        grads, _ = tf.clip_by_global_norm(self.gradients, self.grad_clip)\n",
    "        \n",
    "        optimizer = tf.train.RMSPropOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "    \"\"\"\n",
    "    Embedding\n",
    "    \"\"\"   \n",
    "    def define_embedding_and_output_layers(self):\n",
    "        # Define variables for the spatial coordinates embedding layer\n",
    "        with tf.variable_scope(\"coordinate_embedding\"):\n",
    "            self.embedding_w = tf.get_variable(\"embedding_w\", [2, self.embedding_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.embedding_b = tf.get_variable(\"embedding_b\", [self.embedding_size], initializer=tf.constant_initializer(0.01))\n",
    "\n",
    "        # Define variables for the social tensor embedding layer\n",
    "        with tf.variable_scope(\"tensor_embedding\"):\n",
    "            self.embedding_t_w = tf.get_variable(\"embedding_t_w\", [self.grid_size*self.grid_size*self.rnn_size, self.embedding_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.embedding_t_b = tf.get_variable(\"embedding_t_b\", [self.embedding_size], initializer=tf.constant_initializer(0.01))\n",
    "\n",
    "        # Define variables for the output linear layer\n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self.output_w = tf.get_variable(\"output_w\", [self.rnn_size, self.output_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.output_b = tf.get_variable(\"output_b\", [self.output_size], initializer=tf.constant_initializer(0.01))\n",
    "            \n",
    " \n",
    "        \n",
    "            \n",
    "    \"\"\"\n",
    "    functions\n",
    "    \"\"\"\n",
    "    def get_coef(self, output):\n",
    "        # eq 20 -> 22 of Graves (2013)\n",
    "\n",
    "        z = output\n",
    "        # Split the output into 5 parts corresponding to means, std devs and corr\n",
    "        z_mux, z_muy, z_sx, z_sy, z_corr = tf.split(axis=1, num_or_size_splits=5, value=z)\n",
    "\n",
    "        # The output must be exponentiated for the std devs\n",
    "        z_sx = tf.exp(z_sx)\n",
    "        z_sy = tf.exp(z_sy)\n",
    "        # Tanh applied to keep it in the range [-1, 1]\n",
    "        z_corr = tf.tanh(z_corr)\n",
    "\n",
    "        return [z_mux, z_muy, z_sx, z_sy, z_corr]\n",
    "    \n",
    "    def tf_2d_normal(self, x, y, mux, muy, sx, sy, rho):\n",
    "        '''\n",
    "        Function that implements the PDF of a 2D normal distribution\n",
    "        params:\n",
    "        x : input x points\n",
    "        y : input y points\n",
    "        mux : mean of the distribution in x\n",
    "        muy : mean of the distribution in y\n",
    "        sx : std dev of the distribution in x\n",
    "        sy : std dev of the distribution in y\n",
    "        rho : Correlation factor of the distribution\n",
    "        '''\n",
    "        # eq 3 in the paper\n",
    "        # and eq 24 & 25 in Graves (2013)\n",
    "        # Calculate (x - mux) and (y-muy)\n",
    "        normx = tf.subtract(x, mux)\n",
    "        normy = tf.subtract(y, muy)\n",
    "        sxsy = tf.multiply(sx, sy)\n",
    "        z = tf.square(tf.div(normx, sx)) + tf.square(tf.div(normy, sy)) - 2*tf.div(tf.multiply(rho, tf.multiply(normx, normy)), sxsy)\n",
    "        negRho = 1 - tf.square(rho)\n",
    "        result = tf.exp(tf.div(-z, 2*negRho))\n",
    "        denom = 2 * np.pi * tf.multiply(sxsy, tf.sqrt(negRho))\n",
    "        result = tf.div(result, denom)\n",
    "        self.result = result\n",
    "        return result\n",
    "    \n",
    "    def get_lossfunc(self, z_mux, z_muy, z_sx, z_sy, z_corr, x_data, y_data):\n",
    "        '''\n",
    "        Function to calculate given a 2D distribution over x and y, and target data\n",
    "        of observed x and y points\n",
    "        params:\n",
    "        z_mux : mean of the distribution in x\n",
    "        z_muy : mean of the distribution in y\n",
    "        z_sx : std dev of the distribution in x\n",
    "        z_sy : std dev of the distribution in y\n",
    "        z_rho : Correlation factor of the distribution\n",
    "        x_data : target x points\n",
    "        y_data : target y points\n",
    "        '''\n",
    "        step = tf.constant(1e-3, dtype=tf.float32, shape=(1, 1))\n",
    "        # Calculate the PDF of the data w.r.t to the distribution\n",
    "        result0_1 = self.tf_2d_normal(x_data, y_data, z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "        result0_2 = self.tf_2d_normal(tf.add(x_data, step), y_data, z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "        result0_3 = self.tf_2d_normal(x_data, tf.add(y_data, step), z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "        result0_4 = self.tf_2d_normal(tf.add(x_data, step), tf.add(y_data, step), z_mux, z_muy, z_sx, z_sy, z_corr)\n",
    "        result0 = tf.div(tf.add(tf.add(tf.add(result0_1, result0_2), result0_3), result0_4), tf.constant(4.0, dtype=tf.float32, shape=(1, 1)))\n",
    "        #数值稳定性，加小系数求平均\n",
    "        result0 = tf.multiply(tf.multiply(result0, step), step)\n",
    "        # For numerical stability purposes\n",
    "        epsilon = 1e-20\n",
    "        result1 = -tf.log(tf.maximum(result0, epsilon))  # Numerical stability\n",
    "        return tf.reduce_sum(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a68d3041-dd90-43bf-acf1-80d0adcc042e"
    }
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "458a7049-a273-4e1c-a380-baa91ef9bf98"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448\n",
      "1168\n",
      "774\n",
      "785\n",
      "1313\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002DF069FA9E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "Frame number 0\n",
      "Frame number 1\n",
      "Frame number 2\n"
     ]
    }
   ],
   "source": [
    "datasets = range(4)\n",
    "data_loader = SocialDataLoader()\n",
    "model = SocialModel()\n",
    "    # Initialize all variables in the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for e in range(num_epochs):\n",
    "        data_loader.reset_batch_pointer()\n",
    "        #\n",
    "        for b in range(data_loader.num_batches):\n",
    "            start = time.time()\n",
    "            x, y, d = data_loader.next_batch()\n",
    "        #模型输入为【batch_size,seq_length,maxNumPeds,3】\n",
    "            loss_batch = 0\n",
    "            for batch in range(data_loader.batch_size):\n",
    "                x_batch, y_batch, d_batch = x[batch], y[batch], d[batch]\n",
    "                #x_batch..变成了【seq_length,maxNumPeds,3】\n",
    "                if d_batch == 0 and datasets[0] == 0:\n",
    "                    dataset_data = [640, 480]\n",
    "                else:\n",
    "                    dataset_data = [720, 576]\n",
    "                grid_batch = getSequenceGridMask(x_batch, dataset_data,neighborhood_size, grid_size)\n",
    "                feed = {model.input_data: x_batch, model.target_data: y_batch, model.grid_data: grid_batch}\n",
    "                train_loss, _ = sess.run([model.cost, model.train_op], feed)\n",
    "                loss_batch += train_loss\n",
    "            end = time.time()\n",
    "            loss_batch = loss_batch / data_loader.batch_size\n",
    "            print(\n",
    "                    \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\n",
    "                    .format(\n",
    "                        e * data_loader.num_batches + b,\n",
    "                        args.num_epochs * data_loader.num_batches,\n",
    "                        e,\n",
    "                        loss_batch, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "??tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0916aa97-bb0d-4981-92fc-5b361cde8661"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 40, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "55b8d77d-5f44-411d-a098-7f99030c42db"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "91c76337-0320-4bec-b433-0bd9d5a55cf4"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0ab558dc-d05b-4562-bd31-c07ba90e2768"
    }
   },
   "outputs": [],
   "source": [
    "??tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2120cad1-c52c-4e68-8b4b-46fec1958988"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "1556cef6-6b2a-4498-9a9e-7aba9d24fe41": {
     "id": "1556cef6-6b2a-4498-9a9e-7aba9d24fe41",
     "prev": "32db19c4-b839-4b2f-9639-50aa0b2b8f70",
     "regions": {
      "1dc96c58-6fca-4967-a326-b6e92489d8a0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "91c76337-0320-4bec-b433-0bd9d5a55cf4",
        "part": "whole"
       },
       "id": "1dc96c58-6fca-4967-a326-b6e92489d8a0"
      }
     }
    },
    "32db19c4-b839-4b2f-9639-50aa0b2b8f70": {
     "id": "32db19c4-b839-4b2f-9639-50aa0b2b8f70",
     "prev": "9282411f-75e8-42c7-8888-4c11b184e750",
     "regions": {
      "8d192cbb-6c7b-41d5-89ff-ec3d764b2617": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "55b8d77d-5f44-411d-a098-7f99030c42db",
        "part": "whole"
       },
       "id": "8d192cbb-6c7b-41d5-89ff-ec3d764b2617"
      }
     }
    },
    "3391463c-14fa-4336-a755-214bb74b6512": {
     "id": "3391463c-14fa-4336-a755-214bb74b6512",
     "prev": "9a1ea6e7-7f70-4a6d-a963-3d1ff95d2eae",
     "regions": {
      "94a33f12-6f95-4a5a-8a81-5783238050e0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f5867795-3d25-4777-972e-269ea97f6832",
        "part": "whole"
       },
       "id": "94a33f12-6f95-4a5a-8a81-5783238050e0"
      }
     }
    },
    "4859c758-42fe-4602-af87-f28fd505a45d": {
     "id": "4859c758-42fe-4602-af87-f28fd505a45d",
     "prev": "3391463c-14fa-4336-a755-214bb74b6512",
     "regions": {
      "64eb37f1-47ce-4ce2-82da-774a3b8f775a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a68d3041-dd90-43bf-acf1-80d0adcc042e",
        "part": "whole"
       },
       "id": "64eb37f1-47ce-4ce2-82da-774a3b8f775a"
      }
     }
    },
    "4d190895-f82f-4d02-b9bb-6d31286f0d3c": {
     "id": "4d190895-f82f-4d02-b9bb-6d31286f0d3c",
     "prev": "4859c758-42fe-4602-af87-f28fd505a45d",
     "regions": {
      "f4a16e68-f55e-4287-825e-c75ad9d4bcde": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "458a7049-a273-4e1c-a380-baa91ef9bf98",
        "part": "whole"
       },
       "id": "f4a16e68-f55e-4287-825e-c75ad9d4bcde"
      }
     }
    },
    "74a1c923-9681-40ed-8037-593f7c32ec96": {
     "id": "74a1c923-9681-40ed-8037-593f7c32ec96",
     "prev": "1556cef6-6b2a-4498-9a9e-7aba9d24fe41",
     "regions": {
      "17e6db4b-8248-4d2e-8653-0ea852cdb807": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0ab558dc-d05b-4562-bd31-c07ba90e2768",
        "part": "whole"
       },
       "id": "17e6db4b-8248-4d2e-8653-0ea852cdb807"
      }
     }
    },
    "9282411f-75e8-42c7-8888-4c11b184e750": {
     "id": "9282411f-75e8-42c7-8888-4c11b184e750",
     "prev": "4d190895-f82f-4d02-b9bb-6d31286f0d3c",
     "regions": {
      "1b623542-b550-4ecf-a358-8e5e034d3077": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0916aa97-bb0d-4981-92fc-5b361cde8661",
        "part": "whole"
       },
       "id": "1b623542-b550-4ecf-a358-8e5e034d3077"
      }
     }
    },
    "9a1ea6e7-7f70-4a6d-a963-3d1ff95d2eae": {
     "id": "9a1ea6e7-7f70-4a6d-a963-3d1ff95d2eae",
     "prev": "ddbf0991-5a52-4229-8605-e7b7a780eb27",
     "regions": {
      "f5d60732-60d9-4cc9-b722-3ff3f17a082b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de9f0235-d26f-4e36-a260-7f2766d967d9",
        "part": "whole"
       },
       "id": "f5d60732-60d9-4cc9-b722-3ff3f17a082b"
      }
     }
    },
    "cf82e943-1356-47a4-b120-e962c851054f": {
     "id": "cf82e943-1356-47a4-b120-e962c851054f",
     "prev": "74a1c923-9681-40ed-8037-593f7c32ec96",
     "regions": {
      "d1963331-2579-44f4-a9a6-04820ed72960": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2120cad1-c52c-4e68-8b4b-46fec1958988",
        "part": "whole"
       },
       "id": "d1963331-2579-44f4-a9a6-04820ed72960"
      }
     }
    },
    "ddbf0991-5a52-4229-8605-e7b7a780eb27": {
     "id": "ddbf0991-5a52-4229-8605-e7b7a780eb27",
     "prev": null,
     "regions": {
      "cebed643-9f86-4419-aaa6-a794d7a3c08f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5a245462-7f4b-45a6-87fd-b8dc13d70498",
        "part": "whole"
       },
       "id": "cebed643-9f86-4419-aaa6-a794d7a3c08f"
      }
     }
    }
   },
   "themes": {
    "default": "2afe4b19-7166-4f13-ba99-fc1464c316cc",
    "theme": {
     "2afe4b19-7166-4f13-ba99-fc1464c316cc": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "2afe4b19-7166-4f13-ba99-fc1464c316cc",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         256,
         256,
         256
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         0,
         0,
         0
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         0,
         0,
         139
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         0,
         0,
         0
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Lato",
       "font-size": 5
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
